video_id,video_name,minute,text
Ki2iHgKxRBo,Supervised Learning - Georgia Tech - Machine Learning,0-1,"This class is divided into
three subclasses, three parts. They are supervised learning. >> Yeah.
>> Unsupervised learning, and reinforcement. So, what do you think
supervised learning is? >> So, I think of supervised learning
as being the problem of taking labelled data sets, gleaning information from
it so that you can label new data sets. >> That's fair. I call that function approximation. So, here's an example
of supervised learning. I'm going to give you an input and
an output. And I'm going to give
them to you as pairs, and I want you to guess
what the function is. >> Sure.
>> Okay? Okay. 1, 1. >> Uh-huh. 2, 4. >> Wait, hang on,
is 1 the input and 1 the output,. >> Yes.
>> And 2 the input, and 4 the output? >> Correct.
>> All right. I'm on, I think I am on to you. >> 3, 9. >> Okay.
>> 4, 16. >> Nice. >> 5, 25. 6, 36. 7, 49. >> Nice. This is a very hip data set. >> It is. What's the function?
>> It's hip to be squared. >> Exactly. Maybe. So if you believe that's true,"
Ki2iHgKxRBo,Supervised Learning - Georgia Tech - Machine Learning,1-2,"then tell me if the input is 10,
what's the output? >> 100.
>> And that's right, if it turns out, in fact, that the function is x squared. But the truth is, we have no idea
whether this function is x squared. Not really.
>> I have a pretty good idea. >> You do?
>> Well- >> Where's that idea come from? >> It comes from having spoken with
you over a long period of time. And plus, you know, math. >> And plus math. Well, I'm going to- >> You can't say I'm wrong. >> You're wrong. >> Oh.
>> Yeah, I did. >> You just said I was wrong. >> No, you've talked to me for
a long time, and plus math. I agree with that. >> Okay.
>> But I'm going to claim that you're
making a leap of faith. >> Hm.
>> Despite being a scientist, by deciding that the input is 10 and
the output is 100. >> Sure.
I would agree with that. >> What's that leap of faith? >> Well, I mean, from what you told me,
it's still consistent with lots of other mappings from input to
output like 10 gets mapped to 11. >> Right or
everything is x squared except 10. >> Sure. >> Or everything is x,
x squared up to 10. >> Right, that would be mean- >> That would be mean- >> But it's not logically impossible. >> What would be the median?"
Ki2iHgKxRBo,Supervised Learning - Georgia Tech - Machine Learning,2-3,">> A-ha. >> Thank you very much. I, I was saving that one up."
pqXASFHUfhs,Induction and Deduction - Georgia Tech - Machine Learning,0-1,"Well, what you're doing in order to make
that work and what you end up doing in supervised learning and
functions approximation in general, is you make some fundamental
assumptions about the work, right? You decide that you have a well-behaved
function that is consistent with the data that you're given, and with
that, you're able to generalize, and in fact that is the fundamental
problem in machine learning. It is generalization. Now what's behind all of is
I'm going to claim, Michael, you jump in whenever you disagree is
>> I disagree sorry to soon, go ahead. >> is bias and in particular >> bias
>> inductive bias. >> Inductive bias. >> Right, so all of machine learning or certainly supervised learning is about
induction, as opposed to deduction. >> I see.
Induction of course being a problem of going from examples to
a more general rule. >> Right, specifics to generalities. By contrast, deduction is? >> Be the opposite. It would be going from a general
rule to specific instances, basically like reasoning. >> Right, and in fact, a lot of AI in the beginning
was about deductive reasoning,"
pqXASFHUfhs,Induction and Deduction - Georgia Tech - Machine Learning,1-2,"about logic programming, those sorts of
things, where you have certain rules, and you deduce only those things that
follow immediately from those rules. So for example,
you'd have something like A implies B. That's a rule in the universe. And then I tell you A. So if you A implies B is a rule in
the universe, and I tell you A, then you also know? >> That A implies B. >> And therefore you can infer that? >> And A. B. >> B. You have A implies B,
you have A, that implies B. >> Okay.
>> That's what we just said. But what,
>> that's deduction. >> That's deduction, but
we just did was not deduction. Before then when I asked you one, one,
two, four, three, nine, four sixteen and so forth. >> Right,
>> we did induction. >> That was induction. >> Induction is more about
did the sun rise yesterday? >> yes.
>> Did the sun rise the day before that? >> yes.
>> Did the sun rise the day before that? >> I slept in. Did the sun rise the day before that? >> Yes. >> Yes. So the sun has risen every day. Is the sun going to rise tomorrow? >> I sure hope so. >> We all hope so, and
we all act like it does,"
pqXASFHUfhs,Induction and Deduction - Georgia Tech - Machine Learning,2-3,"because if it doesn't, then there are a
whole bunch of other things we ought to be doing besides sitting in this
studio and having this interview. >> I think we should warn the plants. >> [LAUGH] I don't think
the plants are going to care. >> They are.
They really need sun. I think we all need sun, Mike. >> Eh.
>> So, the idea there is induction is crucial, and
the inductive bias is crucial. We'll talk about all of this in,
in the course. >> Kay.
>> But that's kind of a fundamental notion behind supervised learning and
machine learning in general. >> I agree with that. >> Agreed?
>> Yeah. >> Al lright, so we're on the same page. So that's supervised learning. Supervised learning, you can talk about
it in these high muckity muck ways, but at the end of the day,
it's function approximation. It's figuring out how to take
a bunch of training examples and coming up with some function
that generalizes beyond the data that you see. >> So, why wouldn't you call
it function induction, then? >> because someone said
supervised learning first. Well, there is a- >> No, no, no, no, no.
Sorry. You said supervised learning is function
approximation and I want to say, why don't you say supervised
learning is function induction. >> As opposed to function approximation? >> Yeah. >> Okay. It's a
>> Approximate function induction. >> Or induction of approximate, of. >> Approximate functions? >> Approximate functions,
something like that, yeah. >> You don't want to induce
an approximate function,"
pqXASFHUfhs,Induction and Deduction - Georgia Tech - Machine Learning,3-4,"you want to induce the actual function. >> Yeah, but sometimes you can't,
>> Yeah. >> Because sometimes you think
it's quadratic, but it's not. >> I have that as a plaque on my wall. >> You do? >> No. >> Yeah I didn't think so. Okay so that's supervised learning"
1qtfILYSDJY,Unsupervised Learning - Georgia Tech - Machine Learning,0-1,"What about unsupervised learning? >> Right, so unsupervised learning
we don't get those examples. We have just essentially
something like input, and we have to derive some structure
from them just by looking at the relationship between
the inputs themselves. >> Right so give me an example of that. >> So. When you're studying different kinds
of animals, say, even as a kid. >> Mm-hm.
>> You might start to say, oh, there's these animals that
all look kind of the same. They're all four-legged. I'm going to call all of them dogs. Even if they happen to be horses,
or cows, or whatever. But I have developed,
without anyone telling me, this sort of notion that all
these belong in the same class. And it's different
from things like trees. Which don't have four legs. >> Well some do, but I mean, they have,
they both bark, is all I'm saying. >> Did I really set you up for that? >> Not on purpose. >> I, I'm sorry, I want to apologize
to each and every one of you for that. But that was pretty good. Michael is very good at word play. Which I guess is often
unsupervised as well. No, I get a lot of [LAUGH]."
1qtfILYSDJY,Unsupervised Learning - Georgia Tech - Machine Learning,1-2,">> [LAUGH] You certainly
get a lot of feedback. >> Yeah, that's right. So I say, please stop doing that. >> So if supervised learning is
about function approximation, then unsupervised learning
is about description. It's about taking a set of data and figuring out how you might divide
it up in one way or the other. >> Or maybe even summarization
it's not just the description but it's a shorter description. >> Yeah, it's usually concise. Compression. >> Compact description. So I might take a bunch of pixels
like I have here it might say, male. >> [LAUGH] Wait, wait, wait, wait. I'm pixels now? >> As far as we can tell. >> That's fine. >> I however, am not pixels. I know I'm not pixels. I'm pretty sure the rest
of you are pixels. >> That's right.
>> So I have a bunch of pixels, and I might say male. And or I might say female. Or I might say dog. Or I might say tree. But, the point is I don't have a bunch
of labels that say dog, tree, male, or female. I just decide that pixels like
this belong with pixels like this. As opposed to pixels like something
else that I'm pointing to behind me. >> Yeah we're living in a world right
now that is devoid of any other objects. Oh, chairs! >> Chairs!
Right. So these pixels are very different
than those pixels because of"
1qtfILYSDJY,Unsupervised Learning - Georgia Tech - Machine Learning,2-3,"where they are relative
to the other pixels. Say, right? So, if you were looking- >> I'm not sure that's helping me
understand unsupervised learning. >> Go out and, go outside and look at a crowd of people and try to
decide how you might divide them up. Maybe you'll divide
them up by ethnicity. Maybe you'll divide them up by
whether they have purposefully shaven their hair in order to mock the bald or
whether they have curly hair. Maybe you'll divide them
up by whether they have goatees,
>> Facial hair. >> Or whether they have grey hair, there's lots of things that
you might do in order,. >> Did you just point at me and
say grey hair? >> I was pointing and
your head happened to be there. >> Oh come on.
>> Pixels, >> Where's the grey hair? >> It's a two dimensional, right there,
it's right where your spit curl is. All right. >> Okay.
So, imagine you're dividing the world up that way. You could divide it up male, female. You could divide it up short, tall,
wears hats, doesn't wear hats, all kinds of ways you can divide it up. And no one's telling you the right way
to divide it up, at least not directly. That's unsupervised learning. That's description, because now- >> Mm.
>> Rather than having to send pixels of everyone, or having to do a complete
description of this crowd,"
1qtfILYSDJY,Unsupervised Learning - Georgia Tech - Machine Learning,3-4,"you can say there were 57 males and
23 females say. Or there are mostly people with beards. >> So on.
>> Or whatever. >> I like summarization for that. That seems good. >> I like summarization for that. >> Yeah.
>> It's a nice concise description. That's unsupervised learning. >> Good.
Very good. >> And practice.
>> And that's different from supervised learning? >> It's different in supervised learning
and it's different in a couple of ways. One way that it's different
is all of those ways that we could have just divided up the world. In some sense are all equal either. So I could divide up by sex or I could divide up by height or I could
divide up by clothing or whatever. And they're all equally good absent
some other signal later telling you how you should be dividing up the world. But supervised learning directly
tells you there's a signal. This is what it ought to be,
and that's how you train. And those are very different. >> Now, but I could see ways that
unsupervised learning could be helpful in the supervised setting, right? So if I do get a nice description, and
it's the right kind of description, it might help me map to, it may help me
do the function approximation better. >> Right, so instead of taking
pixels that input, as input, and, and labels like, male or female. I could just simply take a summarization
of you like how much hair do you have your relative height,
the weight, and"
1qtfILYSDJY,Unsupervised Learning - Georgia Tech - Machine Learning,4-5,"various things like that
that might help me do it. That's right.
And by the way, in practice this turns out to be
things like density estimation. We do end up turning it into
statistics at the end of the day. Often. >> But
it's statistics from the beginning. But when you say density estimation. >> Yes.
>> Are you saying I'm stupid? No.
>> All right so what is density estimation? >> Well they'll have to
take the class to find out. >> I see. >> Okay"
Ee4uH7PaN1M,Reinforcement Learning - Georgia Tech - Machine Learning,0-1,"All right.
So that's supervised learning and unsupervised learning. That's pretty good. The last one is reinforcement learning. >> [SOUND]. >> Now reinforcement learning
is what we both do, so Michael does a little bit of
reinforcement learning here and there. You've got how many papers published
in reinforcement learning? >> All of them. [LAUGH] Several. I have several. >> The man has like a hundred papers of
reinforcement learnings and in fact he wrote with his colleagues the great
summary journal article bringing every one up to date on what reinforcement
learning was like back in 1990. >> Yeah like 112 years ago. >> 1992. >> People are saying yeah we should
probably somebody should write a new one because the other ones getting
a little long in the dude. >> But there's been books written
on machine learning system. >> That's right. >> It's a very popular field. That's why we're both in it. Michael tends to prove a lot of things,. >> It is not, that is not why I'm in it. >> What, I didn't, wait, what? >> You said it's a very popular
field and that's why we're in it. >> No, no, no, no, no. Did I say that? >> That's what I heard. >> I didn't mean to say that. >> [SOUND] Let's run it back and see. >> It's a very popular, yeah, let's do that again because
I did not mean to say that. It is a very popular field. Perhaps because you're in it Michael. >> I don't think that's it. When I was an undergraduate,"
Ee4uH7PaN1M,Reinforcement Learning - Georgia Tech - Machine Learning,1-2,"I thought the thing that I
really want to understand. I liked AI,
I liked the whole idea of AI. But what I really want to understand
is how can you learn to be better from experience? And like I, I built a tic-tac-toe
playing program, and like, I want this tic-tac-toe playing program
to get really good at tic-tac-toe. because I was always interested
in the most practical society impacting problems. >> I think that generalized
pretty well to world hunger. >> Eventually. So so that is what got
me interested in it, and I was, I didn't even know what
it was called for a long time. So I started doing
reinforcement learning, and then discovered that it was
interesting and popular. >> Right. Well, I certainly wouldn't suggest that
we're doing the science that we're doing because it's popular. We're doing it because
we're interested in it. >> Yes. >> And I'm interested in reinforcement
learning because in some sense, it kind of encapsulates all
the things I happen to care about. I come from a sort of general AI
background, and I care modeling people. I care about building smart agents
that have to live in in world that other smart agents, thousands of them,
hundreds of thousand of them, thousands of them. Some of them might be human and"
Ee4uH7PaN1M,Reinforcement Learning - Georgia Tech - Machine Learning,2-3,"have to feel some way to
predict what to do over time. So, from a sort a technical point
of view, if we can think of re, in, supervised learning as
function approximation and unsupervised learning as, you know. >> Concise-
>> Concise, impact description, what's
the difference between something like reinforcement learning and those two? Supervised learning. >> So often the way that
supervised learning oh, sorry, reinforcement learning is described is,
is learning from delayed reward. >> Mm-hm.
So instead of the feedback that you get in supervised learning which
is here's what you should do. And the feedback that you get in
unsupervised learning which is the feedback in reinforcement
learning may come several steps after the decisions that
you've actually made. >> So a good example of that, or
the easy example of that would be, actually your tic-tac-toe program,
right? So, you do something in tic-tac-toe,
you put an X in the center and then you put a, let's say,
an O over here. >> Oh. >> And then I put an X right here. >> Nice. >> And then you ridiculously
put an O in the center. >> Which allows me to put
an X over here and I win. >> All right. >> Now what's interesting about that is, I didn't tell you what happened until
the very end when I said X wins."
Ee4uH7PaN1M,Reinforcement Learning - Georgia Tech - Machine Learning,3-4,">> Right. And now I know I made a mistake
somewhere along the way but I don't know exactly where. I may have to kind of roll back the game
in my mind and eventually figure out where it is that I went off track,
and what it is that I did wrong. >> And in the full generality
of reinforcement learning, you may have never made a mistake. It may simply be that's
the way games go but you would like to know which of
the moves you made mattered. Now, if it were a civilized learning
problem, I would have put the X here, he would have put the O there, and
it would have been called that's Good. I would have put the X here, and when he put the O there, it would have
been that's Bad, the O goes here. >> Mm-hm. Right.
>> Or something like that. It would have told you where
he should have put the O. But here, all he gets is eventually
some kind of signal saying, you did something well. You did something poorly and even
then it's only relative to the other signals that you might have gotten. >> Right, so then reinforcement
learning is in some sense harder because nobody's telling you what to do. You have to work it out on your own. >> Yeah it's like playing a game
without knowing any of the rules. Or at least knowing how you win or lose."
Ee4uH7PaN1M,Reinforcement Learning - Georgia Tech - Machine Learning,4-5,"But being told every once in awhile that
you've won or you've lost, okay, now- >> Sometimes I feel like that. >> I know man."
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,0-1,"Okay, so we've got these three little
bits of machine learning here. And there are a lot of tools and
techniques that are inside that. >> Mm-hm.
>> And I think that's great. And we're going to be trying to
teach you a lot of those tools and techniques and
sort of ways to connect them together. So by the way,
as Michael was pointing out, there are kind of ways that these
things might help each other, unsupervised learning might
help supervised learning. It's actually much deeper than that. It turns out you, even though
unsupervised learning is clearly not the same as supervised learning at
the level that we described it, in some ways they're
exactly the same thing. Supervised learning you have some bias. Oh, it's a quadratic function,
induction make sense. All these kind of assumptions you make. And in unsupervised learning, I told you
that we don't know whether this clusters is better than this cluster, dividing by
sex is better than dividing by height, or, or hair color or whatever. >> Mm. >> But ultimately you make some
decision about how to cluster, and that means implicitly
there's some assume signal. There's some assume set of labels
that you think make sense. Oh, I think things that look alike
should somehow be clustered together. >> Mm. >> Or things that are near one
another should cluster together. So in some ways it's still kind
of like supervised learning."
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,1-2,"You can certainly turn any supervised learning problem into
an unsupervised learning problem. >> Mm, mm.
>> Right? So in fact, all of these problems
are really the same kind of problem. >> Yeah, well there's two things
that I'd want to add to that. One is that in some sense,
in many cases, you can formulate all these different
problems as some form of optimization. In supervised learning
you want something that, that labels data well and so you're,
the thing you're trying to optimize is find me a function that,
that does that scores it. In reinforcement learning we're trying
to find a behavior that scores well. And unsu, unsupervised learning we
usually have to make up some kind of a criterion, and then we find
a way of clustering the data, organizing the data so
that it scores well. So that was the first
point I wanted to make. The other one is if you
divide things by sex and your a virgin then there's
numerical instability issues. >> Do you learn about
that on the street? >> I learned it in a Math book. >> Yes you [NOISE] I'm, I'm going to
move on And so here's the thing. >> All right.
>> Everything just Michael just said except the last part is true. But there's actually a sort of
deeper thing going on here."
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,2-3,"To me, if you think about the
commonalities of everything we've just said, it boils down to one thing data,
data, data, data, data, data. Data is king in machine learning. Now Michael would call
himself a computer scientist. >> Oh, yeah.
>> And I would call myself a computationalist. >> What?
>> What if I'm in a college of computing at a department
of computer science? I believe in computing and
computation as being the ultimate thing. So I would call myself
a computationalist, and Michael would probably agree with that
just to keep this discussion moving. >> Let's say. >> Right. So we're computationalists. We believe in computing. That's a good thing.
>> Sure. >> Many of our colleagues who do
computations tend to think in terms of algorithms. They think in terms of what
are the series of steps I need to do in order to
solve some problem? Or they. >> [CROSSTALK].
>> Might think in terms of theorems. If I try to describe this
problem in a particular way, is it solvable quizzically
by some algorithm? >> Yeah. >> And, truthfully,
machine learning is a lot of that. But the difference between the person
who's trying to solve our problem as an AI person or
as a computing person and somebody who's trying to solve our
problem as a machine learning person is"
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,3-4,"that the algorithm stops being central,
the data starts being central. And so what I hope you get out of this
class, or at least part of the stuff that you do, is understanding that
you have to believe the data, you have to do something with the data,
you have to be consistent with the data. The algorithms that fall out of
all that are algorithms, but they're algorithms that take the data
as primary or at least important. >> I'm going to go with co-equal. >> So the algorithms and
data are co-equal. >> Co-equal. >> Well if you believe in Lisp,
they're the same thing. >> Exactly! >> All right.
So there you go. >> They knew back in the 70s. >> So
it turns out we do agree on most things. >> [NOISE] That was close. >> Excellent! So, the rest of the semester
will go exactly like this. >> [LAUGH].
>> [LAUGH] Except you won't see us. You'll see our hands though. >> This side. This side. >> You'll see our hands, though. Thank you, Michael. >> It's all right. >> [LAUGH] What? [LAUGH]. >> What?
[LAUGH]. >> That was good,
that took me back to when I was four. Okay, so. >> Senor Wences. >> Hm?
>> It's called Señor Wences. >> Yes, I know. >> Yeah, okay.
>> I remember that. >> Mm-hm, yeah.
>> I'm not that much younger than you are. >> Little bit."
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,4-5,">> Ten, 12 years only. >> No come on. >> You can count gray hairs. Anyway the point is the rest of
the semester will go like this. We will talk about supervised learning
and a whole series of algorithms. Step back a little bit and talk about
the theory behind them, and try to connect theory of machine learning
with theory of computing notions, or at least that kind of basic idea. What does it mean to be a hard
problem versus an easier problem? Will move into randomized optimization
and unsupervised learning where we will talk about all the issues that we
brought up here and try to connect them back to some of the things that we did
in the section on supervised learning. And then finally, we will spend our
time on reinforcement learning. And a generalization of these
traditional reinforcement learning, which involves multiple agents. So we'll talk about a little bit of. >> Mm-hm.
>> Game theory, which Michael loves to talk about. I love to talk about. And the applications of all the stuff
that we've been learning to solving problems of how to
actually act in the world? How to build that world
out to do something? Or build that agent to play a game or to teach you how to do whatever you,
you need to be taught how to do? But at the end of the day,
we're going to teach you how to"
V59IUhkRPDY,Comparison of These Parts of ML - Georgia Tech - Machine Learning,5-6,"think about data,
how to think about algorithms, and how to build artifacts that you know,
will learn? >> Let's do this thing. >> Excellent.
All right. Well thank you Michael. >> Sure. >> I will see you next time we're
in the same place at the same time."
i04Pfrb71vk,Difference between Classification and Regression - Georgia Tech - Machine Learning,0-1,"Okay, hi Michael. >> Hey Charles, how's it going. >> It's going pretty well, how's it going in your end of the world? >> Very nice, what are we want to talk about today? >> Well today we are going to talk about supervised learning. But, in particular what we're going to talk about are two kinds of supervised learning, and one particular way to do supervised learning. Okay, so the two types of supervised learning that we typically think about are classification. And regression. And we're going to spend most of the time today talking about classification and more time next time talking about regression. So the difference between classification and regression is fairly simple for the purposes of this discussion. Classification is simply the process of taking some kind of input, let's call it x. And I'm going to define these terms in a couple of minutes. And mapping it to some discrete label. Usually, for what we're talking about, something like, true or false. So, what's a good example of that? Imagine that I have a nice little picture of Michael. >> It looks just like me! >> It looks exactly like you. So I have a nice little picture here"
i04Pfrb71vk,Difference between Classification and Regression - Georgia Tech - Machine Learning,1-2,"and I want to know whether this is a male. Or a female. So given an input like this I will map it to male or female. So what do you think, Michael? Do you think this is a male or a female? >> So you're, you're classifying me as male or female based on the picture of me and I would think you know, based on how I look I'm clearly male. >> Yes. In fact, manly male. So, this would be a classification from pictures to male. The alternative would be something like a picture to female, and I'm just going to take a completely stereotypical image of either a female or. >> I think it's actually, that's actually me when I let my hair go long. >> Right, so, so which points out that this can be pretty hard. But this is where we're going to spend most of our time talking about it first as a classification task. So taking some kind of input, in this case pictures, and mapping it to some discrete number of labels, true or false, male or female, car versus cougar, anything that, that you might imagine thinking of."
i04Pfrb71vk,Difference between Classification and Regression - Georgia Tech - Machine Learning,2-3,">> Car versus cougar? >> Yes. >> That, I guess that's an important thing if you're driving. You don't want to run into any cougars or probably other cars either. >> Well you know, you're sitting down and you're trying to decide whether you should ride this thing that you see or not. >> And if its a cougar maybe you don't want to and if it's a car maybe you do. >> Excellent. Don't drive a cougar. >> Don't drive a cougar. That's the first lesson in machine learning. >> Excellent. >> Okay, so that's classification. We'll return to regression in a little bit later during this conversation. But, just as a preview, regression is more about continuous value function. So, something like giving a bunch of points. I want to give in a new point. I want to map it to some real value. So we may pretend that these are examples of a line and so given a point here, I might say the output is right there. Okay, so that's regression but we'll talk about that in a moment. Right now, what I want to talk about is classification. >> Would an example of regression also be, for example, mapping the pictures of me to the length of my hair? Like"
i04Pfrb71vk,Difference between Classification and Regression - Georgia Tech - Machine Learning,3-4,"a number that represents the length of my hair? >> Absolutely, for the purposes of, of the sort of things that we're going to be worried about you can really think of the difference between classification and regression is the difference between mapping from some input to some small number of discrete values which might represent concepts. And regression is mapping from some input space to some real number. Potentially infinite number of real numbers. >> Cool, let's do a, let's do a quiz. Make sure we get this. >> Okay, I like that."
L29Am_JBNm0,Supervised Learning Quiz - Georgia Tech - Machine Learning,0-1,"So we've talked about uh,classification and regression and gave a couple of examples of each. So now I want you to take a moment to make certain that you understand the difference because it's a crucial difference for supervised learning. Here's a very short little quiz. You have three questions here and we divided the world up into some input to some learning algorithm, whatever that learning algorithm is. The output that we're expecting and then a box for you to tell us whether its classification or regression. So, the first question, the input is credit history, whatever that means, the number of loans that you have, how much money you make, how many times you've defaulted, how many times you've been late, the sort of things that make up credit history, and the output of the learning algorithm is rather you should lend money or not. So you're a bank, and you're trying to determine whether given a credit history, I should lend this person money, that's question one. Is that classification, or is that regression? Question two you take as input a picture like the examples that we've given before. And the output of your learning system is going"
L29Am_JBNm0,Supervised Learning Quiz - Georgia Tech - Machine Learning,1-2,"to be whether this person is of high school age, college age, or grad student age. The third question is very similar. The input is again a picture. And the output is, I guess, of the actual age of the person, 17, 24, 23 and a half, whatever. So take a moment and try to decide whether these are classification tasks or regression tasks."
DZa0puxLd9w,Supervised Learning Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,">> And so now let's give the explanation for the quiz. >> Alright, so, let's see what happened here. So, what you're saying is in some cases the inputs are discrete or continuous or complicated. In other cases the outputs could be discrete or continuous or complicated. But I think what you were saying is, that what on, on, what matters to determine if something is classification or regression is whether the output is from a discrete small set or, or whether it's some continuous quantity. Is that right? >> Right, that's exactly right. The difference between a classification task or a regression task is not about the input, it's about the output. If the output is continuous then it's regression and if the output is small discrete set or discrete set, then it is a classification task. So, with that in mind, what do you think is the answer to the first one? >> So, lend money. If it was something like predicting a credit score, that seems like a more continuous quantity. But this is just a yes no, so that's a discrete class, so I'm going to go with classification."
DZa0puxLd9w,Supervised Learning Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,">> That is, correct. It is classification and the short answer is, because it's a binary task. True, false. Yes, no. Lend money or don't lend money. >> Got it. >> So it's a simple classification test. Okay, with that in mind, what about number two? >> Alright, so number two. It's trying to judge something about where they fall on a scale, high school, college, or grad student. But all of, the system is being asked to do is put them into one of those three categories, and these categories are like classes, so it's classification. >> That is also exactly right. Classification. We moved from binary to trinary in this case, but the important thing is that it's discrete. So it doesn't matter if it's high school, college grad, professor, elementary school, any number of other ways we might decide where your status of matriculation is is a small discrete set. So, with that in mind, what about number three? >> Alright, so the input is the same in this case. And the output is kind of the same except there's, well there's certainly more categories because there's more possible ages than just those three. But when you gave the example you"
DZa0puxLd9w,Supervised Learning Quiz Quiz Solution - Georgia Tech - Machine Learning,2-3,"did explicitly say that ages can be fractional like, you know, 22.3. So that definitely makes me think that it's continuous, so it should be regression. >> Right, I think that is exactly the right thing, you have a continuous output. Now, I do want to point something out. That while the right answer is regression, a lot of people might have decided that the answer was classification. So, what's an argument? If I told you in fact the answer was classification, what would be your argument for why that would be? >> Well, I guess. >> Can you think of one? >> Yeah, I guess. I mean, you know, if you think about ages as being discrete. You just say, you know, you can one or two or three or, you know, whatever up to 130, say. But there, but there's just that, that set. There isn't really, you know, usually we don't talk about fractional ages. So, so it seems like you could think of it as, as, as a set of classes. >> Right. So let's imagine. So, how old are people? Let's imagine we only cared about years, so you're either one or two or three or four or five. Or maybe you can be one and a half, and two and a half, and three and a half. But, whatever, it's, it's not all possible real number values. And we know that people"
DZa0puxLd9w,Supervised Learning Quiz Quiz Solution - Georgia Tech - Machine Learning,3-4,"don't live beyond, say, 250. Well, in that case, you've got a very large discrete set but it's still discrete. Doesn't matter whether there's two things in your set, three things in your set, or in this case 250 things in your set, it's still discrete. So, whether it's regression, or classification, depends upon exactly how you define your output and these things become important. I'm going to argue that in practice, if you were going to set up this problem, the easiest way to do it would be to think about it as a real number and you would predict something like 23.7. And so it's going to end up being a regression task and we can might, maybe think about that a little bit more as we move along. So either answer would be acceptable depending upon what your explanation of exactly what the output was. Was. You buy that? >> That makes sense. >> Excellent. Okay. Alright, let's move beyond the quiz and start thinking about exactly what it means to define a classification problem. And then"
DZa0puxLd9w,Supervised Learning Quiz Quiz Solution - Georgia Tech - Machine Learning,4-5,later what it means to define a regression problem.
IrM0MNi_Kxk,Classification Learning One - Georgia Tech - Machine Learning,0-1,"Okay so, classification learning. Before we get into the details of that, I want to define a couple of terms. Because we're going to be throwing these terms out all throughout the lessons. And I want to make certain that we're all on the same page and we mean the same thing. But we're returning to this again and again and again. So, the first term I want to introduce is the notion of instances. So, instances, or another way of thinking about them is input. Those are vectors of valu, of attributes. That define whatever your input space is. So they can be pictures, and all the pixels that make up pictures like we've been doing so far before. They can be credit score examples like how much money I make, or how much money Michael makes. >> [LAUGH] How much money I wish I made, so on and so fourth. So whatever your input value is, whatever it is you're using to describe the input, whether it's pixels or its discrete values, those are your instances, the set of things that you're looking at. So you have instances, that's the set of"
IrM0MNi_Kxk,Classification Learning One - Georgia Tech - Machine Learning,1-2,"inputs that you have. And then what we're trying to find is some kind of function And that is the concept that we care about. And this function actually maps inputs to outputs, so it takes the instances, it maps them in this case to some kind of output such as true or false. This is the, the categories of things that we're worried about. And for most of the conversation that we're going to be having, we're going to be thinking about binary classification, just true and false. But the truth is, this would work whether there were three outputs, as we did with high school, college, or grad school, or whether there were 250 as we were contemplating for ages. But the main thing here is the concept, is the function that we care about that's going to map pictures, for example, to true or false. >> So okay, I get, I get the use of the word,"" instance"", right?"" Instance"" is just, like, a single thing that's out there. But I have an intuitive notion of what a concept is. How does that relate to this more formal notion? Like,"
IrM0MNi_Kxk,Classification Learning One - Georgia Tech - Machine Learning,2-3,"can we connect this to, kind of, the intuitive notion of what a concept is? >> I guess so. So a concept, I don't know. How would you want to put that? So a concept is something That, I mean were talking about is a notion of a function, so what it means formally is that you have some input, like a picture, and it immediately inputs maps anything in that input space to some particular defined output space, like true or false, or male or female, or credit, credit worthy or not. Intuitively a concept is an idea describes a set of things. OK, so we can talk about maleness or femaleness. We can talk about short and tall; we can talk about college students and grad students. And so the concept is the notion of what creditworthiness is, what a male is, what a college student is. >> Okay, I think I see that. So, so essentially if you want to think of tallness, the concept of tallness, one way to define it is to say, Well in general if you give me something I can tell you rather or not its [UNKNOWN] so it's going to map those somethings to am I tall or not. True or false. >> Right. Exactly and so"
IrM0MNi_Kxk,Classification Learning One - Georgia Tech - Machine Learning,3-4,"really when you think about any concept and we talk about this in generally [UNKNOWN] is effectively a way of saying is effectively a set of things. That are apart of that concept. So, you can have a concept of a car and if I gave you ""cars"" you would say these things are in it and if I gave you ""non-cars"" you would say they are not. And so a concept is, therefore by definition, a mapping between objects in a world and membership in a set, which makes it a function. >> Okay, that makes sense. >> Okay."
idSVqYRwCDA,Classification Learning Two - Georgia Tech - Machine Learning,0-1,"So with that, with that notion of a concept as functions or as mappings from objects to membership in a set we have a particular target concept. And the only difference between a target concept and the general notion of concept is that the target concept is the thing we're trying to find. It's the actual answer. All right? So, a function that determines whether something is a car or not, or male or not, is the target concept. Now this is actually important, right, because we could say that. We have this notion in our head of things that are cars or things that are males, or thing, or people who are credit worthy but unless we actually have it written down somewhere we don't know whether it's right or wrong. So there is some target concept we're trying to get of all the concepts that might map pictures or people to true and false. >> Okay, so if you trying to teach me what tallness is so you have this kind of concept in mind of these, these things are"
idSVqYRwCDA,Classification Learning Two - Georgia Tech - Machine Learning,1-2,"tall and these things are not tall. So you're going to have to somehow convey that to me. So how are you going to teach me? >> So that's exactly the, well that's what comes up with the rest of these things that we're defining here. >> Okay. >> So let me tell you what the next four things are then you can tell me whether that answers your question. >> Got it. >> How about that? OK, so we've got a notion of instances, input, we've got a notion of concepts. Which take input and maps into some kind of output. And we've got some target concepts, some specific function from particular idea that we're trying to find, we're trying to represent. But out of what? So that's where the hypothesis comes in. And in fact I think it's better to say hypothesis class. So that's the set of all concepts that you're willing to entertain. So it's all the functions I'm willing to think about. >> So why wouldn't it just be all possible functions? >> It could be all possible functions and that's a perfectly reasonable hypothesis class. The problem with that is that if it is all possible functions it may be very, very hard for you to figure out which function is"
idSVqYRwCDA,Classification Learning Two - Georgia Tech - Machine Learning,2-3,"the right one given finite data. So when we actually go over decision trees next I think it will be kind of clear why you need to pick a specific hypothesis class. >> Okay. >> So let's return to that in a little bit but it's an excellent question. So, conceptually in the back of your head until we, we come to specific examples, you can think of hypothesis class as simply being all possible functions in the world. On the other hand, even so far just the classification learning, we already know that we're restricting ourselves to a subset of all possible functions in the world, because all possible functions in the world includes things like x squared, and that's regeression. And we've already said, we're not doing regression. We're doing classification. So already hypothesis classes all functions we care about and maybe it's all classification functions. So we've already picked a subset. So we got all these incidences, got all these concepts, we want to find a, a particular concept and we've got this set of functions we're willing to look at. So how are we going to determine what the right answer is. So if you try to answer Micheal's question that we do that in machine learning is with"
idSVqYRwCDA,Classification Learning Two - Georgia Tech - Machine Learning,3-4,a sample or another name for which I prefer is a training set.
nF3r05N3Edc,Classification Learning Three - Georgia Tech - Machine Learning,0-1,"So what's a training set? Well a training set is a set of all of our inputs, like pictures of people, paired with a label, which is the correct output. So in this case, yes, this person is credit worthy. >> [LAUGH] >> Versus another example. >> You can tell I'm credit worthy based on my curly hair. >> Purely on the hair. >> Versus someone who has no curly hair and therefore is obviously not credit worthy. And if you get bunches and bunches of examples of input and output pairs, that's a training set. And that's what's going to be the basis for you figuring out what is the correct concept or function. >> I see. So instead of just telling me what tall means, you're going to give me lots of examples of, this is tall, this is not tall, this is tall, this is tall, this is tall, this is not tall. And that's the way that you're explaining what the target concept is. >> Right. So if you want to think about this in the real world, it's as if we're walking down the street and I'm pointing out cars to you, and non-cars to you,"
nF3r05N3Edc,Classification Learning Three - Georgia Tech - Machine Learning,1-2,"rather than trying to give you a dictionary that defines exactly what a car is. And that is fundamentally inductive learning as we talked about before. Lots and lots of examples, lots of labels. Now I have to generalize beyond that. So, last few things that we we talk about, last two terms I want to introduce are candidate, and testing set. So what's a candidate? Well a candidate is just simply the, a concept that you think might be the target concept. So, for example, I might have, right now, you already did this where you said, oh, okay I see, clearly I'm credit worthy because I have curly hair. So, you've effectively asserted a particular function that looks at, looks for curly hair, and says, if there's curly hair there, the person's credit worthy. Which is certainly how I think about it. And people who are not curly hair, or do not have curly hair are, in fact, not credit worthy. So, that's your target concept. And so, then, the question is, given that you have a bunch of examples, and you have a particular candidate or a candidate"
nF3r05N3Edc,Classification Learning Three - Georgia Tech - Machine Learning,2-3,"concept, how do you know whether you are right or wrong? How do you know whether it's a good candidate or not? And that's where the testing set comes in. So a testing set looks just like a training set. So here our training set, we'll have pictures and whether someone turns out to be credit worthy or not. And I will take your candidate concept and I'll determine whether it does a good job or not, by looking at the testing set. So in this case, because you decided curly hair matters, I have drawn, I have given you two examples from a training set, both of which have curly hair, but only one of which is deemed credit worthy. Which means your target concept is probably not right. >> So to do that test I, guess you can go through all the pictures in the testing set, apply the candidate concept to see whether it says true or false, and then compare that to what the testing set actually says that answer is. >> Right, and that'll give you an error. So, by the way, the true target, the true target concept is whether you smile or not. >> Oh. That does make somebody credit worthy. >> It does"
nF3r05N3Edc,Classification Learning Three - Georgia Tech - Machine Learning,3-4,"in my world. Or at least I, wish it did in my world. Okay. So, by the way an important point is that the training set and the testing set should not be the same. If you learn from your training set, and I test you only on your training set, then that's considered cheating in the machine learning world. Because then you haven't really shown the ability to generalize. So typically we want the training set to include lots of examples that you don't, the testing set, I'm sorry, to include lots of examples that you don't see in your training set. And that is proof that you're able to generalize. >> I see. So that, and that makes intuitive sense, right? So, like, if, if you're a teacher and you're telling me, you give me a bunch of fact and then you test me exactly that bunch of facts, it doesn't, I don't have to have understood them. I just can regurgitate them back. If you really want to see if I got the right concept, you have to see whether or not I can apply that concept in new examples. >> Yes, which is exactly why our final exams are written the way that they are written. Because you can argue that I've learned something by doing memorization, but the truth is you haven't. You've just memorized."
nF3r05N3Edc,Classification Learning Three - Georgia Tech - Machine Learning,4-5,"Here you have to do generalization. As you remember from our last discussion, generalization is the whole point of machine learning."
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,0-1,">> All right, so we've defined our terms, we, we know, what it takes to do, at least supervised learning. So now I want to do a specific algorithm and a specific representation, that allows us to solve the problem of going from instances to, actual concepts. So what we're going to talk about next are decision trees. And I think the best way to introduce decision trees is through an example. So, here's the very simple example I want you to think about for a while. You're on a date with someone. And you come to a restaurant. And you're going to try to decide whether to enter the restaurant or not. So, your, input, your instances are going to be features about the restaurant. And we'll talk a little bit about what those features might be. And the output is whether you should enter or not. Okay, so it's a very simple, straightforward problem but there are a lot of details here that we have to figure out. >> It's a classification problem. >> It's clearly a classification problem because"
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,1-2,"the output is yes, we should enter or no, we should move on to the next restaurant. So in fact, it's not just a classification problem, it's those binary classification problems that I said that we'd almost exclusively be thinking about for the next few minutes. Okay. So, you understand the problem set up? >> Yes, though I'm not sure exactly what the pieces of the input are. >> Right, so thats actually the right next question to ask. We have to actually be specific now about a representation. Before I was drawing squiggly little lines and you could imagine what they were, but now since we're really going to go through an example, we need to be clear about what is it mean to be standing in front of the restaurant. So, let's try to figure out how we would represent that, how we would define that. We're talking about, you're standing in front of a restaurant or eatery because I can't see the reliably small restaurant. And we're going to try to figure out whether we're going to go in or not. But, what do we have to describe our eatery? What do we have? What are our attributes? What are the instances actually made of? So, what in, or another way of putting it is, what are the features that we need to pay attention to that are going to"
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,2-3,"help us to determine whether we should yes, enter into the restaurant. Or no, move on to the next restaurant. So, any ideas Michael? >> Sure. I guess there's like the type of restaurant. >> Okay, >> Oh, is it tall or short, and is it a good credit risk? >> [LAUGH] >> Oh wait, no, no, no wait, I know. Like the Italian versus French, versus, you know, Vietnamese. >> So let's call that the type. So it could be Italian, it could be French, it could be Thai, it could be American, there are American restaurants, right? >> Sure. >> Greek, it can be, Armenian. It can any kind of restaurant you want to. Okay, good. So that's something that probably matters because maybe you don't like Italian food or maybe you're really in the mood for Thai. Sounds perfect. Okay anything else? >> Sure. How about whether it smells good? >> You know, I like cleanliness. Let's let's, or you know what, let's, let's be nice to our eateries and let's say atmosphere. >> Mm. Right because if there's, you know, no atmosphere, then it is going to be really hard to breathe."
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,3-4,">> That's exactly right. So is it fancy? Is it a hole-in-the-wall, which I'm going to spell HIW. Is it a hole-in-the-wall, umm, those sorts of things. The, you know? >> Casual, I guess, is another category. >> Casual. And so on, and so forth. You could imagine lots of things like that, but these things might matter to you and your date. Okay, so, we know the type of the restaurant that we have, we know whether it's fancy, whether it's casual, whether it's a hole in the wall. Some of the best food I've ever had are in you know, well-known hole in the walls. Those sorts of things. Anything else you can think of? >> Sure, Sometimes, I might use something like looking inside and seeing whether there's people in there and whether they look they're having a good time. >> Right. So that's an important thing. So let's just say If it's occupied. Now why might that matter in reality? Well it matters because if it's completely full and you may have to"
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,4-5,"wait for a very long time, you might not want to go in. On the other hand. If you're looking at a restaurant you've never heard of, and there's only two people in it, and it's Friday at 7 p.m. Maybe that says something about something. Maybe you want it to be quiet. You know, those sorts of things might matter. Okay, so, we've got type, we've got atmosphere, we've got occupied. Anything else you can think of? >> And I have been out of the dating market for a while, but I guess it could imagine, I could imagine how hard I am trying to work to impress my date. >> perfect. So do you have a hot date or not? Or, this is someone who you really, really, really want to impress and so, maybe it matters then, it's even more important whether it's a fancy restaurant or a hole in the wall, or whether it's French or whether it's an American restaurant. That make sense? I think that makes sense. Notice, by the way, that the first two sets that we have have multiple possible categories here. So it could be Italian, French, Thai, American, so on and so forth. Atmosphere is something that can have many, many possible values, but the last two things that we talked about were"
sjnV76u_Nvs,Example 1: Dating - Georgia Tech - Machine Learning,5-6,"all binary. Either it's occupied or it's not. Yes or no or, you have a hot date or you don't. And I think we could go on like this for a long time but, let's try to move on to maybe a couple of other features and then try to actually figure out how we may actually solve this."
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,0-1,">> Alright, so Michael. Last set of features that that's come up with three or four, three or four more features and then move on. >> Sure. >> So come up with a couple. >> Alright, so I could, sometimes I'll look at the menu that's posted outside, and I'll see if the, you know? How pricey it is. >> Okay, so cost. Right, so cost can be represented as discrete input. By the way, it could also be represented as an actual number. Right? We could say, look it's cheap, it's moderately expensive, it's really expensive or you could have a number which is the average cost of an entry. And it doesn't really matter for, for what we're talking about now but just some way of representing cost. Okay. Just give me one or two more features but I want to give me some features that don't have anything to do with the restraunt itself but might still be important. >> Hmm. >> because, by the way, hot date probably doesn't have anything to do with the restaurant itself. So, even though we've been talking the features of the restaurant. We've actually been picking up, at least, one feature that doesn't have anything to do directly with the restaurant itself."
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,1-2,">> Not to. So, whether I'm hungry? >> I like that. Here's another one. What's the weather like. Is it raining outside? >> Which is a different sense of atmosphere. >> Right. because if it's raining outside, maybe it's not your, your favorite choice but you don't want to walk anymore. Okay, so we have a ton of features here. We've gone through a few of them. Notice that some of the specifically have to do with the restaurant and some of them have to do with things that are external to the restaurant itself but you can imagine that they're all important. Or possibly important to whether you should enter into the restaurant or not. Agreed? And there's a bunch of features you could imagine coming up with that probably have nothing to do with whether you should enter into the restaurant or not. Like, how many cars are currently parked across the country. Probably doesn't have an impact on whether you're going to enter into a specific restaurant or not. Okay. So, we have a whole bunch of features and right now we're sticking with features we think that might be relevant. And we're"
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,2-3,"going to use those to make some kind of decision. So, that gets us to decision trees. So, the first thing, that, that we want to do is, we want to separate out what a decision tree is from the algorithm that you might use to build the decision tree. So the first thing we want to think about is the fact that a decision tree has a specific representation. Then only after we understand that representation and go through an example, we'll start thinking about an algorithm for finding or building a decision tree. Okay, are you with me? >> Yeah. >> Excellent. Okay, so a decision tree is a very simple thing. Well, you might be, might be surprised to know it's a tree, the first part of it. And it looks kind of like this. So, what I've drawn for you is example. Sample generic, decision tree. And what you'll see is three parts to it. The first thing you'll see is a circle. These are called nodes, and these are in fact, decision nodes. So,"
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,3-4,"what you do here, is you pick a particular attribute. [NOISE] And you ask a question about it. The answer to that question, which is its value for what the edges represent in your tree. Okay. So we have these nodes which represent attributes, and we have edges which represent value. So let's be specific about what that means. So here's a particular attribute we might pick for the top node here. Let's call it hungry. That's one of the features that Michael came up with. Am I hungry or not? And there's only two possible answers for that. yes, I'm hungry, true, or false, I am not hungry. And each of these nodes represent some attribute. And the edges represent the answers for specific values. So it's as if I'm making a bunch of decisions by asking a series of questions. Am I hungry? And if the answer is yes, I am hungry, then I go and I ask a different question. Like is it rainy outside?"
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,4-5,"And maybe it is rainy and maybe it's not rainy, and let's say if it isn't rainy then I want to make a decision, and so these square boxes here are the actual output. Okay so it's hungry, so you're hungry, yes, and it's not raining, so what do you do? So, let's just say you go in. True, I go in so, when it's, I'm hungry and it's not raining, I go in. >> And that, that true is answering a different question. It's not in the nodes I guess. So, in the leaves, the t and f means something different. >> That's right. It's the out, that's exactly right. The, the leaves, the little boxes, the leaves of your decision tree is your answer. What's on the on the edges are the possible values that your attribute can take on. So, in fact, let's try to, let's make that clear by picking a different by picking another possible attribute. You could imagine that if I am not hungry, what's"
F8oLgbLh_xo,Representation - Georgia Tech - Machine Learning,5-6,"going to matter a lot now is say, the type of restaurant, right. Which we said there were many, many types of restaurants. So, you know thai, I forget [CROSSTALK] >> Italian. >> Italian, and you know, something. >> French fries. >> And French Fries. So if I'm not hungry, then what matters a lot more is the type of restaurant, and so I'll move down this path instead and start asking other questions. But ultimately, no matter how I, what this decision tree allows me to do is to ask a series of questions and depending upon those answers, move down the tree, until eventually I have some particular ouput answer, yes I go in the resteraunt, or no I do not >> Ok this is still seeming a little abstract to me, can we, can we maybe work through a very concrete example. >> Yeah, I think that makes a lot of sense. >> Let's do a quiz. >> Ha, okay, let's do a quiz."
wk1mWB1fdqY,Representation Quiz - Georgia Tech - Machine Learning,0-1,"Okay, so we've now seen an abstract example of decision trees. So let's make certain that we understand it with a concrete example. So, to your right is a specific decision tree that looks at some of the features that we talked about. Whether you are occupied or not, whether the restaurant is occupied or not what type of restaurant it is. Your choices are pizza, Thai, or other. And whether the people inside look happy or not. The possible outputs are again binary either you don't go or you do go, into the restaurant. On your left is a table which has six of the features that we've talked about. Whether the restaurant is occupied or not, the type of restaurant, whether it's raining outside or not, whether your hungry or not. Whether you're on a hot and whether the people inside look happy, and some values for each of those. And what we would like for you to do is to tell us what the output of this decision tree would be in each case. >> Alright, so the decision tree here is a, it's"
wk1mWB1fdqY,Representation Quiz - Georgia Tech - Machine Learning,1-2,"a classifier, but we had another name. Oh, it's a concept. >> Yes. >> Alright, and each row of this is a different time that we're stopping at a restaurant, and the, the little values there summarize what is true about this particular situation. And, and you're saying we need to then trace through this decision tree and figure out what class is, okay yeah, that's what you said. Okay, I'm ready. Alright, perfect. Okay, that's the quiz, go."
JDLcwBR8Odc,Representation Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"You've got your answers. Let me tell you what we think the answers are. Now the nice thing about a decision tree sort of conceptually and intuitively, is that it really is asking a series of questions. So, we can simply look at these rows over here and the values that our features have and we can just follow down the path of the tree. So, in the first case. We have true. We have true for occupied, which means we want to go down the right side of the tree. And check on the type. So in the first case, the type is pizza. And so we go down the first branch and that means. We do not go down the tree. So, the output is no go. >> So, okay, so now, I got a different answer. So, I looked at this and I said happiness is true. And, the bottom box says happiness true, you go."
JDLcwBR8Odc,Representation Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,">> Right. So, you got the wrong, you got what I'm going to tell you is the wrong answer by going from the bottom of the tree up. The way decision trees work is you always start at the root of the tree. That is the very top of the tree. And you ask the questions in tho, in that order. >> It just seems like it would be faster to start at the bottom. >> Yeah but then you would never look at anything else in the tree. >> Good point. All right so. >> If you start at the bottom, you can't go up. Alright. So, okay, so let me see if I get this straight. So I'll, I'll do the, the second instance. The second instance, you say that we need to start at the top of the tree where it says occupied. And so now I look at the instance and the instance says that it's false for occupied, so we go down that left branch and we hit no go. Oh wait but now I haven't look at any of the other nodes. >> You don't have to look at any of the other nodes because it turns out that if it's not occupied you just don't go into a restaurant. So you're the type of person who doesn't like to be the only person in a restaurant. >> Got it, all right, so that's a no go. So"
JDLcwBR8Odc,Representation Quiz Quiz Solution - Georgia Tech - Machine Learning,2-3,"that's a no-go. That's an important point, Michael. Actually, you might also notice that this whole tree, even if you look at every single feature in the tree, only has three of the attributes. It only looks at occupied. Type. And happiness. >> I see. So hot date is sort of irrelevant which is good, because in this case it's not really changing from instance to instance anyway. >> True. And neither is hungry you might notice. >> Oh, I am kind of hungry. >> Although, I'm always hungry. Although raining does in fact change a little bit here and there. But it apparently it doesn't matter. >> I see. >> Because you always take an umbrella. >> Got it. >> Okay, so let's quickly do the other three and see if we we come to the same conclusion. >> Alright. Well all the instances that have occupied false we know those are no go, right away. >> Oh, good point. >> So we can do it kind of out of order. And the other ones are both occupied. One is tie and one is other. For the tie one we go. The other one, oh I see, for the other"
JDLcwBR8Odc,Representation Quiz Quiz Solution - Georgia Tech - Machine Learning,3-4,"one we have to look at whether there's happiness or not, and in this instance happiness is true. So we get on the right branch and we go. >> And we go. Exactly it. So we notice hot date doesn't matter, hungry doesn't matter and rainy doesn't matter. And the only thing that matters are whether you're occupied, what type of restaurant you're at and whether you're happy or not. Or whether the, the patrons in the restaurants are restaurant is, are happy or not. But, here's the other thing about this. It's not just about the features. Let's tie it back in to the other things, that we mentioned in the beginning. This, in our case, this table actually represents our testing set. It's the thing that we're going to look at to determine whether we were right or wrong. These are the examples that we're going to do to see whether we generalize or not. And this particular tree here is our candidate concept. So there's lots and lots and lots of other trees that we might have used. We might have used a tree that also"
JDLcwBR8Odc,Representation Quiz Quiz Solution - Georgia Tech - Machine Learning,4-5,"took, asked questions about whether it was rainy or not or asked questions about whether you were on a hot date or not. But we didn't. We picked a specific tree that had only these three features and only asked in this particular way. So what we're going to talk about next. Is how we might decide whether to choose this tree over any of the other possible number of trees that we might have chosen instead."
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,0-1,"Alright, so we understand at this point how to use these decision trees, but this is a class about machine learning, right? So we need to figure out how to make those decision trees happen as a result of processing a set of training data. So, it's not clear to me how we're going to make that leap. >> Let's see if we can figure it out together. So, I'm going to play a game with you, Michael, and if we do the game well. Then I think we'll have an idea of what a good algorithm might be for actually building a decision tree. So we're going to play 20 questions. You're familiar with 20 questions? >> Right, that's the game where I'm allowed to ask yes/no questions to try to guess something that you're thinking of, and if I take more than 20 of them, then I lose. >> Right, okay. So, here's what I'm going to do. I'm going to think of a thing, and, you ask me questions and I'm going to answer them and we'll see if you can guess what thing I'm thinking about. Okay, I've got something in my head. >> The first question, the typical first question is it animal, vegetable or mineral but that doesn't"
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,1-2,"seem like a yes/no question, so is it, is it an animal, or like a, a living creature. >> The answer is yes. >> Alright, is it a person? >> Is it a person? The answer is yes. >> Is it a famous person? >> Is it a famous person? That's a deep philosophical question, but I'm going to say yes. >> Is it a famous person that we both know in like directly. >> Oh, who we both personally know directly, I do not believe so. >> Yeah. >> So, the answer is no. >> Is it a living person? >> Living person, no. >> So it is a dead, famous person. Is the person famous for, say being in the music industry. >> The answer yes. >> Did this person live during the 20th century? >> The answer is yes."
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,2-3,">> Is the genre of music that the person was associated with, say hip hop or rap? >> No. >> Is the person a singer? >> Singer? Yes. >> Male or female, is the person female? >> Person female? No. That's ten questions, Michael. >> Yes, the, the clock is ticking down, but I feel like I have narrowed it down quite a bit at this point. Did the person die since you've become a professor? >> So, say in the last How long have you been a professor? >> Too forever it sounds like feels like. Let's see, recent death. And I'm going to say the answer is yes. >> Is the person's name Michael? >> The answer is yes. >> Alright, alright, I think I'm on to it. Is it Michael Jackson? >> No. >> Woo hoo! >> Of course, it's Michael Jackson. >> Alright, Thriller."
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,3-4,">> Yes, Michael Jackson is the answer. >> Alright. So that was, that was very fun. And I'm very glad that I was able to solve it. >> [LAUGH] >> But it's not clear to me how, this is going to give us an algorithm for building decision trees. >> Okay, so let's think about that for a second. So you asked a bunch of questions, and you asked them in a particular order. Right? So, here's a question I have for you. Why was the first question you asked me whether it was an animal or not? >> well, it seemed like I needed some way of narrowing down the space, and so I wanted to get as much information out of that question as I could to try to make progress towards figuring who it actually was. >> Right. So, animal is the first question and it was because it narrowed things down. So, your goal in asking questions was to narrow the possibilities, right? >> Sure, right because I only have 20 questions and then I'm, you know I'm out of it, so if I"
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,4-5,"asked questions like You know, if I had said--started with, Is it someone named Michael, that would have been really bizarre. >> Right, and if the answer was no, it's not clear that it would tell you anything at all. So, actually, that's an interesting point. You started with animal; you could have started with Michael. And if I had said yes, that would have told you something. But if I had said No, it wouldn't have told you hardly anything at all. Right? So animal is a better attribute, or feature, to ask about than Michael as a first question. Do you agree with that? >> Yeah, because it could have been like a stapler or something like that and then I, the Michael question would've been pretty silly. >> Exactly. So what about persons? So first you asked about animal. Then you asked about person. Why person? >> Right, because, because again it seemed like of the space of possibilities that I could think of person would help kind of again narrow things down. That I'd if it was the answer was yes, I would be able to focus there. If the answer was no I could focus some place else. >> Exactly. And so I"
qW3bOhW2W-s,Example 2: 20 Questions - Georgia Tech - Machine Learning,5-6,"think in fact we could, we have a general statement here. That each one of these questions. Person, famous, do we know this person, personally, so on and so forth. All make sense because they further narrow down the possibilities. And that bit about further is important. Because it implies that the usefulness of a question depends upon the answers that you got in the previous questions. So even though Michael is not a particularly good first question to ask, it's a perfectly reasonable twelfth question to ask or however far down it is, given that you already know this person's, this is an animal, a person, a famous person we don't know personally who's not living, who's into music, etc., etc., etc. Okay, that make sense? >> Yeah. >> Okay. So I think then, we have the hints of an algorithm. So let's try to write down that algorithm and, and see if it matches with our intuition."
nfWU1EwkwwU,Decision Trees Learning - Georgia Tech - Machine Learning,0-1,">> Okay, so, inspired by 20 questions let's try to write down exactly what it is that you did in going through your 20 questions to get your answer to discover Michael Jackson was the person I was thinking about. So, what is the very first thing you did? >> I tried to imagine a bunch of possible answers that you could be, could have in mind. And, I tried to think of a question that would help separate them into two roughly equal chunks. >> Okay, so what's the way of putting that in the language that we've been using for supervised learning and classification so far? >> Oh I see. So if I had known in advance, here's here's 200 things that you might ask me about. And what their, what their attribute values are. What would be a question that would split that set in half, right? So, instead of just imagining a bunch of things, if I actually had a list, which I do in the case of a training set. >> Alright, so the first thing you did is you picked the best attribute that you could think of. And, by the way, you said"
nfWU1EwkwwU,Decision Trees Learning - Georgia Tech - Machine Learning,1-2,"something very particular here. You actually defined what best is. You said, that best is the same thing as splitting things roughly in half. So let's revisit that in a moment. Okay, so the first thing you did is you picked the best atribute. You asked a question about it and then, depending upon the answer, you went and picked another attribute right? Does that seem fair >> Yeah. >> Okay. So, we think about decision trees, a way of talking about that is that you follow the path of the answer, and then lather, rinse and repeat. [LAUGH]. You went back and pick the best attribute, asked the question, followed the answer path, so on, and so on, and you kept doing that until what? >> Until, I narrowed the space of possibilities to, in this case, just one item. >> Right, so until you got to the answer. All right."
nfWU1EwkwwU,Decision Trees Learning - Georgia Tech - Machine Learning,2-3,"And that is an algorithm. So you pick the best attribute, and you actually define what best attribute was. You want to pick one that would somehow eliminate at least half of the things which you might worry about and keep the other half in play. You asked a specific question. You followed the path to that and then you went back and you picked another attribute and so on and so forth until you got an answer that you wanted to. That's an algorithm and that's an algorithm that we might use to actually build a decision tree. And the only difference between what you did and what you would do with learning a decision a tree is that, since you don't know in advance what the answer actually is going to be, because you don't know what specific object I might be thinking of, you have to actually follow all possible paths at each time and think of all possible best next attributes until you completely can answer any question. Does that make sense? >> I see. So, right, so instead of just playing the game interactively, I kind of imagine all possible ways it could go and build that whole flow chart, that whole tree."
nfWU1EwkwwU,Decision Trees Learning - Georgia Tech - Machine Learning,3-4,">> Right, so, let's see if we can do that with some pictures and I actually want to decide rather I really believe your definition of best. Okay? >> Sure. >> Alright, so, let's do that."
LthbKTZEyNg,Best Attribute Quiz - Georgia Tech - Machine Learning,0-1,"Alright, so let's take a moment to have a quiz where we really delve deeply into what it means to have a best attribute. So something Michael and I have been throwing around that term, let's see if we can define it a little bit more crisply. So, what you have in front of you are three different attributes that we might apply in our decision tree for sorting out our instances. So, at the top of the screen what you have is you have a cloud of instances. They are labelled either with red x or a green o, and that represents the label so that means that they are part of our training set, so this is what we're using to build and to learn our Decision Tree. So, in the first case you have the set of instances being sorted into two piles. There are some xs and some os on the left and some xs and some os on the right. And the second case you have that same set of data being sorted so that all of it goes to the left and none of it goes to the right. And in the third case you have that same set of data that's sorted so that a bunch of the xs end up on the left and a"
LthbKTZEyNg,Best Attribute Quiz - Georgia Tech - Machine Learning,1-2,"bunch of the os end up on the right. What I want you to do is to rank each one, where one is the best and three is the least best attribute to choose. Go."
R0OA5e1tFhA,Best Attribute Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay Michael. So, are you ready to give me a ranking >> Yes, yes, I think I am. >> Okay, well, if you give me a ranking then. >> So, did you say one was the best. >> One is the best and three is the least best. Alright, so I am really excited about the third cloud structure. The third attribute to be split on. Because, what it does. Is it takes all our x's and o's That need to have different labels and it puts them into two different buckets. One where they all get to be red x's and the other where they all get to be green o's. So I would say the far right one is ranked number one. >> I would agree with you and in fact I would say that infact we're done. >> Yeah, it's perfect. >> It is perfect, agreed. One is perfect. Or 3 is perfect in this case, because I gave it a one. >> Alright, so then, I think the worst one is also easy to pick, because if you look at the middle attribute, the attribute that's shown in the middle, we take all the data, and we put it all on the left. So we really have just kicked the can down the"
R0OA5e1tFhA,Best Attribute Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,"road a little bit. There's nothing. That this attribute splitting has done. So, I would call that the worst possible thing you could do. Which is to basically to do nothing. >> No, I think that's right. and, in fact, it really is doing nothing. >> Right. >> Okay. So what about the first attribute? >> So, I'm going to put that at, you know, if the first one is too hot and the middle one is too cold, I would say this one is, wait, no, no. [LAUGH] I was going down the Goldilocks path. So, so this one is sort of in between. In that it splits things so you have smaller sets of data to deal with, but it hasn't really improved our ability to tell the reds and the greens apart. So in fact, I'd almost want to put this as three also but I'll put it as two. >> Okay. I think an argument could be making it three. An argument could be made for making it two. Your point is actually pretty good, right? We have eight"
R0OA5e1tFhA,Best Attribute Quiz Quiz Solution - Georgia Tech - Machine Learning,2-3,"red things and eight green things up here. And the kind of distribution between them, sort of half red and, half red x's, half green o's, we have the same distribution after we go through this attribute here. So it does some splitting, but it's still, well you still end up with half red, half green, half x, half o. So, that's not a lot of help, but it's certainly better than doing absolutely nothing. >> Well is it though? I mean, it seems it could also be the case. That what we've done is that we're now splitting on that has provided no valid information, and therefore can only contribute to overfitting. >> That's that's a good point. That's a good point. So, do you want to change your answer to three? >> I don't know, what did you want the answer to be? It seems to me that the first one and the second one are just plain bad. >> They are just plain bad. The question is whether one is, more bad than the other. >> I, I don't know. I don't know how to judge. >> Well I'll tell you, I would accept either two or a three as an answer here. I think you can make an argument either way. And I think you actually made both arguments. >> That's very nice of you. >> So. >> Thank you. >> You're very welcome. So this is perfect. This is the House of Representatives and this is the Senate."
R0OA5e1tFhA,Best Attribute Quiz Quiz Solution - Georgia Tech - Machine Learning,3-4,">> [LAUGH] What do you mean they're? Oh. So, there you go. Okay. >> [LAUGH] Not exactly sure what you mean, but it seems somehow denigrating to our political system. >> It is not at all denigrating. It is, it is, I would call it incisive political satire."
-9TdpdjDtAM,Decision Trees Expressiveness AND - Georgia Tech - Machine Learning,0-1,"Okay.
So Michael, for the last 15 minutes or so we've been talking about decision
trees, sort of in the abstract without saying too much about the kinds of
functions they can actually represent. So, for the next few minutes or so I
want to talk a little bit about not just decision trees in the abstract, but
exactly how expressive they can be. Is that okay?
>> Yeah, I think that would be really helpful. >> I think so too. So in fact, I want to look
at a set of functions, and in particular I'm interested in
looking at Boolean functions. >> Boolean. >> So what's your favorite
simple Boolean function? >> Implication. >> What's your other favorite
simple boolean function? >> Well I like Nor. >> Right.
So what I just heard you say is you like And,
so let's do that one. >> Oh, that's great. That is my favorite. >> All right. So, in fact, let's do very simple And. So, how does And work, right? So, you've got two attributes. Let's say A and B. And, this expression,
A and B, is true when? >> When A and B are true. When they are both
true at the same time."
-9TdpdjDtAM,Decision Trees Expressiveness AND - Georgia Tech - Machine Learning,1-2,">> Right, exactly. So, how would you build a decision tree, given that there are only two attribute,
A and B, to represent that function? >> Okay so
I'd have a note that's A and B. And if that's true.
>> Nope, you're not allowed to do that. >> Oh. >> Every node can be,
have at most one attribute. >> All right well let's
let's put A in an attribute. >> Okay, so here's a little node. Let's call it A. >> Okay.
>> Now what? >> And well I mean, for it to be a node it needs to have
the little two branchy things. True and false. >> Okay. All right, so how about true on
the left and false on the right? >> Sure, as long as you label them. So, all right. So then A, if A is true,
okay, I don't know. But oh, but if A is false,
then we know that A and B must be false. Doesn't matter what B is. So we can just put a leaf under the F. >> That's correct. All right, I like that. >> Okay. What about when A is true? >> What, is that an F? >> That is an F, and
that is a minus sign for false. >> Oh, a minus sign. I get it, okay."
-9TdpdjDtAM,Decision Trees Expressiveness AND - Georgia Tech - Machine Learning,2-3,"I thought you were just not
done drawing the F yet. >> good.
All right. So, oh yeah. On the true side then,
I don't think we know. So I think we need to split on B also. >> Okay. >> So put a little B under there. >> All right, done. >> All right, and
then true-false split on B. All right and so
now we've got these two cases. So if B is false, then again,
it doesn't matter what A was but A turns out to be true. But it's still the, the, it should
be a minus sign underneath that. >> Okay. >> So it's not A and B is not true. But if A is true and
B is true then A and B is true. So there should be
a plus sign on the left. >> That's exactly right. >> Woo. >> So clearly decision trees proof by, we just drew it here,
can represent the Boolean function And. >> Sure.
>> [CROSSTALK]. >> You said something int,
you said something interesting, Michael. You said it doesn't matter
what A is if B is false. So what would happen if I switch,
A and B around. >> That's the same."
-9TdpdjDtAM,Decision Trees Expressiveness AND - Georgia Tech - Machine Learning,3-4,"So if B, okay, in the beginning,
we say, if B is false, it's false. If B is true, we check A. If A is false, then it's false. But if A is true, then it's true. So it actually still represents
exactly the same function, A and B. Oh, because A and B is collaborative. No, commutative. Yes?
No? Hello?
>> It's one of those things. It's commutative. As opposed to associative. >> As opposed to what? >> Associative. >> Well I mean it, it's that too. But I mean, it's the reason that you
can just switch those two things and it didn't make a difference is because
they play the same role in the function. >> That's true in, in terms of
representation of the decision trees. You know, it doesn't really matter
which attribute you pick or the order in which you do them. You might get a better tree or a worse
tree or a longer tree or a shorter tree. But for something simple like,
two valued And, it really just doesn't matter. >> Okay. >> kind of neat, huh? >> Yeah."
drna_Y3YNH0,Decision Trees Expressiveness OR - Georgia Tech - Machine Learning,0-1,"Okay, so we can do A and B. So, let's pick another function. What's your other favorite,
Boolean function of two variables? >> Well, if we're doing two attributes,
you know, or is the other really nice one. >> I like or. So, let's see. Do you think, now that we've shown that
we can do A and B, could we do A or B? >> I feel like we could do A or B. because there's that nice De Morgen's
Law relationship between them but but let's just, how about this,
can you erase the tags at the bottom? >> Like that? >> Oh, yeah but
that's not going to work, is it? So, so if B and A are both true, so the left branch, then the,
the, the leaf should be plus? >> Yes. And if B is true and
A is false then the tag should be plus. >> Yes. >> And if B is false, I want to say
false but we don't know because A could be true and A or B is true if
either of the two of them are true. >> Oh okay, so maybe the mistake here is just trying
to use exactly the same thing."
drna_Y3YNH0,Decision Trees Expressiveness OR - Georgia Tech - Machine Learning,1-2,"So let's just erase it. >> All right. >> And start from scratch. So what would you do
starting from scratch? >> I'd split on B again. >> Okay. >> True False or False True. >> True False. >> True False. >> All right, and now if B is true. We know that A or B is true, so
we can put a plus under the left side. >> Right. >> But if B is false. >> Mm-hm. >> Then we need to split on A. >> Okay. >> And if A is true, then we're golden,
we get the Or is true. And if A is false, then it is false. >> Very good, and
that represents A or B. >> That represents the function,
the logical function A or B, yeah. >> Right. What happens if I swap A and
B around, does it still work? >> I mean, my, my, since they're
collaborative or commutative. Since they're commutative I want to say
it shouldn't make a difference, but let's just double check that. So if A is true then the output's true."
drna_Y3YNH0,Decision Trees Expressiveness OR - Georgia Tech - Machine Learning,2-3,"If A is false and
B is true then the output's true. And if A and B are both false,
then the answer's false, yeah, totally. >> Excellent. And, you know, if I hadn't erased
it you would see that the two trees actually look very, very much alike. >> They're sort of mirror each,
of each other. >> If you just swapped around. Yeah the, yeah exactly,
they're mirrors of one another."
DFuFDfu-H4E,Decision Trees Expressiveness XOR - Georgia Tech - Machine Learning,0-1,"[LAUGH] Okay, let's pick one
more Boolean function to do. What function am I thinking of? >> XOR is always good. >> Let's do XOR. So what does XOR mean? Remind me. >> Okay.
XOR is exclusive or, which means it's true if A is true or
B is true, but not if they're both true, so it has elements of both or
and and in it. >> Right. >> And I think of XOR usually when I'm, when I'm, like,
playing with light switches in my house. If I have a, a light that's activated
by two different light switches, it's usually an XOR function. If one is up, the light's on,
if the other one's up, the lights on, but if they're both up,
the light goes back off. >> Right.
The other thing when I think of XOR is when people say or most of the time when
people say or, when they're talking, they mean xor. >> Really? >> Yeah.
So a lot of times when people say or in English, they really mean xor. They say, well do you want to go to the
movies or do you want to go swimming? Do want to eat chicken or
do you want to eat fish? And really, they're saying either or. >> I see, you want one or"
DFuFDfu-H4E,Decision Trees Expressiveness XOR - Georgia Tech - Machine Learning,1-2,"the other, but you can't have chicken
and fish or go swimming and the movies. >> No, those things are not
possible to do together. >> Got it. Okay.
>> All right, so how would you do XOR? We got, we still have our- >> Well, I would start with the- >> Or, because it's a lot like or. >> So, what would you want to do? >> Okay, so to do XOR,
we can split on A. >> Okay. >> And there's a true branch and
a false branch. And what happened with and
and or at this point is, there is at least one branch where
we actually knew the answer, at this point, but
I don't think that's true here. >> That's right. >> So, so if A is true,
the output might be true or false. It depends on B. And if A is false,
the output might be False or True. It depends on B. So I-
>> This is exactly right. So I guess in both cases we
still have to split on B. >> Okay.
All right. So, now it should be relatively easy in the sense that there's a separate
leaf for all possible inputs. And so we can just write
the XOR function on the bottom."
DFuFDfu-H4E,Decision Trees Expressiveness XOR - Georgia Tech - Machine Learning,2-3,"So if A and B are both true, then the
output is false because it's exclusive. If A is true and B is false, then it
should be true, because A is true. If A is false and B is true, then it
should be true because B is true. And if A and B are both false
then it should be false. >> That's right. And by the way,
if you were to think about it for a little while, it would probably
occur to you that's this tree is just a another representation
of the full truth table. >> Very nice. >> And in fact, if we wanted to do or
again, we could say, well I was very smart last time, but
I could actually write or like this. And then just fill out
the values at the bottom. If A is true and B is true, then yes. If A is true and B is false, then yes. If A is false and B is true, then yes. If A is false and B is false, then no."
DFuFDfu-H4E,Decision Trees Expressiveness XOR - Georgia Tech - Machine Learning,3-4,"And this is a perfectly legitimate a
decision tree to represent or because it basically is just another simple
representation of the truth table, but as we pointed out
when did last time, it's more of a decision
tree than we actually need. >> I can see that. >> Because in particular,
we don't actually need this. All right. So this little difference here between
writing out the entire truth table on the left, as we did for XOR, and not
having to write out the entire decision tree on the right for o,r actually isn't
going to turn out to matter when we try to do things either more complicated
or with more attributes that we did for the simple and, or, and XOR. Would you like to see? >> Yeah, that sounds really cool. >> Beautiful."
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,0-1,">> So, we saw before when we looked at AND and OR versus XOR that in the case of AND and OR we only needed two nodes but in the case of XOR we needed three. The difference between two and three is not that big, but it actually does turn out to be big if you start thinking about having more than simply two attributes. So, let's look at generalized versions of OR and generalized versions of XOR and see if we can see how the size of the decision tree grows differently. So in the case of an n version of OR. That is we have n attributes as opposed to just two. We might call that the any function. That is a function were any of the variables are true then the output is true. We can see that the decision tree for that has a very particular and kind of interesting form. Any ideas Michael about what that decision tree looks like? >> So, well. So going off of the way you described OR in the two case. We can start with that. And you."
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,1-2,"You pick Pick one of the variables. And if its true then yeah. Any of them is true since the leaf is true. >> What happens if its false? >> Well, then we have to check what everything that's left. [LAUGH] So then we move on to one of the other attributes like A2. >> mm hm. >> And again, if it's true, it's true and if it's false then we don't know. >> Look at A3. >> Good idea. This could take some time. >> Yes, oh that was actually an interesting point. Let's say if there were only three, we would be done. Right? >> Right. >> But wait, what if there were five? >> Then we need one more node. >> What if there were n? >> Then we need n minus 4 more nodes. >> Right, so what you end up with in this case is a nice little structure around the decision tree. And how many nodes do we need?"
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,2-3,">> Looks like one for each attribute, so that would be n. >> n nodes, exactly right. So we have a term for this sort of thing, the size of the decision tree is, in fact, linear. In n. And that's for any. Now what about an n version of XOR? >> Mm. So XOR is, if one is true but the other one's not true then it's true. And if they're both true. Yeah I don't. It's not clear headed. Generalize that. So why not hmm. >> So, while the usual general version of this we like to think of as parity. All parity is a way of counting, so there's usual two forms of parity that we worry about. Either even parity or odd parity. So let's pick one, it doesn't matter. Let's say. >> Odd. >> I like that, we'll do odd parity. And all that works out to be in this case is, if the number of attributes that are true is an odd number, then the"
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,3-4,"output of the function is true, otherwise it's false. Got it? >> Got it. >> Okay, so, how would we make that decision tree work? >> Ooh. Well, we got to split on something and there all the same, so let's split on A1 again. >> Okay. So what do we do if A1 is true, versus being false. >> We don't know much if A1 is true. We have to look at everybody else. >> Right. So let's look at A2. What if A2 is true versus false? >> Well if A1 and A2 are true then, then the output is going to be whatever the parity of all the remaining variables are. So you still have to do that. >> Uh-huh, yup. And I'm already running out of room, so let's pretend there's only three variables. What's the output? >> [LAUGH] All right, so the far left. Is there's three trues which is odd so the output is true. >> Yep."
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,4-5,">> The next leaf over, only two trues. A1 is true, A2 is true, but A3 is false, so that's two trues which is is even so the answer's false. >> Um-huh. >> Is this going to, is this pattern continuing? Now we've got. No, so then it's false again because we've got two trues and a false to get to the next leaf. >> Mm-hm. >> And we've got one true to get to the next leaf so that's true. Oh, that looks like XOR. >> It looks just like XOR. In fact, each one of these sub trees is kind of a version of XOR isn't it? Now what we have is, we have to do the same thing on the right. So we gotta redo A2, and we're going to be in the same situation before. And we're going to start drawing on top of each other because. >> [LAUGH] >> there's just not enough room. Hm, so, what's the answer to the one on the very right. Where all of them is false. All of them are false. >> So that's, an even number of trues. Zero is even. So that's false. Okay, so in the case where only A3 is true, it's true and we just keep going on and on and on again. Now imagine what would happen, in"
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,5-6,"fact let me ask you Michael, what would happen if we had four attributes instead of three. >> Then we would be really tired of this game. >> Yes, and I am already tired of this game so the question is, can you. >> We get a whole another, a whole other level of this tree. >> Yep. We have the, it just goes on and on and on and nobody wants to think about it anymore. [LAUGH] So, how many nodes do you think there are? >> Well, for three there was one, two, three, four, five, six, seven. Which seems suspiciously like one less than the power of two. >> Mm-hm. And that is exactly right. You need more or less 2 to the n nodes. Or. >> 2 to the n, maybe, minus 1. >> Yeah. So let's just say big O of 2 to the n. Everyone watching this is a computer scientist to they know what they're doing. Okay so, you need an exponential therefore, as opposed to linear number of nodes. >> Gad. >> Yeah, so you very, very quickly run out of room here. You very, very quickly have a really, really big tree because it's"
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,6-7,"growing exponentially. So, XOR is an exponential problem and is also known as hard. Whereas OR, at least in terms of space that you need, it's a relatively easy one. This is linear. We have another name for exponential and that is evil. Evil, evil, evil. And it's evil because it's a very difficult problem. There is no clever way to pick the right attributes in order to give you an answer. You have to look at every single thing. That's what make this kind of problem difficult. So, just as a general point, Michael, I want to make, is that we hope that in our machine learning problems we're looking at things that are more like any than we are looking at things that are more like parity. Because otherwise, we're going to need to ask a lot of questions in order to answer the, the parity questions. And we can't be particularly clever about how we do it. >> Though, if we were kind of clever and added another attribute, which is like, the sum of all the other attribute values, that would make it not so bad again. So maybe it's just a,"
KwMaBd3UitA,Decision Tree Expressiveness - Georgia Tech - Machine Learning,7-8,"it's just a kind of, bad way of writing the problem down. >> Well, you know, what they say about AI is that the hardest problem is coming up with a good representation. So what you just did is, you came up with a better representation, where you created some new pair, new variable. Let's call it B, which is just the sum of all of the As, where we pretend that I don't know, true is one and false is zero. This is actually a really good idea. It's also called cheating. [LAUGH] Because you [LAUGH] got to solve the problem by picking the best representation in the first place. But you know what? It's a good point, that in order for a machine running to work, you either need an easy problem or you need to find a clever way of cheating. So, let's come back and think about that throughout all the rest of the lessons. What's the best way to cheat?"
te5K2prTrhE,Decision Tree Expressiveness Quiz - Georgia Tech - Machine Learning,0-1,">> All right, so what that last little exercise showed is that XOR, in XOR parody, is hard. It's exponential. But that kind of provides us a little bit of a hint, right? We know that XOR is hard and we know that OR is easy. At least in terms of the number of nodes you need, right? But, we don't know, going in, what a particular function is. So we never know whether the decision tree that we're going to have to build is going to be an easy one. That is something linear, say. Or a hard one, something that's exponential. So this brings me to a key question that I want to ask, which is, exactly how expressive is a decision tree. And this is what I really mean by this. Not just what kind of functions it kind of represent. But, if we're going to be searching over all possible decision trees in order to find the right one, how many decision trees do we have to worry about to look at? So, let's go back and look at, take the XOR case again and just speak more generally. Let's imagine that we once again, we have n attributes. Here's my question to you, Michael."
te5K2prTrhE,Decision Tree Expressiveness Quiz - Georgia Tech - Machine Learning,1-2,"How many decision trees are there? And look, I'm going to make it easy for you, Michael. They're not just attributes, they're Boolean attributes. >> Thanks. >> Okay? And they're not just Boolean attributes, but the output is also Boolean. Got it? >> Sure. But how many trees? So it's, I'm going to go with a lot. >> Okay. A lot. Define a lot. >> Define a lot. So, alright, well, there's n choices for which node to split on first. >> Yeah. >> And then, for each of those, there's n minus 1 to split on next. So I feel like that could be an n factorial kind of thing. >> Maybe. I like that. >> And then, even after we've done all that, then we have an exponential number of leaves. And for each of those leaves, we could fill in either true or false. So it's going to be exponential in that too. >> Hm, so let me see if I got that right. So you said we have to pick each attribute at every"
te5K2prTrhE,Decision Tree Expressiveness Quiz - Georgia Tech - Machine Learning,2-3,"level. And so you see something that you think is probably going to be, you know? Some kind of commutatorial question here. So, let's say n factorial, and that's going to just build the nodes. That's just the nodes. Well, once you have the nodes, you still have to figure out the answers. And so, this is exponential because factorial is exponential. And this is also exponential. Huh. So let's see if we can write that down. So let me propose a way to think about this, Michael. You're exactly right the way you're thinking. So, let's see if we can be a little bit more concrete about it. So, we have Boolean inputs and we have Boolean outputs, so this is just like AND, it's just like OR, it's just like XOR, so, whenever we're dealing with Boolean functions, we can write down a truth table. So let's think about what the truth table looks like in this case. [SOUND] Alright, so, let's look at the truth table. So what a truth table will give me is,"
te5K2prTrhE,Decision Tree Expressiveness Quiz - Georgia Tech - Machine Learning,3-4,"for, the way a truth table normally works is you write out, each of the attributes. So, attribute one, attribute two, attribute three, and dot dot dot. And there's n of those, okay? We did this a little earlier. When we did our decision tree. When we tried to figure out whether I was on a hot date or not. And then you have some kind of output or answer. So, each of these attributes could take on true or false. So one kind of input that we may get would be say all trues. Right? But we also might get all trues, except for one false at the end. Or maybe the first one's false and all the rest of them are true, and so on, and so forth. And each one of those possibilites is another row in our table. And that can just go on for we don't know how long. So we have any number of rows here and my question to you is"
te5K2prTrhE,Decision Tree Expressiveness Quiz - Georgia Tech - Machine Learning,4-5,how many rows? Go.
z98Lr7105IM,Decision Tree Expressiveness Quiz 2 Quiz Solution - Georgia Tech - Machine Learning,0-1,"So, we're back. What's the answer Micheal? How many rows do we have? >> So if it was just one variable we're splitting on, then it need to be true or false, so, that's two rows. If it was two variables, then there's four combinations and three, would be eight, combinations. So, generalizing the end, it ought to be 2 to the n. >> That's exactly right, there are 2 to the n different rows. And, that's what always happen when we're dealing with n, you know, n attributes, n boolean attributes. There's always 2 to the n possibility. Okay, so I get just halfway there and I get to your point about, combinatorial choices, among the attributes. But ,that's only the number of rows that we have. There's another question ,we need to ask which is, exactly how big is the truth table itself? Alright, so here's the question for you. We know we have 2DN, different possible instances we might see. That is two to the end, different ways we might assign different values to the attributes. But, that still doesn't tell us how many decision trees we may have, or how many different functions we might have. So, if we have 2DN rows, here's my question. How many different ways might we fill out. This column over here of outputs? Remember, an output can be either true or false. Go. >> Okay, Michael, what's your answer? >> Alright. So. Again, a lot feels like a good answer, it's already written down on the left. But it's also wait, wait, may be we can quantify this. So if it were. Maybe one way to think about this is if each of the, each of those empty boxes there, is either true or false. It's kind of like a bit. And we're asking how many different bit patterns can we make? And in general, it's two to the number of positions, but here the number of positions is 2 to the n. So it ought to be 2, to the 2 to the n. Which is that the same as 4 to the n? >> No. >> Okay. >> But you're right. It's 2 to the 2 to the n. So it's a double exponential and it's not the same thing as 4 to the nth. It's actually 2 to the 2 to the nth. Now how big of a number do you think that is Michael? >> I'm going to go again to my go to place and just say a lot. >> It is, in fact, a lot and I'm"
z98Lr7105IM,Decision Tree Expressiveness Quiz 2 Quiz Solution - Georgia Tech - Machine Learning,1-2,"going, I actually, I'm going to look over here, and I'm going to tell you. That for even a small value of n, this gets to be a really big number. >> So for, for one, it's 2 to the 2 to the 1, which is 4. That's not a big number. >> That's true. What about two? >> For two, it's 2 to the 2 to the 2. So 2 to the 2 is 4, so it's 2 to the 4, which is 16. >> What about three? >> Alright, so that's two to the 8th, which is 256? >> Mm-hm. So that's growing pretty fast, don't you think? >> Sure, but those aren't big numbers yet. >> What if I told you, [LAUGH] that for n equals 6, 2 to the 2 to the n was, I'm going to start writing it, okay? 18466744073709551616."
z98Lr7105IM,Decision Tree Expressiveness Quiz 2 Quiz Solution - Georgia Tech - Machine Learning,2-3,">> Holy monkeys. >> Yes, that is in fact the technical term for this number, it's a holy monkey. It is a very, very big number. So 2 to the n grows very fast. We already called that evil. 2 to the 2 to the n is a double exponential and it's super evil. It grows very, very, very, very, very fast. So what's the point of this exercise, Michael? It's, it's to point that the space of decision trees, the hypothesis space that we've chosen, is very expressive because there's lots of different functions that you can represent. But that also means we have to have some clever way to search among them. And that gets us back to our notion of an algorithm with actually going to very smartly go through and pick out which decision tree. Because if we aren't very smart about it and we start eliminating whole decision trees along the way. Then we're going to have to look it to billions upon, billions upon, billions upon, billion upon, billion of possible decision choice."
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,0-1,"So now, we have an intuition of best, and how we want to split. We've, we've looked over, Michael's proposed, the high-level algorithm for how we would build a decision tree. And I think we have enough information now that we can actually do, a real specific algorithm. So, let's write that down. And the particular algorithm that Michael proposed is a kind of generic version of something that's called ID3. So let me write down what that algorithm is, and we can talk about it. Okay, so here's the ID3 algorithm. You're simply going to keep looping forever until you've solved the problem. At each step, you're going to pick the best attribute, and we're going to define what we mean by best. There are a couple of different ways we might, we might define best in a moment. And then, given the best attribute that splits the data the way that we want, it does all those things that we talked about, assign that as a decision attribute for node. And then for each value that the attribute A can take on, create a descendent of node. Sort the training examples to those leaves based upon exactly what values they"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,1-2,"take on, and if you've perfectly classified your training set, then you stop. Otherwise, you iterate over each of those leaves, picking the best attribute in turn for the training examples that were sorted into that leaf, and you keep doing that. Building up the tree until you're done. So that's the ID3 algorithm. And the key bit that we have to expand upon in this case, is exactly what it means to have a best attribute. All right so, what is exactly, what exactly is it that we mean by best attribute? So, there are lots of possibilities, that you can come up with. The one that is most common, and the one I want you to think about the most, is what's called information gain. So information gain is simply a mathematical way to capture the amount of information that i want to gain by picking particular attribute, funnily enough. But what it really talks about is the reduction in the randomness, over the labels that you have with set of data, based upon the knowing the value of particular attribute. So the formula's simply"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,2-3,"this. The information gain over S and A where S is the collection of training examples that you're looking at. And A, as a particular attribute, is simply defined as the entropy, with respect to the labels, of the set of training examples, you have S, minus, sort of, the expected or average entropy that you would have over each set of examples that you have with a particular value. Does that make sense to you, Michael? >> So what we're doing, we're picking an attribute and that attribute could have a bunch of different values, like true or false, or short, medium, tall? >> Right. >> And. >> And that's represented by v. >> Okay, each of those is a different v. And then we're saying okay, for over those leaves, we're going to do this entropy thing again. >> Mm-hm. >> And we right. So what, and what is entropy? >> entropy. So, we'll talk about entropy later on in the class"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,3-4,"in some detail and define it exactly and mathematically. And some of you probably already know what, what entropy is, but for those of you who don't, it's exactly a measure of randomness. So if I have a coin, let's say a two-headed coin. It can be heads or tails, and I don't know anything about the coin except that it's probably fair. If I were to flip the coin, what's the probability that it would end up heads versus tails? >> A half. >> It's a half, exactly, if it's a fair coin it's a half. Which means that I have no basis, going into flipping the coin, to guess either way whether it's heads or it's tails. And so that has a lot of entropy. In fact it has exactly what's called one bit of entropy. On the other hand, let's imagine that I have a coin that has heads on both sides. Then, before I even flip the coin, I already know what the outcome's going to be. It's going to come up heads. So what's the probability of it coming up with heads? It's. >> One. >> One. So that actually has no information, no randomness, no entropy whatsoever. And has"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,4-5,"zero bits of entropy. So, when I look at this set of examples that I have, and the set of labels I have, I can count the number that are coming up, let's say, red x's. Versus the ones that are coming up green o's. And if those are evenly split, then the entropy of them is maximal, because if I were to close my eyes and reach for an instance, I have no way of knowing beforehand whether I'm more likely to get an x or I'm more likely to get an o. On the other hand, if I have all the x's in together, then I already know before I even reach in that I'm going to end up with an x. So as I have more of one label than the other the amount of entropy goes down. That is, I have more information going in. Does that make sense, Michael? >> I think so. So, is there, can, maybe we can say what the formula is for this, or, or? >> Sure. What is the formula for it? You should remember. >> It's, if we have, well, I'm not sure what the notation ought to be with"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,5-6,"these S's but it has something to do with Log P log, no wait, it's P(log)P. >> Mm-hm. So the actual formula for entropy, using the same notation that we're using for information gain is simply the sum, over all the possible values that you might see, of the probability of you seeing that value, times the log of the probability of you seeing that value, times minus one. And I don't want to get into the details here. We're going to go into a lot more details about this later when we get further on in the class with randomize optimization, where entropy's going to matter a lot. But for now, I just, you have, I want you to have the intuition that this is a measure of information. This is the measure of randomness in some variable that you haven't seen. It's the likelihood of you already knowing what you're going to get if you close your eyes and pick one of the training examples, versus you not knowing what you're going to get. If you close your eyes and you picked one of the training examples. Okay? >> Alright. So, well, so, okay, so then in the practice, trees that you had given us before, it was the"
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,6-7,"case that we worked, we wanted to prefer splits that I guess, made things less random, right? So if things were all mixed together, the reds and the greens, after the split if it was all reds on one side and all greens on the other. Then each of those two sides would have very, what? They would have very low entropy, even though when we started out before the split we had high entropy. >> Right, that's exactly right. So if you, if you remember the, the, three examples before. One of them, it was the case that all of the samples went down the left side of the tree. So the amount of entropy that we had, didn't change at all. So there was no gain in using that attribute. In another case, we split the data in half. But in each case, we had half of the x's and half of the o's together, on both sides of the split. Which means that the total amount of entropy actually didn't change at all. Even though we split the data. And in the final case, the best one, we still split the data in half, but since all of the x's ended up on one side and all of the o's ended up on the other side, we had to entropy or no randomness left whatsoever. And that gave us the maximum amount of information gain."
IX0iGf2wYM0,ID3 - Georgia Tech - Machine Learning,7-8,>> So is that how we're choosing the best attribute? The one with the maximum gain? >> Exactly. So the goal is to maximize over the entropy gain. And that's the best attribute.
iBvBbbStx5Y,ID3 Bias - Georgia Tech - Machine Learning,0-1,">> So, we've got a whole bunch of trees we have to look at, Michael. And were going to have to come up with some clever way to look through them. And this get's us back, something that we've talked about before, which is the notion of bias. And in particular, the notion of inductive bias. Now, just as a quick refresher, I'm want to remind you that there is two kind of biases we worrying about when we think about algorithms that are searching through space. One is what's called a restriction bias. The other is called preference bias. So a restriction bias is nothing more than the hypothesis set that you actually care about. So in this case, with the decision trees, the hypothesis set is all possible decision trees. Okay? That means we're not considering, y equals 2x plus 3. We're not considering quadratic equations. We're not considering non-boolean functions of a certain type. We're only considering decision trees, and all that they can represent. And nothing else. Okay? So that's already a restriction bias"
iBvBbbStx5Y,ID3 Bias - Georgia Tech - Machine Learning,1-2,"and it's important. Because, instead of looking at the infinite number uncountably infinite number of functions that are out there, that we might consider. We're only going to consider those that can be represented by a decision tree over in, you know, all the cases we've given so far discreet variable. But a preference bias is something that's just as important. And it tells us what source of hypotheses from this hypothesis set we prefer, and that is really at the heart of inductive bias. So Michael, given that, what would you say is the inductive bias of the ID3 algorithm? That is, given a whole bunch of decision trees, which decision trees would ID3 prefer, over others? >> So, it definitely tries, since it's, since it's making it's decisions top down. It's going to be more likely to produce a tree that has"
iBvBbbStx5Y,ID3 Bias - Georgia Tech - Machine Learning,2-3,"basically good splits near the top than a tree that has bad splits at the top. Even if the two trees can represent the same function. >> Good point. So good splits near the top. Alright. And you said something very important there Michael. Given two decision trees that are both correct. They both represent the, the function that we might care about. It would prefer the one that had the better split near the top. Okay, so any other preferences? Any other inductive bias on the, on the ID3 algorithm. >> It prefers ones that model the data better to ones that model the data worse. >> Right. So this is one that people often forget: it prefers correct ones to incorrect ones. So, given a tree that has very good splits at the top but produces the wrong answer. It will not take that one over one that doesn't have as good splits at the top, but does give you the correct answer. So that's really,"
iBvBbbStx5Y,ID3 Bias - Georgia Tech - Machine Learning,3-4,"those are really the two main things that are the inductive bias for ID3. Although, when you put those two together, in particular when you look at the first one, there's sort of a third one that comes out as well, which is ID3 algorithm tends to prefer shorter trees to longer trees. Now, that preference for shorter trees actually comes naturally from the fact that you're doing good splits at the top. Because you're going to take trees that actually separate the data well by labels, you're going to tend to come to the answer faster than you would if you didn't do that. So, if you go back to the example where we went before, where one of the attributes doesn't split the data at all, that is not something that ID3 would go for, and it would in fact create a longer and unnecessarily longer tree. So it tends to prefer shorter trees over longer trees. So long as they're correct and they give you good splits near the top of the tree."
LgLMX5nYfN4,Decision Trees Continuous Attributes - Georgia Tech - Machine Learning,0-1,"Alright. So, we've actually done pretty well. So through all of this, we finally figured out what decision trees actually are. We know what they represent. We know how expressive they are. We have an algorithm that let's us build the decision trees in an effective way. We've done just about everything there is to do with decision trees, but there is still a couple of open questions that I want to think about. So, here's a couple of them and I want you to, to think about and then we'll discuss them. So, so far all of our examples that we've used. All the the things we've been thinking about for good pedagogical reasons. We had not only discreet outputs but we also had discreet inputs. So one question we might ask ourselves, is what happens if we have, continuous attributes? So Michael, let me ask you this. Let's say we had some continuous attributes. We weren't just asking whether someone's an animal or whether they're human or whether it's raining outside or we really cared about age"
LgLMX5nYfN4,Decision Trees Continuous Attributes - Georgia Tech - Machine Learning,1-2,"or weight or distance or anything else that might have a continuous attribute. How are we going to make that work in a decision tree? >> Well, I guess the literal way to do it would be for something like age to have a branching factor that's equal to the number of possible ages. >> Okay, so that's one, one possibility. So we stick in age and then we have one. 1.0, we have one for 1.1, we have one for 1.11, we have one for 1.111 >> Ahh, I see. Alright. Well, at the very least, okay. Heheheh. What if, what if we only included ages that were in the training set? Presumably there's at least a finite number of those. Oh, we could do that. We could just do that, except what are we going to do then when we come up with something in the future that wasn't in the training session. >> Oh, right. Can we look at the testing set? >> No were not allowed to look at the testing set. That is cheating, and not the kind of good cheating that we do when we pic good representation."
LgLMX5nYfN4,Decision Trees Continuous Attributes - Georgia Tech - Machine Learning,2-3,">> Okay, fair enough. Well we could, we could Ranges. What about ranges? Isn't that the way we cover more than just individual values? >> Give me an example. >> Say ages you know, in the 20s. >> Okay, so, huh. How would we represent that with a decision tree? Let's say in the 20s. Age. >> How we do that. >> You could do like age, element sign, bracket. >> 20. >> 20 comma 21, or, or 29 or 30 right per end. >> Yeah it's too much. Why don't I just say age Is between less is, let's see, greater than or equal to, 20 and, less than 30. And just draw a big oval for that. Alright? So that's a range, so that's all numbers between, 20 and 30 inclusive of 20 but not 30 Right. >> Yeah. >> And what's good about that is that's a question. You are either in your"
LgLMX5nYfN4,Decision Trees Continuous Attributes - Georgia Tech - Machine Learning,3-4,"20s or you are not. So, the output of that is actually true or false. >> So, I guess the good news there is that now we know how to evaluate attributes like that because we have a formula from ID3 that tells you what to do. But seems like there's an awful lot of different ones to check. >> Right, and in fact if it's truly a continuous variable, there are in principal an infinite number of them checked. But we can do now the sort of cheating you wanted to do before. We can just look at the training set, and we could try to pick questions that cover the sorts of data in the training set. So, for example, if all of the values are in the 20s, then there is no point of even asking the question. You will start just split instead upon values that were, say less than 25 or greater than 25, and you could imagine all kinds of ways where you might do that. You might look at all of the values that show up in the training set, and say well, I am going to do a binary search. So, I am just going to create an attribute for Less than half of whatever is in the training set or greater than half of whatever the range is in the training set. Does that make sense? >> Yeah, that's clever."
LgLMX5nYfN4,Decision Trees Continuous Attributes - Georgia Tech - Machine Learning,4-5,">> Right. Thank you. I just made that up on the spot. Okay, so you do those sorts of things and that's how you would deal with continuous attributes. That brings me to a next question, I'm going to actually do this as a quiz because I want an answer from our audience."
8VG2dCvsAXE,Decision Trees Other Considerations Quiz - Georgia Tech - Machine Learning,0-1,"So, here's the next question I want to ask you, simple true or false question. Does it make sense to repeat an attribute along any given path in the tree? So, if you we pick some attribute like A, should we ever ask a question about A again? Now, I mean something very specific about, by that. I mean, down a particular path of the tree, not just anywhere else in the tree. So, in particular, I mean this. So, I ask a question about A, then I ask a question about B, and then I ask a question about A again. That's the question I'm asking. Not whether A might appear more than once in the tree. So, for example, you might have been the case where A shows up more than once in the tree, but not along the same path. So, in the second case over here, A shows up more than once, but they really don't really have anything to do with one another because once you've answered B, you will only ever ask the question about A once. So, my question to you is,"
8VG2dCvsAXE,Decision Trees Other Considerations Quiz - Georgia Tech - Machine Learning,1-2,does it make sense to repeat A more than once along a particular path in the tree? Yes or no? Answer the question.
U90LuOEQEnA,Decision Trees Other Considerations Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay, Michael, what's the answer? >> So, alright. Does it make sense to repeat, an attribute along a path in the tree? So, it seems like it could be no, [SOUND] in that, you know, if we're looking at attributes like, you know, is a true, then later we would ask again is a true because we would already have known the answer to that. >> Right, and by the way, information gain will pick that for you automatically. >> It doesn't have to be a special thing in the algorithm, if, if, you consider, an attribute that you've already split on, then you're not going to gain any information, so it's going to be the worst thing, to split on. >> Exactly. >> Alright, but it, >> Okay, doing good. >> But it seems like maybe you're trying to lead us on because ,this we're in the continuous attributes portion of our show. >> Okay, well what's the answer there? Is the answer not also false? >> Well we wouldn't want to ask the same question, about the same attribute. So, we wouldn't have age, between 20 an 30, and then later ask again, age ,between 20 and 30. But ,maybe we want to ask, you know, given that we are less than 20, we're, are we teenagers or not, so we might"
U90LuOEQEnA,Decision Trees Other Considerations Quiz Solution - Georgia Tech - Machine Learning,1-2,"have a different range, on age later in the tree. >> So, that's exactly right, Michael. So, the answer is no, it does not make sense ,to repeat an attribute along a path of the tree, for discrete, value trees. However, for continuous [UNKNOWN] attributes, it does make sense. Because, what you're actually doing, is asking a different question. So, one way to think about this, is that the question is age in the 20's or not. Is actually ,a discreet valued attribute that you've just created, for the purposes of the decision tree. So, asking that question doesn't make sense but asking a different question, about age, does in fact make sense. So ,once you know, that you are not in the 20's you might ask well am I less than, 20 years old? Maybe a teenager or am I greater than 40. How old am I, 44? Greater than 44, in which case, I'm old. >> So if it's, if you ask, [LAUGH] the tree that you drew isn't quite right though, right? >> Yeah, it is. >> because, if you go down the false branch, it means you are less than 20. >> No, I can be greater than 30. >> Oh, good one."
U90LuOEQEnA,Decision Trees Other Considerations Quiz Solution - Georgia Tech - Machine Learning,2-3,">> Yes, I'm very clever, or at least I accidentally got it right. One of the two, it's the same thing. Okay, so there you go."
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,0-1,">> So, we've answered the thing about continuous attributes. Now, here's another thing. When do we really stop? >> When we get all the answers right. When all the training examples are in the right category. Class. >> Right, so the the answer in the algorithm is when everything is classified correctly. That's a pretty good answer, Michael. But what if we have noise in our data? What if it's the case that we have two examples of the same object, the same instance, but they have two different labels? Then this will never be the case. >> Oh. So, then our algorithm goes into an infinite loop. >> Which seems like a bad idea. >> So we could have, we could, we could just say, or we've run out of attributes. [LAUGH] >> [LAUGH] Or we've run out of attributes. That's one way of doing it. In fact, that, that was, that's going to have to happen at some point, right? That's probably a slightly better answer. Although that doesn't help us in the case where we have continuous attributes and we might ask an infinite number of questions. So we probably"
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,1-2,"need a slightly better criteria. Don't you think? >> Hm. >> So, what got us down this path, was thinking about what happens if we have noise. Why would we be worried about having noise anyway? >> Noise anyway. Well, I guess the training data might have gotten corrupted a little bit or maybe somebody copied something down wrong. >> Right, so since that's always a possibility, does it really make sense to trust the data completely, and go all the way to the point where we perfectly classify the training data? >> But Charles, if we can't trust our data, what can we trust? >> Well, we can trust our data, but we want to verify. [LAUGH] The whole point is generalization. And if it's possible for us to have a little bit of noise in the data, an error here or there, then we want to have some way to deal to handle that possibility, right? >> I guess so. >> So, what will we do? >> [LAUGH] I mean, we actually have a name for this, right? When you get really, really, really good at classifying your training"
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,2-3,"data, but it doesn't help you to generalize, we have a name for that. >> Right. That sounds like overfitting. >> Exactly. We have to worry about overfitting. So you can overfit with the decision tree too? >> Yeah. What, you don't believe that? >> No, no, no. I was, I was being naive, I was being, I know that you can overfit a decision tree. [LAUGH] I was just. >> [LAUGH] Yeah but your [SOUND] is the [SOUND] that you use when you're, when you're like, I don't believe what you just said Charles, but I'm going to go along with it anyway, because I have to get off the phone soon. >> [LAUGH] Fair enough. I'll try to, I'll try to have a different personality then. >> [LAUGH] Okay, step one, have a different personality with maximal information gain. Okay, so we don't want to, we don't want to overfit. So we need to come up with some way of overfitting. Now the way you overfit in a decision tree is basically by having a tree that's too big, it's too complicated. All right. Violates Occam's Razor. So, what's a kind of, let's say, modification to something like ID3"
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,3-4,"to our decision tree algorithm that will help us to avoid overfitting? >> Well last time we talked about overfitting, we said cross-validation was a good way of dealing with it, which, it allowed us to choose from among the different, say degrees of the polynomial. >> Right. >> So maybe we could do something like that? I don't know. Try all the different trees and, see which one has the lowest cross validation error? Maybe there's too many trees. >> Maybe, but that's a perfectly reasonable thing to do, right? You take out a validation set. You build a decision tree, and you test it on the, on the validation set and you pick whichever one has the lowest error in the validation sect, that's one way to avoid it. And then you have, don't have to worry about this question about stopping, you just grow the tree on the training set minus the validation set until it does well on that. And you check it against the crossvalid, you check it against the validation set, and you pick the best one. That's one way of doing it, and that would work perfectly fine. There is another way you can do it that's more efficient. Which is, you"
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,4-5,"do the same idea validation, except that you hold out a set and as you, everytime you decide whether to expand the tree or not, you check to see how this would do so far in the validation set. And if the error is low enough, then you stop expanding the tree. That's one way of doing it. >> So is there, is there a problem in terms of, I mean if we're expanding the tree depth for search wise, we could be at, you know, we could be looking at one tiny little split on one side of the tree before we even look at any, anything on the other side of the tree. >> That's a fine point. So how would you fix that? >> Maybe expand breadth first? >> Yeah, that would probably do it. Anything else you could think of? Well, so, you could do pruning, right? You could go ahead and do the tree as if you didn't have to worry about over-fitting, and once you have the full tree built, you could then do a kind of, you could do pruning. You could go to the leaves of the tree and say, well, what if I collapse these leaves back up into the tree? How does that create error on my validation set? And if the"
qDMh645ph0Q,Decision Trees Other Considerations - Georgia Tech - Machine Learning,5-6,"error is too big, then you don't do it. And if it's very small, then you go ahead and do it. And that should help you with overfitting. So, that whole class of ways of doing it, is called pruning. And there's a whole bunch of different ways you might prune. But pruning, itself, is one way of dealing with overfitting, and giving you a smaller tree. And it's a very simple addition to the standard ID3 algorithm."
dE7bgpf0okQ,Decision Trees Other Considerations  Regression - Georgia Tech - Machine Learning,0-1,"So another consideration we might want to think about with decision trees but you're not going to go into a lot of detail but I think might be worth at least mentioning is the problem of regression. So, so far we've only been doing classification ,where the outputs are discreet, but what if we were trying to solve something that looked more like x squared or two x plus 17, or some other continuous function. In other words, a regression problem. How would we have to adapt decision trees, to do that? Any ideas Michael? >> So these are now continuous outputs, not just continuous inputs. >> Right, maybe the outputs are all continuous, maybe the outputs are discrete, maybe they're a mix of both. >> Well it certainly seems like out rule of using, information gain is going to run into trouble because it's not really clear how you measure information on these continuous values. So, I guess you could measure error some other way. Well we're not, it's not, it's"
dE7bgpf0okQ,Decision Trees Other Considerations  Regression - Georgia Tech - Machine Learning,1-2,"not error right it's tryin to measure how mixed up things are? Oh so ,maybe something like variance? Cause in a continuous space you could talk about you know, if there's a big spread of, in the values that, that would be measured by the variance. >> Oh good. So what you really have now is a question about splitting. What's the splitting criteria? Maybe [CROSSTALK] >> I guess there's also an issue of, of what you do in the leaves. >> Right. So, what might you do in the leaves? >> I guess you could do some sort of more standard kind of fitting algorithm. So, like, report the average or, or do some kind of a linear fit. [SOUND] >> Is any number of things you can do. By the way ,that's worth pointing out on the, on the output that if we do pruning like we did before, we have errors, we did actually say when we talked about that how you would report an output. Right? If you don't have a clear answer where everything is labeled true or everything is labled false, how do you pick? So something like an average would work there. >> I don't know, I mean, it seems like it depends on what we're trying to measure with the tree. If the tree"
dE7bgpf0okQ,Decision Trees Other Considerations  Regression - Georgia Tech - Machine Learning,2-3,"is, we're trying to get as many right answers as we can, then you probably want to do like a vote in the leaves. >> Right, which ,at least, if the only answer is true or false, that would look more like an average I guess. Right, so you pick, you do a vote. So we do a vote, so we do pruning. We do have to deal with this issue of the output. Somehow ,and something like a vote mixing. And here, when you have a regression, then I guess average is a lot like voting. >> Yeah, in a continuous phase. >> Yeah. So either way we're doing a kind of voting. I like that."
khM2LClDSs4,Decision Trees Wrap up - Georgia Tech - Machine Learning,0-1,"Hi Michael, so that covers Decision Trees >> Excellent. >> So, since you are the one who is listening, you get to tell me what we have learned today? >> Well, we learned about the Decision Tree representation, we learned the top down algorithm for inducing a Decision Tree. And we call that ID3 >> All right. So we got a representation, we got a top down learning algorithm ID3. >> We learned about the, the expressiveness and the bias. >> Right. So those are 2 separate things, we learned about the sort of expressiveness. And we learned about the bias of ID3. >> And we gave one, so is this specific to ID3? We, we looked at one specific way of deciding on splits, which was to do this maximum information game."
khM2LClDSs4,Decision Trees Wrap up - Georgia Tech - Machine Learning,1-2,">> Right. So we talked about in general,um, what are good attributes or what are best attributes. So, information gain is one way of doing it. As one example. And, by the way, this notion of best attribute is something we'll end up returning to sometimes explicitly, and sometimes implicitly, throughout the entire course. And lastly, I feel like we talked about the problems with over-fitting and how in the Decision Tree context, you can prune back the tree to avoid over-fitting. >> Over-fitting is an issue. Over-fitting is always an issue and we came up with a couple of strategies for dealing with over-fitting in the context of Decision Trees. Okay! So we've learned everything there is to know about Decision Trees, there's nothing else to know. >> [LAUGH] Somehow I find that hard to believe. >> Yeah, there's a lot there and the students will get a chance to learn even more as they do the assignments. >> Cool. >> Excellent. All right Michael, thank you. >> Sure, look forward to the next chat."
D8PNnttuGZk,Regression Quiz - Georgia Tech - Machine Learning,0-1,">> Hey Charles, how you doing? >> I'm doing just fine Michael, how are you doing? >> I'm doing pretty well, thanks. I'm happy to get a chance to tell you about something today. >> Excellent, and what is it you're going to tell me about? >> We're going to talk about regression. >> Like, progression? [LAUGH]. >> No, regression. So, let me tell you about regression. So we are, in this section of the class, talking about supervised learning. And Supervised learning, in supervised learning we can take examples of inputs and outputs and based on that we are going to be able to take a new input and predict the corresponding output for that input, right. So this, this covers all of this, this the things we are talking about in the context of supervised learning, right. >> Right. >> Now, what makes regression special subtopic. We are going to be talking about mapping continuous inputs to outputs. As opposed to, what was the other thing that we were mapping, what other kinds of outputs did we think about? >> Well, we had discrete outputs and continuous outputs. >> Right, and so this is going to"
D8PNnttuGZk,Regression Quiz - Georgia Tech - Machine Learning,1-2,"be the focus on continuous. So regression seems like sort of an odd word. It doesn't really kind of fit for this. So often I think about regression as. So this is, this is me being all sad and sort of reverting back to a childhood state. And that's, you know, that's in the psychological sense, that's what regression refers to. But it turns out that, that's not what it means in this setting. But the story by which those things became linked, I think, is kind of interesting. So let me tell you about that. Okay. So, this is a picture of you Charles. >> [LAUGH] Okay. I'll accept that. >> You can tell it's you because he's really tall. And you're, you're a fairly tall man. I know you don't think of yourself that way, but you think of everyone else as being short which is really the same thing. >> Fair enough. >> Alright, so let's say that this is Charles. Let's say that this is someone of average height. Just someone at random. >> Mm-hmm. >> So now, let's pretend, Charles, that you have children. >> I do have children. >> All right. So let's, that's okay but we can just pretend, and we want to ask the question what would you expect the average height"
D8PNnttuGZk,Regression Quiz - Georgia Tech - Machine Learning,2-3,"of your children to be? Would you expect it to be sort of, you know, sort of Charles' height? Or average height or may be somewhere between. So let's let's actually ask this as a quiz."
XA9vnKoz44A,Regression Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay, Charles, so what do you, what do you think about this? >> Wait, how old are my children? >> Let's say what their adult height is going to be. >> I would expect them to be a little bit smaller than me. >> A little bit smaller than you? >> Mm-hmm. >> So, so their, the average height, their average height of your children, you would you say it would be like an average height person? Or like your height or sort of in between? >> In between. >> In between. All right. So it turns out that if you actually do this, you measure people's heights and you measure the heights of their children, that that is in fact what you tend to see. That very, very tall people, like you tend to have taller than average children. But the height is between. It actually regresses to the mean. And here we really do mean regresses in the sense of going back to this kind of more primitive state that, if you think about average height people, as being like your ancestors, then, you know, you as a, as a very tall person tend to have kids that that tend regress back"
XA9vnKoz44A,Regression Quiz Solution - Georgia Tech - Machine Learning,1-2,"toward that average value that sort of, more older, more ancient value. So does that that make some sense to you? >> That makes some sense. But one comment and one question. Comment, that is awesome because I've always actually wondered what regresses to the mean actually means. The second, what prevents us from all being the same height then? >> Yes, so what, what seems to be happening is that there's a kind of a noisy process and some people turn out to be taller, but then the, then the next generation there's a little bit of a history effect in people stay taller, but it tends to drift back towards the mean. So it's, so it's, it's sort of like a random walk, to some extent. >> Oh, that actually kind of makes sense."
zQLP2UQDND0,Regression and Function Approximation,0-1,"Alright, so what does this have to do with function approximation or regression. So how does this notion of regression of falling back toward the mean have to do with this idea of approximating functions, mapping inputs to outputs, it seems kind of odd. So it turns out that the relationship is, here's the, here's the connection between them. I'm going to draw a graph and on this axis will be the parent height. And on this axis will be the average child height. So if we plot these against each other, let's let me put the mean up here. Let's say that this is mean height for the population. And now say that you know pair, we sort of imagine that parents of average height will have children of average height. But parents that are really tall, like that hypothetical person from before, will have children that are taller than average but not as tall as themselves. And similarly people that are very"
zQLP2UQDND0,Regression and Function Approximation,1-2,"let's say of smaller stature will have children that are also you know short. And, but not quite as short again closer to the mean. And it turns out that you have this, this very nice linear relationship between these quantities, and, there's an important aspect to this. Which is that the slope of this line is less than one, it's two thirds. Right. If the slope of this line was one, what would that mean Charles? >> That would mean that everybody's children had the, would, the same height of their parents. >> Right, right, and so that's exactly right, and so but if this slope is less than one, like it is, it turns out to be in, in real populations. Then what's happening is the children are little shorter than the parents. Children of taller parents are shorter than they are. And the children of short parents are taller than they are. And that's the fact that this is less than one is what makes it regression to the mean. Now this, this was worked out in I believe in"
zQLP2UQDND0,Regression and Function Approximation,2-3,"the late 1800s and it was just such a beautiful way of connecting all these different quantities together. To kind of think of them as being related in this functional way. That people said, oh this is really great. I'm going to use this idea of regression. And what they started to mean actually was this not this idea of regression to the mean. But this idea of finding a, a mathematical relationship based on a bunch of measurements of points. So this term ended up getting misused. But that's the term that we have now. So regression now refers to not this idea of collapsing back towards, towards the mean, but, the idea of using functional form to approximate a bunch of data points. Isn't that weird. >> That's pretty cool. >> There's another example of this sort of idea where where a reasonable word, like, like regression which we're referring to some physical thing in the, in the world due to experiments like psych experiments at this point became this mathematical concept where the name doesn't really fit anymore, like there isn't really anything regressing in what we're doing. >> Mm-hm."
zQLP2UQDND0,Regression and Function Approximation,3-4,">> There's another, really important example that we're going to get to the later in the course. Do you, do you know what I'm thinking of Charles? >> No. >> So reinforcement learning is my field of study. And often your field of study. >> Often. >> Often. And it turns out that reinforcement learning doesn't mean what the words mean anymore. That this was a concept that the psychologist used to explain what they were observing. And then some mathematicians, well let's call them computer scientists, took the word themselves, started to use it and used it wrong, but now it stuck. [LAUGH] And regression is another example like that. They, the word is sort of being used wrong, but it stuck and that's what we're going to use. >> This explains why every time I have a conversation with a psychologist about reinforcement learning, we talk past each other. >> Yes, they get very confused. I tried it to tell them upfront that's not really what I mean, but I'm going to use the words anyway, but it still confuses them. >> Hmm."
Kto_QBCR9q0,Linear Regression,0-1,"Alright, so, one of the things that's very helpful about regression is that in many ways it's very simple to visualize, it's very simple to think about what some of the issues are and all the various topics in machine learning that are really important to understand and sometimes are difficult concepts really do come up in a fairly easy to understand way. So what I'd like to do now is to step through an example Of doing some regression and to point out what some of the pitfalls are and how they're generally handled in the machine learning context. So, this graph that I put up here, is, we just made these numbers up, but it's supposed to tell us a, a little bit about housing prices. So let's imagine that we're off to buy a house and What we notice is that there's lots of different houses on the market, and there are lots of different, sizes, right. So ,the square footage of the house can vary. And in this case the houses that I visited can be between, about 1,000 to 10,000 square feet. And of course, as you get bigger houses, you tend to get more, the, the"
Kto_QBCR9q0,Linear Regression,1-2,"prices tend to go up, too. Alright, so the price that the house cost is, tends to rise with the size of the house. So, what I've done here is I've plotted as a little x say a set of nine houses that I've observed. Start off over here with a house that's a 1,000 square feet and cost a $1,000? I don't know what year this happened in. And we end up with a house that is 10,000 square feet and cost about $6,000. Again, I don't. This is not true in Providence Rhode Island, I'll tell you that. >> Are you sure? >> Yeah, I'm pretty sure. >> Yeah, it's really not true in Atlanta Georgia. >> So Alright... So, so, so imagine that this is the relationship we observe. But now we want to answer a question like, Well, what happens If we find a house on the market and it's about $5,000, what do you think a fair price for that would be? So what do you, what do you think, Charles? Looking at this, what do you think a fair price for a 5,000 square foot house would be? >> Apparently about $5,000. >> About, $5,000. Right. So, how did you do that?"
Kto_QBCR9q0,Linear Regression,2-3,">> I looked at the graph, I went over to 5,000 square feet at the x-axis and I went up. Until I found ,where one of the x's was on the y axis and I said, oh, that's about 5,000 square feet. >> Well, but there was no corresponding point for that, so you had to interpolate or something ,uh, based on the points that were there you had to kind of imagine what might, might be happening at the 5,000 square foot mark, right? >> That's true, although this one was a little easy because at 4,000 and 6,000 square feet, they were almost exactly the same. >> Mm, and so that, to you, made it feel like there was probably ,um, that's probably the level where things in this range would be. >> Yeah. >> Okay. Alright, that seems kind of reasonable. So sure, though what we're going to do in this case is actually try to find a, a function that fits this. >> Mm-hm. >> Alright ,so what we can do is actually say, well what if there is a linear relationship. What would be the best linear function that captures the relationship between the size and the cost. So ,what I have here is, it turns out of all the possible"
Kto_QBCR9q0,Linear Regression,3-4,"linear functions, this is the one that minimizes the squared error, the squared deviation, between these x points and the corresponding position on green line. So it finds a way of balancing all those different errors against each other and that's the best line we've got. Now in this particular case, it's interesting right, because if you put your idea of 5,000 square feet. Look what this line predicts. It's something more like $4,000, right. Do you see that? >> I do. That is doesn't seem right to me. >> It doesn't, yeah, it doesn't really look like a very good fit. But it does at least capture the fact that there is increasing cost with, with increase in size. >> That's true."
dewLtKqna04,Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"Alright. So it's worth asking, how do we find this best line? So again there's an infinite number of lines. How do we find one that fits these points the best. And again we're defining best fit. As the one that has the least squared error, where the error is going to be some of the distances between these x points and the green line that we, that we fit. I'm not even sure that this really is the best fit in this case. I just kind of hand drew it. So, okay. So is this something that we, that we would want to solve by hill climbing which is to say, we kind of pick the. The slope and the intercept of the line, and we just kind of try different values of this until it gets better and better and then we can't get any better, and we stop. Can we do this using calculus? Can we use random search, where we just like, pick a random M, pick a random B, and see if we're happy with it? Or is this the sort of thing where we probably would just go and ask a physicist because it involves, like, continuous quantities, and we're discrete people? And that's the correct answer. All right. So let's actually go through that exercise and derive how we do that. because it's not so bad in two dimensions and it generalizes to higher dimensions as well. >> Okay. >> So it turns out that we can use calculus to do this, I am not going to step through the two-variable example for reasons that I am embarrassed to say. But I am going to show you a different example. So imagine that what we're trying to do is that we've got a bunch of data points, and we're trying to find the best constant function, right? So the best function that has the form, the value of the function for any given X is always the same constant, C. So if our data looks like this, we got a bunch of X's and a bunch of Y's, then what we're going to do, we're going to say for any given value of C, any given constant, we can have an error. What's the error going to be? The error is going to be the sum over all of the data points. Speaker 1: The square difference between that constant we chose and what"
dewLtKqna04,Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,"the actual yi value is. So that's why. >> Michael. >> These differences here. Yes, Charles. >> Can I ask you a question? >> Sure. >> Why are we doing sum of squares? >> There is many different error functions and sometimes called a, a relative concept called the loss function. There is lots of difference once that could work, you can do the absolute error, you can do the squared error, you can do various kinds of squashed errors where you know. The errors count different depending on how, how much deviation there is. It turns out that this one is particularly well behaved because of this reason that I'm explaining now that that because this error function is smooth as a function of the constant C, we can use calculus to actually find the minimum error value. But there's lots of other things that could work and they actually do find utility in various different machine learning settings. >> Okay. >> So just now using the chain rule, if you want to find how do this error function output change as a function of input c. We"
dewLtKqna04,Quiz Quiz Solution - Georgia Tech - Machine Learning,2-3,"can take the derivative of this sum you know, bring the two over. Times this, times the derivative of the inside, which is negative one in this case. And now this gives us a nice, smooth function saying what the error is as a function of c. And if we want to find the minimum, what do we want to do to this quantity? >> Set it equal to zero, because that's what I remember from Calculus. >> That's right. So in particular if the error you know, the error function is a nice smooth thing the derivative is negative and then zero and then positive. When it hits zero that's when the thing has bottomed-out. Alright. So now we just need to solve this, this equation for c. So we have one equation and one unknown. Alright, so that gets us this. But, this quantity, it's just the constant added to itself n times. So it's n times c. We move that to the other side. We get n times c. N is the number of data points as you recall. Is the sum of the yi's. We divide"
dewLtKqna04,Quiz Quiz Solution - Georgia Tech - Machine Learning,3-4,"two by n and what do we see? So what is it Charles? >> The best constant is the average of all your y's. >> Great, it's the mean. The mean comes back. Right, so in the case of finding the best constant here, we just have to average the y, the y's together and that catches thing that minimizes the squared air. So squared air is this really nice thing because it tends to bring things like mean back into the picture. It's really very convenient. And, it generalizes to higher, higher order of function tier, not higher functions, but more variables like, like lines. Sorry. Lines that have some, some non constant slope. By doing the same kind of process and things actually work really nicely."
JAMf1QWpcWs,Order of Polynomial,0-1,"Alright, so now let's, let's get back to our data set that we were looking at before. So again, the ideas that we're, we're going to try to find a way of predicting the value for various points along the way on this curve. And one thing we could do is find the best line. But we also talked now about finding the best constant. Turns out these all belong to a family of functions that we could fit. Which are functions of this form. Alright. We've got x is our input and what we're going to do is we're going to take some constant and add that to some scaled version of x times some scaled version of x squared plus some scaled version of x cubed, all the way up to some order k. And we've talked about k equals zero, the constant function. And k equals one, the line. But there's also k equals two, parabola. Would it probably be a good choice at this particular case? >> Yes. >> It does seem like it's got, sort of, curvy downy nature, right? >> Mm hm. >> It's going up and it's kind of flattening out and maybe we could imagine that it starts coming down again? At least, over the course of these points, it doesn't come down again but at least it sort of"
JAMf1QWpcWs,Order of Polynomial,1-2,"flattened out. So let's take a look at that. Let's take a look at the. The best parabola to fit this. Alright, so, so here we go. We've got the, the best line now, the best constant function which is just the average. We have the best line with some slope to it. That's the green one. We have now the best parabola and look at it, it does, it does a nice job, right? Kind a gets, gets tucked in with all those other points. so, so what do you think? Is this the best way of, of capturing this. This particular set of points? >> Well, if the only thing we care about is minimizing the sum of squared error, my guess is that the parabola has less squared error. >> Yeah. It ha, there's more degrees of freedom so at the worst we could have just fit the parabola as a line. Right. We can always just set any of these coefficients to, to zero. So if the best fit to this really was a line. The best fit to this data point was a line, then the parabola that we see here wouldn't have any curve to it. So,"
JAMf1QWpcWs,Order of Polynomial,2-3,"yeah. Our arrows going down. Hm, As we have gone from order zero to order one to order two. So can you think of any other way getting there in order to getting down even more. >> How about order 14 million. >> Interesting, while in this particular case, given the amount of data that we have, we can't go past the number of data points, yeh after that. They're really unconstrained. >> Okay. Then how about order nine? >> Order nine is a good idea. But just to give you an idea here, we're going to step up a little more. This is order four and look at, look at how lovely it can actually capture the flow here. That's, very faded. Order six and in fact the best we can do here is of the, of the, sorry. The most, the highest order that, that works is order eight. And, son of a gun, look what it did. It hit every single point dead on in the center. Boom. Boom. Boom. Boom. It used all the degrees of freedom it had to reduce the error to essentially zero. >> Excellent. >> So [LAUGH], one could argue that this is a really good idea. Though, if you look at what happens around 9000,"
JAMf1QWpcWs,Order of Polynomial,3-4,"there's some craziness. Do you see that? >> I do. >> At the Yeah, the To try to get this particular parabola to hit that particular point, it sent the curve soaring down with an up again. >> We also did that between 6500 and 8500, it sent [CROSSTALK]. >> Yes good point >> [UNKNOWN] [CROSSTALK] >> Right, right, that's right went off the top of the plot. So Yeah, that's kind of [INAUDIBLE]. But let's just, just to show that we really are, as we have more degrees of freedom we're fitting the error better. Let me show you what it looks like, the amount of error for the best fit for each of these orders of k. Alright and so, so what you see when we actually plot the, the squared error, this function that we're trying to minimize. As we go from order zero to order one, order two, order three, order four, order five, all the way to eight. By eight, there is no error left because it nailed every single point. So you know its kind of a good, nut it doesn't feel quite right like the curves that we're looking there looked a little bit crazy."
zA5QNkJspxY,intro to charles and michael,0-1,"All right, so let's, let's do a quiz. Give you a chance to kind of think about what where are these trade-offs are actually going to be. So we're going to pick the degree for the housing data, and your choices are going to be the degree zero, one, two, three, or eight. So a constant, that's the first choice. Or a line that has some slope that, you know, sort of increases with the data, that's your second choice. Or it could be we use a degree two parabola. So sort of goes up and then levels off. Or you can it might be a little hard to see but here's a cubic that that goes up flattens out a little bit and then rises up again at the end. Or we could go with the full monty, the octic. You can see that might not be spelled correctly. That actually has enough degrees of freedom that it can hit each of these points perfectly. Like that. >> The authority line. >> [LAUGH] Good, you got that in. Hi Michael.
>> Hey Charles, how's it going? >> It's going quite well,
how's it going with you? >> Good.
Good. >> Good Good. So, today I thought we would talk
a little bit about the philosophy of Machine Learning. >> Oh, I hate philosophy. >> I don't like it much either,
although I am a doctor of philosophy. >> Oh, that's very impressive. >> Aren't you a doctor
of philosophy too? >> I am, it's kind of impressive. >> It is kind of impressive. So what we wanted to kind of get across
today was a little bit about why we, the class is structured the way it is. What the different parts are. And maybe go a little bit of back and forth about what we think you should
be getting out of the course. That seem reasonable? >> Sure. >> Okay.
Well, so, first off, by the way, before we get
started, I wanted to thank you for coming down to Atlanta, and
joining me in these beautiful, studios. >> Well, it's, it's,
it's very nice to be here. Thank you for inviting me. >> Oh, no, no, thank you for
coming, Michael. >> Thank you for
asking me to do the course. This has been a lot of fun. >> Oh, the whole point was to be able
to do the course with you, Michael. We like each other, and that's one of
the things that we want you to get, want to get across in this class,
because we like machine learning. We've a lot of stuff in common, but I'm
not sure we completely agree on the most"
zA5QNkJspxY,intro to charles and michael,1-2,"important parts of machine learning and
why we do the things that we do. >> Hm, all right. >> So
I think people in the outside world, Michael, would claim that you're
more theoretical than I am. >> In theory. >> In theory, and
I'm more practical than you are. >> Practically. >> At least in practice. And hopefully some of that tension
will come out in the class. But I think in order to see why
that tension works that way, you have to understand
what machine learning is. So, Michael. >> Right. >> What's machine learning? >> It's about proving theorems. >> [LAUGH] No. >> No.
>> I would not say it's about proving theorems, although proving theorems is
often important in machine learning. >> I agree with that. >> Okay.
>> So we're on the same page. >> We're partially on the same page. What is machine learning? >> What is machine learning? >> Give me a definition. >> So it is computational statistics. How's that for a definition? >> That is a definition. It is wrong on so many levels. However, a lot of people would
agree with that statement. They would say that machine learning
is really just applied statistics. >> Not applied statistics. Computational statistics. >> Computationally applied statistics."
zA5QNkJspxY,intro to charles and michael,2-3,"I don't like that definition. I think that it's a bit too narrow. I think that machine learning
is about this broader notion of building artifacts,
computational artifacts, typically. That learn over time
based on experience. And then in particular,
it's not just the act of building these artifacts that matter,
it's the math behind it. It's the science behind it. It's the engineering behind it,
and it's the computing behind it. It's everything that goes into building
intelligent artifacts that almost by necessity have to learn over time. You buy that? >> Yeah, so you, you have data, and
you do analysis of the data and try to glean things from the data. And you used, various kinds of
computational structure to do that, so, computational statistics. >> I don't think that's
computational statistics."
LQbxOm_L5OM,Pick the Degree Quiz - Georgia Tech - Machine Learning,0-1,"So Charles, how would we go about trying to figure this out? >> How would we go about trying to figure this out? >> Yeah, what do you think? Which one would you choose and how would you choose? >> so, well that's a good question. Well just given what you, what you've given me, I'm going to ask. I think smartly guess, that probably k equals 3, is the right one, and >> K equals 3 >> And I'll tell you why. It's because zero, one and two seem to make quite a few errors. >> Mh-hm >> Three does a pretty good job but doesn't, doesn't over commit to the data. >> Hm. >> And that's the problem with eight, is that eight says, you know, the training data that I have is exactly right and I should been and moved heaven and earth in order to, to match the data. And that's probably the wrong thing, certainly if there's any noise or, or anything else going on in the data. >> Right. So it sort of seems like it's overkill,"
LQbxOm_L5OM,Pick the Degree Quiz - Georgia Tech - Machine Learning,1-2,"especially that it's doing these crazy things between the points. Whereas the cubic one, even though it clings pretty close to the points, it stays between the points, kind of between the points. >> Yeah. >> Which seems like a really smart thing. So yeah so, so that turns out to be the right answer but let's actually let's actually evaluate that more concretely."
nGcMl03LPC0,Polynomial Regression,0-1,"Alright. So we talked through how it works when you've got you're trying to fit your data to a constant function, to a zero order polynomial. But let's, let's at least talk through how you do this in the more general case. This is, this is what I've been doing to, to fit various curves to the data at least implicitly. So, what we're really trying to do is we've got a set of data, x and y. Set n, n examples of x's and their corresponding y's. And what we're trying to find is these coefficients, C0, C1, C2, C3. Let's say if we're trying to do cubic regression where C0 gets added to C1 times x, which gets added to C2 times x squared. Which gets added to C3 times X cubed and we're trying to get that to look a lot like y. Now we're not going to get to exactly equal y but let's pretend for a moment that we could. We have a bunch of these examples and we want it to work for all of them. So we can arrange all of the, all these"
nGcMl03LPC0,Polynomial Regression,1-2,"constraints, all these equations into matrix form. If you're familiar with linear algebra. So the way that we can write this is here are the, here are the coefficients that we're looking for, the C's, and here are what we're going to multiply them by. We're going to take the X one and look at the zeroth power, the second power, the third power. And that equation I'll use my hands cause that's I always, I always need to use my hands when I do matrix multiplication. So you're going to across here and down there to multiply these and add. And that needs to correspond to y1. And same thing this now the second row. Multiplied by these coefficients. Need to give us our y2 and so forth. Alright. So if we arrange all these x values into a matrix, and we'll call it, you know, x. And then we have these other guys. And we'll call this w, like the coefficents. Obviously w stands for coefficent. And we"
nGcMl03LPC0,Polynomial Regression,2-3,"want that to sort of equal This vector of y's. And we basically just need to solve this equation for the w's. Now, we can't exactly solve it because it's not going to exactly equal, but we can solve it in a least squares sense. So let me just step through the steps for doing that. Alright, so let's, so here's how we're going to solve for w. So what we're going to do is premultiply by the transpose of x. Both sides. I mean really what we wanted to do at first is if we are solving for Y, we need to multiply by the inverse of X, but this isn't really going to be necessarily well behaved. But if we pre mulitplied by the X transpose then this thing is going to have a nice inverse. So now we can pre multiply by that inverse. All right. Now, conveniently because this has a nice inverse, the inverses cancel each other. [NOISE] We get that the weights we're looking for can be derived by taking the x matrix times its own transpose, inverting that, multiplying by x transpose and then multiplying it by the y. And that gives us exactly the"
nGcMl03LPC0,Polynomial Regression,3-4,"coefficients that we need To have done our polynomial regression. And it just, it just so happens that we have some nice properties in terms of these x transpose x. Not only is it invertible, but it does the right thing in terms of minimizing the least squares. It does it as a projection. Now, we're not going to go through the process by by which we argue that this is true. >> Does it have something to do with calculus? >> It most likely has something to do with calculus. And we'll get back to calculus later. But in this particular case we can, we're just using projections and linear algebra. And most importantly the, the whole process is just we take the, the data we arrange it into this matrix with whatever sort of powers that we care about. And then we just compute this quantity and we're good to go. >> Okay."
0URPuafk9Tg,Errors Quiz - Georgia Tech - Machine Learning,0-1,"Alright, now, part of the reason, we can't just solve these kinds of problems by solving, a system of linear equations and just being done with it, the reason we have to do these squares is because of the presence of errors. The training data that, that we are given, has errors in it. And it's not that we're actually modelling, a function, but ,the thing that we're seeing is the function plus some, you know, some error term on each piece of data. So, I think, it's reasonable to, to think about where did these errors come from? So, I don't know, what do you think ,Charles, why, why is it we're trying to fit data, that ,has error in it, can't we just, can't we just have no errors? [LAUGH] >> I would like to have no errors. Certainly ,my code, has no errors. [CROSSTALK] well, so let's see where might errors come from. So, they could come from, sensor error, right? Just ,somehow you're, you're getting inputs and you're getting outputs and that output's, being read by, some machine or by a camera or by something and you just, there's just error in the way that you read the data. Just an error in the sensors."
0URPuafk9Tg,Errors Quiz - Georgia Tech - Machine Learning,1-2,">> Alright, can you think of other ways. I guess, I guess ,in this case you're imagining that the data came by actually measuring something, with the machine. So that, that makes, a lot of sense. What other ways, can we put together the data? >> I don't know I could think of a bunch. I mean the error, well, the errors could come, maliciously. There could be some, something out there, that is trying to give us bad data. >> Alright, that seems like a possibility, that, when the data set was collected, let's say that we're collecting, various, Oh, maybe if I. Oh, this happens, this happens a lot. So, so, if you're trying to collect data from other Computer Science departments and you're trying to put together, some kind of collection of, you know, how much do you spend on your. Graduate students ,say,uh, sometimes ,these departments will actually misrepresent the data and give you give you, things that are wrong. Because, they don't want to tell you the truth, because they're afraid of what you are going to do. >> Yeah, I've noticed that everyone does that except, for Georgia Tech and Brown University. >> Yeah, there are highly honest and reputable universities in my experience."
0URPuafk9Tg,Errors Quiz - Georgia Tech - Machine Learning,2-3,">> Yeah, that's what I feel. >> well, another time that you can get data, is if somebody, is, copying stuff down. So, what about sort of the idea of a transcription error. >> Uh-huh. >> So we're just, you know, we've copied everything, but, you know, there's, there's just some of the, some of the lines that got filled in just got mistyped. >> Yeah, and you think ,that's different from sensor error? >> Well, it's, it's maybe a slightly different kind of sensor error, right? So ,sensor errors were actually saying there's something physical, that's being measured and there's just noise in that. Transcription error, is similar except it's a person. [LAUGH] >> Mm. >> Right? The, the there's a little blips in the person's head and they can do, it can be a very different kind of error. You can get, like transpositions of digits, maybe instead of ,um, just you know, noise. >> Okay, how bout, how bout one more? How about ,uh, there's really, just noise, in the process. So how about that, that we took in input X, but there's something else going on in the world, that we weren't measuring, and so the output ,might depend on other things besides, simply"
0URPuafk9Tg,Errors Quiz - Georgia Tech - Machine Learning,3-4,",the input that we're looking at. So what would be an example of that? >> So an un-modeled influence, might be, well, if we're. >> [CROSSTALK] Let's look at the housing data. >> That's what I, that's what I was thinking exactly. So ,in the housing data ,we were just trying to relate, the size of the houses, to the price, but, there's a lot of other things like change of the houses to the price and >> Location, location. >> Location and location, right those are three really good reasons, that are not in the particular regression, that we did, that could ,actually influence the prices. So right, that and, you know, the quality of the house and who, who built it, and, you know, the colors, the colors. >> Even, even, even time of day, or what the interest rates were that morning, versus the, what people thought they might be the next day. Who knows? >> Right and so all these different things are being considered ,in that particular regression, so we're just kind of imagining ,that it's noise, that it's just having a, a ,uh, bumpy influence on the whole process. >> Sure. >> All right. So, so what I'd like you to do is select ,the ones that you think actually are important, the"
0URPuafk9Tg,Errors Quiz - Georgia Tech - Machine Learning,4-5,"ones that, that, that could actually come up, when you're using machine learning and regression to solve your problems."
sFO2ff-gTh0,Cross Validation,0-1,"All right, and if you know, if you were paying attention as we were going through this, these are all very common, and realistic things. So, you know these are all true, these are all sources of error. And this is why we really need to be careful when we fit our data. We don't want to fit the error itself, we want to just fit the underlying signal. So let's talk about how we might be able to figure that out. How can we, how can we get a handle on what the underlying function really is apart from the errors and the noise that are, that are in it. Alright, so let me try to get to this concept of cross validation. So, imagine that we've got our data, this is our training set. We can, again, picture geometrically in the case of regression. And, ultimately what we're trying to do is find a way of predicting values and then testing them. So, what we imagine is we do some kind of regression and we might want to fit this too a line. And, you know, the line is good, it kind of captures what's going on and if we apply this to the testing set, maybe it's going to do a pretty good job. But, if we are, you know, feeling kind of obsessive compulsive about it we might say well in this particular case we didn't actually track all the ups and downs of the data. So what can we do in terms of if we, if we fit it with the line and the errors not so great. What else could we switch to Charles? >> We could just use the test. No, sorry. What, what I mean is if we fit, we fit this to a line and we're sort"
sFO2ff-gTh0,Cross Validation,1-2,"of not happy with the fact that the line isn't fitting all of the points exactly. We might want to use ,uh, maybe a higher order polynomial. >> Oh, I'm sorry, totally misunderstood you. >> To fit this better. So if we, we can fit this with a higher order polynomial and maybe it'll hit, all these points much better. You know, so we have this kind of, kind of other shape, and now it's doing this, it's making weird predictions in certain places. So, really what we'd like to do is, and what was your suggestion? If we trained on the test set, we would do much better on the test set, wouldn't we? >> Yes. >> But that, that, that's definitely cheating. >> Why is cheating? >> Is there some, why is it cheating? Well, if we exactly fit the error, the, the test set. That's not a function at all, is it? [LAUGH] If we exactly fit the, the test set, then again that's not going to generalize to how we use it in the real world. >> So the goal is always to generalize. The test set is just"
sFO2ff-gTh0,Cross Validation,2-3,"a stand-in For ,what we don't know we're going to see in the future. >> Yes, very well said. Thank you. >> Actually that suggests something very important, right, it suggest that ,um, nothing we do, on our training set or even if we cheat and use the test set .Actually makes sense unless we believe that somehow the training set and the test set represent the future. >> Yes, that's a very good point, that we are assuming that this data is representative of how the system is ultimately going to be used. In fact, there's an abbreviation that statisticians like to use. That the data, we really count on the data being independent and identically distributed, >> Mm-hm. >> which is to say that all the data that we have collected, it's all really coming from the same source, so there is no, no sort of weirdness that the training set looks different from testing set looks different from the world but they are all drawn from the same distribution. >> So would you call that a fundamental assumption of supervised learning? >> I don't know that I'd call it a fundamental of supervised learning per se, but it's a fundamental assumption in a lot"
sFO2ff-gTh0,Cross Validation,3-4,"of the algorithms that we run, that's for sure. >> Fair enough. >> There's definitely people who have looked at, well what happens in real data if these assumptions are violated? Are there algorithms that we can apply that still do reasonable things? But the stuff that we're talking about? Yes, this is absolutely. A fundamental assumption. Alright, but here's, here's where I'm trying to get with this stuff. So what we really would like to do, is that we'd like to use a model that's complex enough to actually model the structure that's in the data that we're training on, but no so complex that it's, it's matching that so directly that it doesn't really work well on the test set. But unfortunately we don't really have the test set to play with because that again, is going to, it's too much teaching to the test. We need to actually learn the true structure that is going to need to be generalized. So, so how do we find out. How can we, how can we pick a model that is complex enough to model the data while making sure that it hasn't started to kind of diverege in terms of how it's going to be applied to the test set. If we don't have access to the test set, is there something that we can use in"
sFO2ff-gTh0,Cross Validation,4-5,"the training set that we could have it kind of act like a test set? >> Well, we could take some of the training data and pretend its a test set and that wouldn't be cheating because its not really the test set. >> Excellent. Indeed, right, so there's nothing magic about the training set all needing to be used to fit the coefficient. It could be that we hold out some of it ,as a kind of make pretend test set, a test test set, a trial test set, a what we're going to say cross validation set. And it's going to be a stand in for the actual test data. That we can actually, make use of that doesn't involve actually using the test data directly which is ultimately going to be cheating. So, this cross validation set is going to be really helpful in figuring out what to do. So. Alright, so here's how we're going to do this, this concept of cross validation. We're going to take"
sFO2ff-gTh0,Cross Validation,5-6,"our training data, and we're going to split it into what are called folds. I'm not actually sure why they're called folds. I don't know if that's a sheep reference. >> Why would it be a sheep reference? >> I think there's a sheep-related concept that is called a fold. Like, You know, we're going to bring you back into the fold. >> Oh. >> It's like the, it's like the group of sheep. >> You are just trunk full of knowledge. >> Alright so what we're going to do is train on the first three folds, and use the fourth one to, to see how we did. Train on the [LAUGH] second there and fourth fold and check on the first one. And we're going to we're going to try all these different combinations leaving out each fold as a kind of a, a fake test set. And then average these errors. The ,uh, the, the goodness of fit. Average them all together, to see how well we've done. And, the model class, so like the degree of the polynomial in this case that does the best job, the lowest error, is the"
sFO2ff-gTh0,Cross Validation,6-7,"one that we're going to go with. Alright, so if this is a little bit abstract still let me, let me ground this back out in the housing example."
lvJzg6SJXbw,Housing Example Revisited,0-1,"Alright so here's how we're going to look at this. So as you may recall, in this housing example. If we look at different degrees of polynomials and how well they fit the data. Let's look at the training error. The per example training error. So how far off is it for each of the data points? And as we increase the degree of the polynomial from constant to linear to quadratic and all the way up to, when this case order six, the error's always falling. As you go up, you have more ability to fit the data, closer and closer and closer, right? because, each of these models is, is nested inside the other. We can always go back. If the zero fits best and I give you six degrees of freedom, you can still fit the zero. So, that's what happens with the training error, but now let's use this idea of cross validation to say what if we split the data up into chunks and have each chunk being predicted by the, the rest of the data? Train on the rest of the data, predict on the chunk. Repeat that for all the different chunks"
lvJzg6SJXbw,Housing Example Revisited,1-2,"and average together. So, so I actually did that. And this is what I got with the cross validation error. So there's a I don't know there's a couple of interesting things to note about this plot. So that we see, we have this red plot that is constantly falling and the blue plot which is the cross validation error starts out a little bit higher than the, the red plot that's got higher error. So, why do you think that is Charles? >> Well that makes sense right? because we're actually training to minimize error. We're actually trying to minimize error on the training set. So the parts we aren't looking at, you're more likely to have some error with. That makes sense if you'd have a little bit more error on the data you haven't seen. >> Right, so, good. So, so, in the, on the, this red curve. We're actually predicting predicting all the different data points using all of those same data points. So it is using all the data to predict that data. This blue point, which is really only a little bit higher in this case, is using, in this particular case I used all but one of the examples to predict the remaining example. But it doesn't have that example when it's, when it's doing its fitting. So it's really predicting on a new"
lvJzg6SJXbw,Housing Example Revisited,2-3,"example that it hasn't seen. And so of course you'd expect it to be a little bit worse. In this particular case, the averages are all pretty much the same so there's not a big difference. But now, let's, let's look at what happens as we start to increase the degree, we've got the ability to fit this data better and better and better, and, in fact, down at you know say, three and four, they're actually pretty close in terms of their ability to, to, to fit these examples. And then what's great, what's really interesting is what happens is now we start to give it more, the ability to fit the data closer and closer. And by the time we get up to, to order six polynomial, even though the error on the training set is really low, the error on this, on this cross validation error, the error that you, that you're measuring by predicting the examples that you haven't seen, is really high. And this is beautiful this, this inverted u, is, is exactly what you tend to see in these kinds of cases. That the error decreases as you have more power and then it starts to increase as you use too much [LAUGH] of"
lvJzg6SJXbw,Housing Example Revisited,3-4,"that power. Does that make sense to you? >> It does make sense, so. The, the problem is that as we give it more and more power we're able to fit the data. But as it gets more and more and more power it tends to over fit the training data at the expense of future generalization. >> Right. So that's exactly how we, we referred to this is this sort of idea that if you don't give yourself enough degrees of freedom, you don't give yourself a model class that's powerful enough you will underfit the data. You won't be able to model what's actually going on and there'll be a lot of error. But if you give yourself too much you can overfit the data. You can actually start to model the error and it generalizes very poorly to unseen examples. And somewhere in between is kind of the goldilocks zone. Where we're not underfitting, and we're not overfitting. We're fitting just right. And that's the point that we really want to find. We want to find the model that fits the data without overfitting, and not underfitting. >> So what was the answer on the, housing exam? >> Well, so, it seems pretty clear in this, in this plot that it's somewhere, it's either three or four. It turns out, if you look at the"
lvJzg6SJXbw,Housing Example Revisited,4-5,"actual numbers, three and four are really close. But three is a little bit lower. So three is actually the thing that fits it the best. And, in fact, if you look at what four does. It fits the data by more or less zeroing out the, the quartic term, right? It doesn't really use the, this power. >> Oh, but that's interesting. So that means it, it barely uses the, the, the extra degree of freedom you give it. But even using it a little bit, it still does worse than generalization. >> Just a tiny bit worse. >> Huh. >> Yup exactly so. >> That's actually kind of cool."
p0opXBswvWo,Other Input Spaces,0-1,"Alright. Up to this point I've been talking about regression in the context of a scalar input and continuous output. Sorry. Scalar input and continuous input. So basically this x variable. But the truth of the matter is we could actually have vector inputs as well. So what would might, what might be an example of where we might want to use a vector input? >> A couple of things. One if you look at the housing example, like we said earlier, there are a bunch of features that we weren't keeping track off. So we could have added some of those. >> Great yeah, we could include more input features and therefore combine more things to get it. But how would we do that? So let's say for example, that we have. Two input variables that we think might be relevant for figuring out housing costs. The size, which we've been looking at already, But also let's say the distance to the nearest zoo. We, we think that that's a really important thing. People like to live close to the zoo and so. >> But probably not too close to the zoo. >> [LAUGH] Possibly not too close to the zoo. But let's let's imagine that"
p0opXBswvWo,Other Input Spaces,1-2,"it's like size, something that actually Or actually, let, let's do it the other way, let's sort of imagine that, that, that the further away from the zoo, you are, the better it is. Just like the bigger the size is, the better it is. >> Mm-hm. >> So how do we combine these two variables into one in the context of the kinds of function classes that we've been talking about? >> Well, if you think about lines, we can just generalize the planes and hyper planes. Right so, in the case of, of a 1 dimensional input. That 1, 1 dimensional input gets mapped to the cost. But in the case of 2 dimensional inputs, like size and distance to the zoo. We have something that's more like a plane, combining these two things together in, in the linear fashion to actually predict what the. Cost is going to be. So right, so these, this notion of linear functions generalizes, this notion of polynomial function function generalizes too very, very nicely. All right, there is another kind of input that's important too, that, let's think about a slightly different example to help drive the idea home. So let's imagine we are trying"
p0opXBswvWo,Other Input Spaces,2-3,"to predict. Credit score, what are some things that we might want to use as features to do that. >> Do you have a job? >> I do, actually. >> [LAUGH] yes. >> Oh, I am sorry, I am sorry, I misunderstood. So you are asking, you are saying one [UNKNOWN] that could be important for predicting someone's credit score is just to know do they currently have a job. Right another thing might be well you, you can ask instead how much money they actually, how, how much, how many assets they have. How much money do they have? Credit cards. >> Great. So, so, right. So things like, what is the value of the assets that, that they own, right? So this is a continuous quantity like we've been talking about. But something like do you have a job, yes or no, is a discreet quantity. And one of the nice things about these kinds of regression approaches that we've talking about, like polynomial regression, is that we can actually feed in these discrete variables as well. Certainly if they're, if they're Boolean variables like, do you have a job or not? It, you can just think of that as being a kind of number that's just zero or one. No, I don't have a job. Yes, I have"
p0opXBswvWo,Other Input Spaces,3-4,"a job. What if it's something like, you know, how many houses do you own? >> Hmm. >> That's pretty easy because that's, you could just treat that as a As a quantity, a scalar type quantity. What about >> Are you. >> Type of job. >> Type of job, I like that. How about hair color? >> So, yeah, how would we do that? If we, if we're trying to feed it in to some kind of regression type algorithm, it needs to be a number or a vector of numbers, and they can be discrete. So right. So how do we encode this as some kind of a numerical value? >> Well, we could do something ridiculous like actually write down the RGB value which would make it kind of continuous. >> Interesting. >> That seems insane, but you could do that. Or you could just enumerate them and just assign them values one through six in this case. Right, 1, 2, 6 or they could be vectors like, is it red, yes or no? Is it beige, yes or no? Is it brown, yes or no? Have it be a vector and actually for different kinds of discreet quantities like"
p0opXBswvWo,Other Input Spaces,4-5,"this it can make it different, right? So in particular if we just gave the numbers. Then it's kind of signalling to the algorithm that blonde is halfway between brown and black, which doesn't really make sense. We could reorder these. Actually the RGB idea doesn't seem so bad to me. >> [UNKNOWN] of course, you have an interesting question of what's the real RGB value. It implies that somehow interpreting between them Make sense. >> That's right, that's right. >> It also implies an order right. It implies that the scalar order of RGB is somehow mean something that it's no different from saying red is one and beige is two. So, if we multiply it, for example, by a positive coefficient then the more RGB you have The better or the worse, right? >> Hmm. Interesting. Though, in fact what I had in mind here is for RGB, it's three different hair colors. >> I thought the g stood for green. >> There's, people don't have green hair, they have gray hair. >> But I thought the g in RGB stood for"
p0opXBswvWo,Other Input Spaces,5-6,"green. Yeah it does usually but I'm making a hair joke. [LAUGH] >> Oh oh. I am sorry. I am glad you explained that. You know Michael. >> No problem sir. >> I really, I really like the [UNKNOWN] factor idea. >> Yeah so I think. I think. I imaging that we are going to return to this issues when we start actually encoding problems as mission learning problems. >> I think your right. >> But I think that's I think that's said about regression for the time being. >> I agree."
E-9H6v2WqLo,Conclusion,0-1,"So, Charles, what did we learn about regression? >> well, we learned a bunch of interesting historical facts about where the word came from, which I thought was interesting anyway. >> Oh good. >> We learned about model selection and overfitting. And underfitting. And fitting in general, cross validation. >> Talked about, how to do linear and polynomial regression. >> Yeah. >> That the best constant, that the best constant in terms of squared error is the mean. >> Mh-hm >> These little cocktails for that. >> Well we also did the same thing for well we talked about the process for how you do it in genreral for any polynomial function. >> I think that's everything. >> Well one more thing, and we talked a little bit about representation, and how to make that work in regression. >> Great, we talked about input representations"
E-9H6v2WqLo,Conclusion,1-2,"and what some of the issues are. There. >> Yeah. >> Great, I think that's, I think that's a good amount. >> I think so, too."
L_6idb3ZXB0,Neural Networks,0-1,"Hey Charles. How's it goin'? >> It's going pretty well Michael. How are things going with you? >> Good. You know I'm excited to tell you about neural networks today. You may be familiar with neural networks because you have one, in your head. >> I do? >> Well, yeah. I mean, you have a network neurons. Like, you know, you know neurons, like brain cells. Let me, let me, I'll draw you one. >> Okay. >> So this is my template drawing, a nerve cell, a neuron. And you can, you know, you've got billions and billions of these inside your head. And they have you know, most of them have a pretty similar structure, that there's the, there's the kind of the main part of the cell called the cell body. And then there's this thing called an axon which kind of is like a wire going forward to a set of synapses which are kind of little gaps between this neuron and some other neuron. And what happens is, information spike trains >> Woo woo! >> Travel down the axon. When the cell body fires it has an electrical impulse"
L_6idb3ZXB0,Neural Networks,1-2,"it travels down the, the, the axon and then causes across the synapses excitation to occur on other neurons which themselves can fire. Again by sending out spike trains. And so they're very much a kind of a computational unit and they're very, very complicated. To a first approximation, as is often true with first approximations they're very simple. Sort of by definition of first approximation. So what, what, in the field of artificial neural networks we have kind of a cartoonish version of the neuron and networks of neurons and we actually. Put them together to compute various things. And one of the nice things about the, the way that they're set up is that they can be tuned or changed so that they fire under different conditions and therefore compute different things. And they can be trained through a learning process. So that's what we're going to talk through if you haven't heard about this before. >> Okay. >> So we can replace this sort of detailed version of a"
L_6idb3ZXB0,Neural Networks,2-3,"neuron with a very abstracted way kind of notion of a neuron. And here's how it's going to work. We're going to have inputs that are kind of you know, think of them as firing rates or the strength of inputs. X1, X2, and X3 in this case. Those are multiplied by weight, w1, w2, w3 correspondingly. And so the weights kind of turn up the gain or the sensitivity of the neuron, this unit, to each of the inputs respectively. Then what we're going to do is we're going to sum them up. So we're going to sum. Over all the inputs. The strength of the input times the weight, and that's going to be the activation. Then we're going to ask is that greater than, or equal to the firing threshold. And if it is, then we're going to say the output is one, and if it's not, we're going to say the output is zero. So this is"
L_6idb3ZXB0,Neural Networks,3-4,"a particular kind of neural net unit called Perceptron. Which is a very sexy name because they had very sexy names in the 50s >> They did. >> When this was first developed. Alright? So this, this whole neuron concept gets boiled down to something much simpler, which is just, a linear sum followed by a threshold, thresholding operation, right? So it's worth kind of thinking, how can we, what sort of things can this, can networks of these kinds of units compute? So, let's see if we can figure some of those things out."
VwCMm3llk1s,How Powerful is a Perceptron Unit,0-1,"Alright ,just to make sure that you understand. let's let's think through an example. let's imagine, that we've gotta a neuron. We got one of these perception units. And the input, to it ,is one, zero negative one point five. For the three different, inputs in this case. And the corresponding weights, are half three fifths and one... And the threshold, let's say is zero, meaning that it should fire, if the weighted sum is above zero, or equal to zero, and otherwise, it should not fire. So, what I'd like you to compute, is based, on these numbers, what the output y would be in this case Alright Charles you want to help us kind of work through this example? >> Sure. So ,we multiply x1 times w1 so that gives us a half >> Um-huh. >> We multiply zero times three fifth which would get a zero. >> Um-huh. >> And we multiply minus one point five times one. Which will give us minus three halves. And so, the answers negative. Whatever it is. >> It is right, so it's, this was negative ahead, negative one and a half plus a half, so it should be negative one. >> Right. >> And, but that's not the output that we should actually produce, right? That's the activation. What do we do with the activation? >> Well we see if the activation is above our threshold fata, which in this case is zero, and it is not So the output should be zero. >> Good. Alright. Well we'd like to try to get an understanding of how powerful one of these perceptron units are. So, what is it that they actually do? So they, they return, in this case either 0 or 1 as a function of a bunch of inputs. So let's just for simplicity of visualization, let's just imagine that we've got 2 inputs, X1 and X2. So Charles, how could we represent the region in this input space that is going to get an output of 0 versus the region that's going to get an output of 1. >> Order the weights. >> Right. So indeed, the weights matter. So let's, let's give some concrete values to these weights. And let's just say, just making these up that weight 1 is a half, weight 2 is a half, and our threshold data is three quarters. So now what we want to do is again, break up this, this space into where's it going to return 1 and where's it going to return 0. >> Okay, so I think I know how to figure this out. So, there's kind of"
VwCMm3llk1s,How Powerful is a Perceptron Unit,1-2,"an, there's 2 sort of extreme examples, so let's take a case where X1 is 0. >> X1 is 0. Okay, good. So that's this Y axis, uh-huh. >> Alright. So if X1 is 0, what value would X2 have to be in order to break a threshold of three quarters? Well, the weight on X2 is a half. >> Mm-hm. >> So then, the value of X2 would have to be twice as much as the threshold which in this case is one and a half. >> Right. So we're trying to figure out where is it, if X1 is 0, where does X2 need to be so that we're exactly at the threshold. So that's going to be. >> Right. >> The X2 times the weight, which is half has to exactly equal the threshold which is three quarters. So, if we just solve that out, you get X2 equals 3 halves. So okay that's this point here. That's going to be a dividing line. So anywhere above here, what's it going to return? >> It will return, it will break the threshold, and so it will return a 1. >> These are all going to be 1s and then below this these are all going to be 0s. >> Right."
VwCMm3llk1s,How Powerful is a Perceptron Unit,2-3,">> Alright. Well now we have a very, very skinny version of the picture. [LAUGH] Well what else can we do? >> Well we can do the same thing that we just did except we can swap X2 and X1 because, they have the same weight. So, we could say X2 equal to 0 and figure out what the value of X1 has to be. >> Good, and that seems like it would be exactly the same algebra, and so we get X1 is 3 halves, gives us at the one and a half point above here are going to be 1s and below here are going to be 0s. Okay, so now we've got 2 very narrow windows, but what we notice is that the relationships are all linear here. So solving this linear inequality gets us a picture like this. So this perceptron computes a kind of half plane right? So, so the half of the, the plane that's above this line, the half plane thatt's above this line is getting us the 1 answers and below that line is giving us a zero answers. >> So Michael can we generalize from this, so you're telling me then that because of the linear relationship"
VwCMm3llk1s,How Powerful is a Perceptron Unit,3-4,"drawn out by a perceptron that perceptrons are always going to compute lines. >> Yeah. Always going to compute, yeah these half planes right. So there's a dividing line where you're equal to the threshold and that's always going to be a linear function and then it's going to be you know, to the right of it or to the left of it, above it or below it but its always halves at that point. >> Okay, so perception is a linear function, and it computes hyperplanes. >> Yeah, which maybe in some sense it doesn't seem that interesting, but it turns out we're already in a position to compute something fascinating. So let's do a quiz."
QA2PatOWYTw,How Powerful is a Perceptron Unit Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"So this example that we, you know, created just at random actually is it computes an interesting function. So let's, let's focus on just the case where our X1 is in the set zero, one and X2 is in the set zero, one. So those are the only inputs that we care about, combinations of those. What is Y computing here? What is the name of that relationship that function that's being computed? And so, just as a hint, there's a, there's a, there's a nice short one-word answer to this if you can kind of plug it through and see what it is that it's computing. Charles, can you figure this out? >> Yes, I believe I can. So, the first thing to note is that because we're sticking with just 0 and 1, and not all possible values in between, we're thinking about a binary function. And the output is also binary. Which makes me think of Boolean functions, where zero represents false and one represents true, which is a common trick in machine learning. >> Alright, so and let me, let me mark those on the picture here. So we're talking about the only four combinations are here. And you're saying in particular. That we're interpreting these as combinations of true and false. >> Right >> False, false true false, false true and true, true. >> Exactly and if you look at it the only way that you get something above the line is when both are true. And that is called and. >> Also take conjunction. Right, exactly so, exactly so. So this is, even though"
QA2PatOWYTw,How Powerful is a Perceptron Unit Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,"we're, you know we're setting these numerical values but it actually is, gives us a way of specifying a kind of logic key. >> Right. So here's a question for you Michael. Could we do or? >> That's a very good question. Or looks a lot like And in this space, it, it seems like it aught to be possible. So let's let's do that as a quiz. ."
CXijskL6MkU,How Powerful is a Perceptron Unit OR Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"Alright, so we're going to go in the opposite direction now. And we're saying, we're going to tell you what we want y to be, we want y to be the or function. So it should be outputting a one if either x one or x two is one, and otherwise it should output a zero. And what you need to do is fill in numbers for weight one, weight two, and theta so that it has that semantics. Now, just so you know, there is no unique answer here. There's a whole bunch of answers that will work, but we're going to check to see that you've actually typed in one that, that works. Alright Charles, let's, let's figure this one out. It turns out, as I said, there's lots of different ways to make this work, but, what we're going to do is move that line that we had for conjunction. If we, what we really want to do now is figure out how to move it down ,so that now, these three points, are, in the green zone. They're going to output, one, because they're the or, and the only one in the, that's left in the zero zone in the, in the red zone is the zero, zero case. >> Right. >> So, How are we going to be able to do that? >> Well, since ,we want it to be case that, either, X2 or X1, being one get you above the line, then, we need a threshold and a set of weights ,that put either one of them over. You don't have to have both of them, you only need one of them. >> Okay. >> So, let's imagine a case where X1 is one and X2 is zero ,then basically, oh, there you're right, there's a whole lot of answers, so a weight of 1, for X1, would give you a one. Right?"
CXijskL6MkU,How Powerful is a Perceptron Unit OR Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,">> Yes, Huh >> And so, if we made the threshold 1, that would work. >> What about weight 2? >> Well, we do exactly the same thing. So, we set, weight 2 equal to 1. And that means, that in the case where both of them are 0, you get 0 plus 0, which gives you something less than 1. If ,one of them is 1 and the other is 0, you get 1, which gives you right at the threshold. And, if both of them, are, one then you get two, which is still greater than one. >> Good, alright, that seems like it worked. The other way we could do it, is we can keep the weights at in another way we can do it, is keep the weights where they were before, that just moves this line nice and smoothly down. And then, right? So before, we had a, a threshold of, one and a half. Now we need a threshold of, like, a half ,ought to do it. >> Yep. >> Or even less, as long as it's greater than zero. So, a quarter should work, as well. >> So, good, so, lots, lots of different ways"
CXijskL6MkU,How Powerful is a Perceptron Unit OR Quiz Quiz Solution - Georgia Tech - Machine Learning,2-3,"to do that. And, cool. Can we do not? >> What's not of two variables? >> That's a good question. Let's do not of one variable, then. >> Okay."
dPzpnAEe1hg,How Powerful is a Perceptron Unit NOT Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"Maybe you should help me finish this picture here. So what we've got is X1 is our variable and so we can take on any sort of values. And I marked negative one, zero, and one here. And if we're doing not, right, then what should the output be for each of these different values of X1? So like if the, if the, if X1 is zero, then we want the output to be. >> one. >> One. And if X1 is one, we want the output to be >> Zero. >> Zero. All right, so now what we'd like you to do is say okay, what should weight one be and what should theta be so that this, you get, we get this kind of knot behavior. Alright Charles, you were about to say, how we could do this. >> I think the answer is, simply, that we basically need to flip the, here's my thinking. We need to flip zero and one, which suggests that either our weight or our threshold needs to be negative. And since we, we The threshold is in above, it's going to end up being our weight being negative. So, let's say, if we have a zero, we want to turn that into something above the threshold and if it's a one, we want it to be below the threshold. So, why don't we make the weight negative one. >> Okay. >> And that, that turn a zero into a zero and it will turn a one into a minus one. Alright. >> And so, then the threshold just has to be zero. >> So that would mean that anything, I see, so anything that's negative will be greater than, zero or negative would be greater than or equal to the threshold. And anything on the other side of that. would be under the threshold. So"
dPzpnAEe1hg,How Powerful is a Perceptron Unit NOT Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,"we get this kind of dividing line at one, so were taking advantage of the fact the equation had a greater than or equal to in it. So, yeah, right, that ought to be a Not. So ,we've got And, Or, and Not are all expressible, as perceptron units. So and, or, and not are all expressible as perceptron units. >> Hey that's great because if we have AND, OR, and NOT, then we can represent any Boolean function. >> Well, do we know that? We know that if we combine them together, we combine these perceptron units together Can we, can we express any perceptron, oh sorry, any boolean function that we want using a single perception? >> So, what do we normally do in this case? So ,what's the most evil function we can think of? >> Yes indeed, we'll when we're woking on, on decision trees The thing that was so evil was the XOR, the called parity more generally. >> Right. >> So, alright. I mean, may, maybe if we can do that, we can do anything. So, let's, let's give it a shot."
2KUq_Ou-7FY,XOR as Perceptron Network Quiz - Georgia Tech - Machine Learning,0-1,"Alright so here's what we're going to do. We're going to try to figure out how to draw sorry, compute XOR as instead of a single perceptron, which we know is impossible, we can do it as a network of perceptron. Just to, to make it easier for you, here's how we're going to set it up. That we're, we've x1 and x2 as our inputs We've got two units. This first unit is just going to compute and add and we already know how to do that. We've already figured out what weights need to be, here and here. And what the threshold needs to be, so that the output will be the and of those two inputs. So, that's all good. But ,what we don't know ,eh, what, what, it turns out to be the case, that the second unit, with now three inputs, X1, X2, and the and of X1 and X2, can also be made to, or can be, can be, now, we can set the weights on that, so that the output is going to be X or. So, what we'd like you to do is, figure out how to do that. How do you set this weight - Is the input of X1, this way which is the and input, and this way which is the X2 input, and the threshold. So that ,it's going to actually"
2KUq_Ou-7FY,XOR as Perceptron Network Quiz - Georgia Tech - Machine Learning,1-2,"compute an X or. And, and just so you know, this is not a trick question. You really can do it this time."
5rAhHGimTOU,XOR as Perceptron Network Quiz Solution - Georgia Tech - Machine Learning,0-1,"So, okay, so, how we, how we going to solve this? >> Okay, so, I guess the first thing to do is if you look at the table you have at the bottom, it tells us what the truth tables are for AND and XOR, alright? So, we know that Boolean functions, can all be represented as combinations of and or N not. So, I'm going to recommend you feel out that empty column with OR. >> So, OR is like that. >> Right. And you'll notice, if you look at AND OR and XOR that, OR looks just like XOR except ,at the very last row. >> In the second, okay good, uh-huh, and in that row. >> Right, and, AND on the other hand, tells us a one only on the last row. So what, I'm going to suggest that we really want that last node to do in your drawing, is to compute the or of X1 or X2."
5rAhHGimTOU,XOR as Perceptron Network Quiz Solution - Georgia Tech - Machine Learning,1-2,"And produce the right answer, except in the case of the last row, which we only want to turn off when and happens to be true. So ,really what that node is, is computing or minus and. >> Alright, so how do we make this or minus and? So the way we did or before Well we did it a couple of different ways. But one is we gave weights of one on the two inputs. And then a threshold of one. And that made, ignoring everything else at the moment, this unit will now turn on if either x1 or x2 are on. And otherwise it will stay off. >> Right. So what's the worst case? The lowest value that you can get. Is when one of those is one and one of those is zero, which means that the, sum into those will be, in fact, one. >> Yeah. >> Right? So, if the AND comes out as being true, it's going to give us some positive value. So, if we just simply have"
5rAhHGimTOU,XOR as Perceptron Network Quiz Solution - Georgia Tech - Machine Learning,2-3,"a negative wait there, that will subtract out. Exactly in the case ,when AND is on. It's not going to quite give us the answer we want, but it's a good place to start to think about it. >> Alright, so like just a negative weight, like negative one. >> Mm-hmm. >> Alright. So does that work? >> Not quite. >> Alright, and why doesn't it work? Because if, well certainly when and is off then we really are just getting the or, that's all good. >> Yeah. >> But if both x1 and x2 are both on, then the sum here is going to be two minus the one that we get from the AND which is still one. >> So, minus one isn't enough? >> Minus with both, maybe we can do more than that. Maybe we can do minus two What happens if we do minus two? Then we've got ,X1 and X2 if they're both on, then we get a sum of one minus two plus one or zero. Which is less than our threshold so it will output zero. And in the other two cases, right, when and is off than it just acts like or. So this actually kind of does the right thing. Its actually OR minus kind of and"
5rAhHGimTOU,XOR as Perceptron Network Quiz Solution - Georgia Tech - Machine Learning,3-4,times two. [LAUGH] >> Right. And there you go. And of course there's an infinite number of solutions to this.
5g0TPrxKK6o,Perceptron Training,0-1,"Alright. So in the examples up to this point, we've be setting the weights by hand to make various functions happen. And that's not really that useful in the context of machine learning. We'd really like a system, that given examples, finds weights that map the inputs to the outputs. And we're going to actually look at two different rules that have been developed for doing exactly that, to figuring out what the weights ought to be from training examples. One is called the the Perceptron Rule, and the other is called gradient descent or the Delta Rule. And the difference between them is the perception rule is going to make use of the threshold outputs, and the, the other mechanism is going to use unthreshold values. Alright so what we need to talk about now is the perception rule for, which is, how to set the weights of a single unit. So that it matches some training set. So we've got a training set, which is a bunch of examples of x, these are vectors, and we have y's which are zeros and ones which are the, the output that we want to hit. And what we want to do is"
5g0TPrxKK6o,Perceptron Training,1-2,"set the, set the weights so that we capture this, this same data set. And we're going to do that by, modifying the weights over time. >> Oh, Michiel, what's the series of dashes over on the left. >> Oh, sorry, right. I should mention that, so one of the things that we're going to do here is were going to give a learning rate for the weights W, and not give a learning rule for Theta But we do need to learn the theta. So there's a, there's a very convenient trick for actually learning them by just treating it as a, as another kind of weight. So if you think about the way that the, the thresholding function works. We're taking a linear combination of the W's and X's, then we're comparing it to theta,but if you think about just subtracting theta from both sides, then, in some sense theta just becomes another one of the weights, and we're just comparing to zero. So what, what I did here was took the actual data, the x's, and I added what is sometimes called a, a bias unit to it. So"
5g0TPrxKK6o,Perceptron Training,2-3,"basically, the input is one always to that. And the weight corresponding to it is going to correspond to negative theta ultimately. So, just, just again, this just simplifies things so that the threshold can be treated the same as the weights. So from now on, we don't have to worry about the threshold. It just gets folded into the weights, and all our comparisons are going to be just to zero instead of some, instead of theta. Centric, yeah. It certainly makes the math shorter. So okay, so this is what we're going to do. We're going to iterate over this training set, grabbing an x, which includes the bias piece, and the y. Where y is our target X is our input. And what we're going to do is we're going to change weight i, the, the, the weight corresponding to the ith unit, by the amount that we're changing the weight by. So this is sort of a tautology, right. This is truly just saying the amount we've changed the weight by is exactly delta W - in other words the amount we've changed the weight by. So we need to define that what that weight change is. The weight change is going to be find as"
5g0TPrxKK6o,Perceptron Training,3-4,"falls. We're going to take the target, the thing that we want the output to be. And compare it to, what the network with the current weight actually spits out. So we compute this, this y hat. This approximate output y. By again summing up the inputs according to the weights and comparing it to zero. That gets us a zero one value.So we're now comparing that to what the actual value is. So what's going to happen here, if they are both zero so let's, let's look at this. Each of y and y hat can only be zero and one. If they are both zeros then this y minus y hat is zero. If they're both ones and what does that mean? It means the output should have been zero and the output of our current. Network really was zero, so that's, that's kind of good. If they are both ones, it means the output was supposed to be one and our network outputted one, and the difference between them is going to be zero. But in this other case, y minus y hat, if the output was supposed to be zero, but we said one, our network says one, then we get a negative one. If the output was supposed to be one and"
5g0TPrxKK6o,Perceptron Training,4-5,"we said zero, then we get a positive one. Okay, so those are the four cases for what's happening here. We're going to take that value multiply it by the current input to that unit i, scale it down by the sort of thing that is going to be cut the learning rate and use that as the the weight update change. So essentially what we are saying is if the output is already correct either both on or both off. Then there's gong to be no change to the weights. But, if our output is wrong. Let's say that we are giving a one when we should have been giving a zero. That means our, the total here is too large. And so we need to make it smaller. How are we going to make it smaller? Which ever input XI's correspond too, very large values, we're going to move those weights very far in a negative direction. We're taking this negative one times that value times this, this little learning rate. Alright, the other case is if the output was supposed to one but we're outputting a zero, that means our total"
5g0TPrxKK6o,Perceptron Training,5-6,"is too small. And what this rule says is increase the weights essentially to try to make the sum bigger. Now, we don't want to kind of overdo it, and that's what this learning rate is about. Learning rate basically says we'll figure out the direction that we want to move things and just take a little step in that direction. We'll keep repeating over all of the, the input output pairs. So, we'll have a chance to get in to really build things up, but we're going to do it a little bit at a time so we don't overshoot. And that's the rule. It's actually extremely simple. Like, you, actually writing this in code is, is quite trivial. And and yet, it does some remarkable things. So let's imagine for a second that we have a training set that looks like this. It's in two dimensions, again, so that it's easy to visualize. That we've got. A bunch of positive examples, these green x's and we've got a bunch of negative examples these red x's, and were trying to learn basically a half plane right? Were trying to learn a half plane that separates the positive from the negative examples. So Charles do you see a, a, half plane that we could put in here that would do the trick? >> I do."
5g0TPrxKK6o,Perceptron Training,6-7,">> What would it look like? >> It's that one. >> By that one do you mean, this one? >> Yeah. That's exactly what I was thinking, Michael. >> That's awesome! Yeah, there are isn't, isn't a whole lot of flexibility in what the answer is in this case, if we really want to get all greens on one side and all the reds on the other. If there is such a half plane that separates the positive from the negative examples, then we say that the data set is linearly separable, right? That there is a way of separating the positives and negatives with a line. And what's cool about the perception rule, is that if we have data that is linearly separable. The Perceptron Rule will find it. It only needs a finite number of iterations to find it. In fact, which I guess is really the same as saying that it will actually find it. It won't eventually get around to getting to something close to it. It will actually find a line, and it will stop saying okay I now have a set of weights that, that do the trick. So that's happens if the data set is in fact linearly separable and that's pretty cool. It's"
5g0TPrxKK6o,Perceptron Training,7-8,"pretty amazing that it can do that, it's a very simple rule and it just goes through and iterates and, and solves the problem. So. Charles Sened solves the problem. So. >> I can think of one. What if it is not linearly separable? >> Hmm, I see. So, if the data is linearlly separable, then the algorithm works, so the algorithm simply needs to only be run when the data is linearlly separable. It's generally not that easy tell actually, when your data is linearly separable especially, here we have it in two dimensions, if it's in 50 dimensions, know whether or not there is a setting of those perimeters that makes it linearly separable, not so clear. >> Well there is one way you could do it. >> Whats that? >> You could run this algorithm, and see if it ever stops. I see, yes of course, there's a problem with that particular scheme, right, which says, well for one thing this algorithm never stops, so wait, we need to, we"
5g0TPrxKK6o,Perceptron Training,8-9,"need to address that. But, but really we should be running this loop here, while, there's some error so I neglected to say that before. But what you'll notice is if you continue to run this after the point where it's getting all the answers right. It found a set of weights that lineally separate the positive and negative instances what will happen is when it gets to this delta w line that y minus y hat will always be zero the weights will never change we'll go back and update them by adding zero to them repeatedly over and over again. So. If it ever does reach zero error, if it ever does separate the data set then we can just put a little condition in there and tell it to stop filtering So what you are suggesting is that we could run this algorithm and if it stops then we know that it is linearly separable and if it doesn't stop Then we know that it's not linearly separable, right? By this guarantee. >> Sure. >> The problem is we, we don't know when finite is done, right? If, if this were like 1,000 iterations, we could run it for 1,000 if it wasn't done. It's not done, but all we know at this point is that it's a finite number"
5g0TPrxKK6o,Perceptron Training,9-10,"of iterations, and so that could be a thousand, 10 thousand, a million, ten million, we don't know, so we never know when to stop and declare the data set not linearly separable. >> Hmm, so if we could do that, then we would have solved the halting problem, and we would all have nobel prizes Well, that's not necessarily the case. But it's certainly the other direction is true. That if we could solve the halting problem, then we could solve this. >> Hm. >> But it could be that this problem might be solvable even without solving the halting problem. >> Fair enough. Okay."
1j4bERmqmOU,Gradient Descent,0-1,">> So we are going to need a learning algorithm that is more robust to non-linear separability or linear non-separability. Does that sound right? >> Non-linear separability. Non linear separability. >> Non? >> Yeah think of it. >> Left parenthesis, linear sep, spreadability left parenthesis. >> There we go, that's right, negating the whole phrase, very good. So and, Gradient descent is going to give us an algorithm for doing exactly that. So, what we're going to do now is think of things this way. So what we did before was we had a summation over all the different input features of the activation on that input feature times the weight, w, for that input feature. And we sum all those up and we get an activation. And then we have our estimated output as whether or not that activation is greater than or equal to zero. So let's imagine that the output is not thresholded when we're doing the training, and what we're going to do instead is try to figure out the weight so that the Not thresholded value is, as close"
1j4bERmqmOU,Gradient Descent,1-2,"to the target as we can. So this actually kind of brings us back to the regression story. We can define an error metric on the weight vector w. And the form of that's going to be one half, times the sum over all the data in the dataset, of what the target was supposed to be for that particular example minus what the activation actually was. Right? The activation being the dot product between the weights and the input and we're going to square that. We're going to square that error and we want to try to now minimize that. > Hey Michael, can I ask you a question? >> Sure. >> Why one half of that? >> Mm. Yes. It turns out that it turn, in terms of minimizing the error this is just a constant and it doesn't matter. So why do we stick in a half there? Let's get back to that. >> Okay. >> Just like in the regression case we're going to fall back to calculus. Right, calculus is going to tell us how we can push around these weights, to try to push this error down. Right, so we would like to know. How does changing the weight"
1j4bERmqmOU,Gradient Descent,2-3,"change the error, and let's push the weight in the direction that causes the error to go down. So we're going to take the partial derivative of the, this error metric with respect to each of the individual weights, so that we'll know for each weight which way we should push it a little bit to move in the direction of the gradient. So that's the partial dif, dif, [INAUDIBLE] So that's the partial derivitive with respect to weight wi, of exactly this error measure. So to take this partial derivitive we just use the chain rule as we always do. And what is it to take the derivitive of something like this, if you have this quantity here. We take the power, move it to the front, keep this thing, and then take the derivitive of this thing. But that, so this now answers your question, Charles. Why do we put a half in there? Because down the line, it's going to be really convenient that two and the half canceled out. So, it's just going to mean that our partial derivative is going to look simpler, even though our error measure looked a little bit more complicated. So so what we're left with then, is exactly what I said, the sum over all these data points of what"
1j4bERmqmOU,Gradient Descent,3-4,"was inside this. Quantity here times the derivative of that, and here I expanded the a to be, the definition of the a. Now, we need to take the partial derivative with respect to weight w i of this sum that involves a bunch of the ws in it. So, when don't match the w i, that derivative is going to be zero because the, you know, changing the weight won't have any impact on it. The only place where this, changing this weight has any impact is at x of i. So that's what we end up carrying down. This summation disappears. And all that's left is just the one term that matches the weight that we care about. So this is what we're left with. Now the derivative of the error with respect to any weight w sub i. Is exactly this, this sum. The sum of the difference between the activation and the target output times the activation on that input unit >> You know? That looks exactly like, almost exactly like the rule that we use with the rule that we used perceptron before. >> It does indeed! What's the"
1j4bERmqmOU,Gradient Descent,4-5,"difference? Well, actually let's Let's write this down. This is now just a derivative, but let's actually write down what our weight update is going to be because we're going to take a little step in the direction of this derivative and it's going to involve a learning rate."
zgtepSTqzgc,Comparison of Learning Rules,0-1,"So here's our update rules what they end up being. The gradient descent rule we just derived says what we want to do is more the weights in the negative direction of the gradient. So if we negate that expression that we had before and take a little step in that direction we get exactly this expression. Multiply the. The input on that weight times the target minus the activation. Whereas in the perceptron case what we were doing is taking that same activation, thresholding it. Like, determining whether it's positive or negative. Putting in a zero or a one. And putting that in here, that's what y hat is. So really it's the same thing except in one case we have done the thresholding and in the other case we have not done the thresholding. But we end up with two different algorithms with two different behaviors. The perceptron has this nice guarantee. A finite convergence, which is a really good thing, but that's only in the case where we have linear separability. Whereas the gradient descent rule is good because, calculus. >> [LAUGH]. >> I guess that's not really an answer is it. It's, the"
zgtepSTqzgc,Comparison of Learning Rules,1-2,"gradient descent rule is good because it's more. Robust. To to data sets that are not linearly separable, but it's only going to converge in the limit. To a local optimum. Alright is that, is that the story there Charles? >> As far as I'm concerned."
9qIfStTc7A4,Comparison of Learning Rules Quiz - Georgia Tech - Machine Learning,0-1,"So once we see these two things next to each other, it kind of raises the question, why, don't we just use a gradient decent type ,on an error metric that's defined in terms of y, hat instead of this, the activation a? because y hat ,is the thing, that we really want to match the output. We don't really want the activation to match the output. There's no, there's no need for that. So, it seemed there's a, bunch of different possible reasons for that. It could be, well we don't do that, because, it would just be computationally compactable. It's too, it's too much work. Another possibility ,would be, well to do the gradient descent, you'd have to be able to take the derivitive and if we use it in this form, it's not differentiable. So, we can't take the derivative. Another one is, well sure we can do all that, it's not intractable and its not, not differentiable. But, if we do that then the weights tend to grow too fast, until you end up getting unstable answers, and then, the last possible choice that we will give you is. You can do that but you can get multiple different answers and the different answers, behave differently and so this is"
9qIfStTc7A4,Comparison of Learning Rules Quiz - Georgia Tech - Machine Learning,1-2,really just to keep it from being in illdefined.
ymHKayqpp1E,Comparison of Learning Rules Quiz Quiz Solution - Georgia Tech - Machine Learning,0-1,"So why don't we do gradient descent on y hat? >> Well there could be many reasons but the main reason is it's not differentiable. It's a just discontinuous function. There's no way to take the derivative at the point where it's discontinuous. >> So this this activation thing. The, the change from. Activation to y hat has this big step function jump in it, right, at zero. So once the activation goes positive, actually at zero. It jumps up to one. And before that, it's, it's not. So the derivative is basically zero, and then that. Not differentiable, and then zero again. So really, the zero's not giving us any direction to push, in terms of how to fix the weights. And the undefined part, of course, doesn't really give us any information either. So this, this algorithm doesn't really work, if you. Try to take the derivative through this discontinuous function. But it does kind of, you know. What if we made this, more differentiable? Like, what is it that makes this so undifferentiable? It's"
ymHKayqpp1E,Comparison of Learning Rules Quiz Quiz Solution - Georgia Tech - Machine Learning,1-2,"this, it's this really pointy spot, right. So you could imagine a function that was kind of like this, but then instead of the point spot, it kind of smoothed out a bit. Mm, like that. So kind of a softer version of a threshold, which isn't exactly a threshold. But it leaks this differentiable. >> Hm. >> So that would kind of force the algorithm to put its money where its mouth is. Like if that really is the reason, that the problem is non differentiable, fine. We'll make it differentiable. Now, how do you like it? I don't know, how do we like it now [LAUGH]? >> Well, I'll tell you how much I like it when you show me a function that acts like that."
WcDtwxi7Ick,Sigmoid,0-1,"Challenge accepted. We're going to look at a a function called the sigmoid. Sigmoid meaning s-like, right, sig, sigma-ish, sigmoid. So we're going to define this, this, the sigmoid using the letter. Sigma and it's going to be applied to the activation just like we were doing before, but instead of thresholding it at zero, what it's instead going to do is compute this function of a, one over one plus e to the, e to the minus a, and what do we know about this function? Well, it is. Ought to be clear that as the activation gets less and less and less, we'd want it to go to zero, and in fact it does, right. So, as a goes to negative infinity, the negative a goes to infinity. E to the infinity is something really, really big. So it's one over 1 plus something really big, which is like 1 over something huge, which is almost zero. So, the sigmoid function goes toward, this function that we defined here, goes to zero as the activation goes. To negative infinity, that's great, that's just like threshold, and as"
WcDtwxi7Ick,Sigmoid,1-2,"the activation gets really really large, we're talking about e to the minus something really large, which is like e to the almost, or like e to the negative infinity which is like almost zero, so one over one plus zero is essentially one. So on the one limit, it go towards zero, and the other limit it goes towards one, and in fact we can just Draw this so you can see what it really looks like you know, minus five and below it's essentially at zero, and then it makes this kind of gradual, you can see why it's sigmoid s-shaped curve, then it comes back up to the top and it's basically at one by the time it get to five. So instead of just an abrupt of transition to zero, we had this gradual transition between negative five and five. And this is great because it's differentiable, so. What do you think Charles, does this answer your question? >> It does, I buy that. >> Alright good so if we have units like this now we can take derivatives which means we can use this gradient decent idea all over the place. So not only is this function differentiable but the derivative itself has"
WcDtwxi7Ick,Sigmoid,2-3,"a very beautiful form. In particular it turns out... That if you take the derivative of this sigma function, it can be written as the function itself times one minus the function itself. So this is just, this is just really elegant and simple. So, if you have, you know, the sigma function in your code, there's nothing special that you need for the derivative. You could just compute it this way. So we would, it's not a bad exercise to go through and do this. Practice your calculus, we just did this together but it's not that fun to watch. So I would suggest doing it on your own, and if you have any trouble we'll, we'll provide additional information for you to, to help you work that out. >> But when you do it on your own make sure that no one is watching. >> [LAUGH] Well they can watch, they just probably won't enjoy it very much. So, so can we say anything about why this form kind of makes sense? So, so what's neat about this is. As we, as our activation gets very, very negative, then our sigma value gets closer and closer to zero. And if you look at what our derivative is there, it's something like zero times"
WcDtwxi7Ick,Sigmoid,3-4,"something like one minus zero, whereas the derivative as you get to very, very large as, that's like sigma's going to one. And you get 1 times 1 minus 1 minus 1, so essentially 1 times 0. So you can see the derivatives flatten out for very large and very negative a's. And when a is like, zero, so what happens when a is like zero? Boy, what does happen when a is like zero? Charles, what happens if we plug zero into this sigma function? >> You get one half. >> Is that obvious? Oh, I see, because e to the minus a, that's zero, so e to the zero is one, one over one plus one, so a half. And then our derivative at that point is a half times a half, or a quarter, so that's kind of neat. >> Mm-hm. >> So so this is really, this, it's, it's in a very nice form for being able to work with it. >> But it's probably worth saying that. Surely you could use other functions that are different, and there might be good reasons to do that. This one just happens to be a very nice way of dealing with the threshold in question."
WcDtwxi7Ick,Sigmoid,4-5,">> Yeah and there's other ways that are also nice. So again, the main properties here are that as activation gets very negative it goes to zero, as activation gets very positive it goes to one, and there's this smooth transition in between, there's other ways of making that shape."
w9OFiOaTFs8,Neural Network Sketch,0-1,"Alright so we're now in a great position to talk about what the network part of the neural network is about. So now the idea is that we can construct using exactly these kind of sigmoid units, a chain of relationships between the input layer, which are the different components of x, with the output. Y, and the way this is going to happen is, there's u, other layers of, of units in between. That each one is computing the weighted sum, signoided, of the layer before it. These other layers of units are often referred to as hidden layers, because you can kind of see the inputs, you can see the outputs. This, this other stuff is, is less constrained. Or indirectly constrained. And what's happening is that each of these units, it's, it's running exactly that kind of, you know, take the weights, multiply by the things coming into it, put it through the sigmoid and that's your activation, that's your output. So, so what's cool about this is, in the case"
w9OFiOaTFs8,Neural Network Sketch,1-2,"where all these are sigmoid units this mapping from input to output. Is differentiable in terms of the weights, and by saying the whole thing is differentiable, what I'm saying is that we can figure out for any given weight in the network how moving it up or down a little bit is going to change the mapping from inputs to outputs. So we can move all those weights in the direction of producing something more like the output that we want. Even though that there's all these sort of crazy non linearities in between. And so, this leads to an idea called back propagation, which is really just at its heart, a computationally beneficial organization of the chain rule. We're just computing the derivatives with respect to all the different weights in the network, all in one convenient way, that has, this, this lovely interpretation of having information flowing from the inputs to the outputs. And then error information flowing back from the outputs towards the inputs, and that tells you how to compute all the derivatives. And then, therefore how to make all the weight updates to make, the network produce something more"
w9OFiOaTFs8,Neural Network Sketch,2-3,"like what you wanted it to produce. So this is where learning is actually taking place, and it's really neat! You know, this back propagation is referring to the fact that the errors are flowing backwards. Sometimes it is even called error back propagation. >> Nice, so here's a question for you Michael. What happens if I replace the sigmoid units with some other function and, and let's say that function is also different Well, if it's differentiable, then we can still do this, this basic kind of trick that says we can compute derivatives, and therefore we can move weights around to try to get the network to produce what we want it to produce. >> Hmm. That's a big win. Does it still act like a preceptron? >> Well, even this doesn't act exactly like a preceptron, right? So it's really just analogous to a preceptron, because we're not really doing the hard thresholding, we don't have guarantees of, of convergence in finite time. In fact, the error function can have many local optima, and what, what we mean by that is this idea that we're trying to get the, we're trying to set the weight so that the error"
w9OFiOaTFs8,Neural Network Sketch,3-4,"is low, but you can get to these situations where none of the weights can really change without making the error worse. And you'd like to think, well good, then we're done, we've made the error as low as we can make it, but in fact it could actually just be stuck in a local optima, that there's a much better way of setting the weights It's just we have to change more than just one weight at a time to get there. >> Oh so that makes sense, so if we think about sigmoid the sigmoid and the error function that we picked right. The error function was sum of squared airs, so that looks like a porabola in some high dimensional space, but once we start combining them with others like this over, over, and over again Then we have an error space where there may be lots of places that look low but only look low if you're standing there but globally would not be the lowest point. >> Right, exactly right and so you can get these situations in just the one unit version where the error function as you said is this nice little parabola and you can move down the gradient and when you get down to the bottom you're done. But now when we start throwing these networks of units together we can get an error surface that looks just in its cartoon form looks"
w9OFiOaTFs8,Neural Network Sketch,4-5,"crazy like this, that there's, it's smooth but there's these Place where it goes down, comes up again and goes down maybe further, comes up again and doesn't come down as far and you could easily get yourself stuck at a point like this where you're not at the global minimum. Your at some local optimum."
mE2N3na1VzI,Optimizing Weights,0-1,"So one of the things that goes wrong, when you try to actually run gradient descent on a complex network with a lot of data is that you can get stuck in these local minima and then you start to wonder, boy is there some other way that I can optimize these weights. I'm trying to find a set of weights for the neural network Well that what? That, that tries to ,minimize error on the training set. And so, gradient decent is one way to do it, and it can get stuck, but there's other kinds of advanced optimization methods that become very appropriate here. And in fact, there's a lot of people in machine learning who think of optimization and learning as kind of being the same thing. That, that what you're really trying to do in any kind of learning problem is solve this, this high order, very difficult optimization problem to figure out what the The learned ,representation needs to be. So, I need to mention in passing some kinds of advanced methods that people have brought to bear, there's things like ,uh,using momentum terms in the gradient, which basically, where the idea in momentum is, as we're doing gradient decent, so let's imagine this is our error"
mE2N3na1VzI,Optimizing Weights,1-2,"surface, we don't want to get stick on this ball here, we want to kind of pass all the way through it to get to this ball, so maybe we need to just continue in the direction we've been going. So, instead of You know think of it as a kind of physical analogy. Instead of just, just going to the bottom of this hill and getting stuck, it can kind of bounce out and pop over and come to, what might be a lower, minima, later. There's a lot of work in using higher order derivatives to, to better optimize things instead of just thinking about the, way that individual weights change the error function to look at combinations of weights. Hamiltonions and whatnot. There's various ideas for randomized optimization, which we're going to get to in a sister course, that can be applied to, to, to make things more robust. And sometimes it's worth thinking, you know what, we don't really want to just minimize the error on the training set, we may actually want to have some kind of penalty for using, using a structure that's too complex. I mean this, this ,uh, when did we, when did we see something like this before Charles?"
mE2N3na1VzI,Optimizing Weights,2-3,">> When we were doing regression, and we were talking about over fitting. >> So right. That's right. It came up in regression but something similar will also happen in the decision tree section. >> Sure. We, we had a, we had a issue with decision trees where if we had, we let the tree grow too much to explain every little quirk in the data. You'd over fit, and so ,we came up with a lot of ways of dealing with that, like pruning. No going too far deeply into the tree. You can either do that by filling out the tree and then backing up so you only have a little bit of small error Or by stopping once you've reached some sort of threshold as you grow the tree out. That's really the same as giving some kind of penalty for complexity. >> Yes, exactly, right. So complexity in the tree setting has to do with the size of the tree, in regression it had to do with the order of the polynomial. What do you suppose it would mean in the neural net setting? And, and how would you predict, what negative attributes it might have. So, what's, what's a more or less complex network? >> Well, there's two things you can do with networks, you can add more and more"
mE2N3na1VzI,Optimizing Weights,3-4,"nodes, and you can add more and more layers. >> Good. So, right. So if we, the more nodes that we put into network, the more complicated the mapping becomes from input to output, the more local minima we get, the more we have the ability to actually model the noise, which brings up exactly the same overfitting issues. It turns out there's another one that's actually really interesting in the neural net setting which, I think didn't occur to people In the early days but it became clear and clear over time, which is that ,you can also have a complex network, just because the numbers, the weights, are very large. So same number of weights, same number of nodes, same number of layers, but larger numbers often leads to more complex. Network and the possibility of overfitting. And so ,sometimes we want to penalize a network not just by giving it fewer nodes or layers but also by keeping the numbers in a reasonable range. Does that, does that make sense? >> Makes perfect sense."
UQk_bq2exSM,Restriction Bias,0-1,"So this brings up the issue of what neural nets are more or less appropriate for. What is the restriction bias, and the inductive bias of this class of classifiers, and regression algorithms? So Charles, can you remind us what restriction bias is? >> Well, restriction bias Tells you something about the representational power of whatever data structure it is that you're using. So in this case the network of neurons. And it tells you the set of hypotheses that you're willing to consider. >> Right, so if, if the, if there's a great deal of restriction, then there's lots and lots of different kinds of models that we're just not even considering. We're, we're restricting our view to just a subset of those. So In the case of neural nets, what restrictions are we putting? >> Well, we started out with a simple perceptron unit, and that we decided was linear. So we were only considering planes. Then"
UQk_bq2exSM,Restriction Bias,1-2,"we move to networks, so that we could do things like exor, and that allowed us to do more. Then we started sticking Sigmoids and other arbitrary functions and to nodes so that we could represent more and more, and you mention that if you let weights get big and we have lots of layers and lots of nodes, we can be really, really complex. So, it seems to me that we are actually not doing much of a restriction at all. So let me ask you this then Michael. What kind of functions can we represent, clearly we can represent boolean functions, cause we did that. Can we represent continuous functions? That's, that's a great question to ask, that's what we should try to figure that out. So, in the case, as you said, Boolean functions, we can. If we give ourselves a complex enough network with enough units, we can basically map all the different sub components of any Boolean expression to threshold like units and basically build a circuit that can compute whatever Boolean function we want. So that one definitely"
UQk_bq2exSM,Restriction Bias,2-3,"can happen. So what about continuous functions? So what is it? What is a continuous function? A continuous function is one where, as the input changes the output changes somewhat smoothly, right? There's no jumps in the function like that. >> Well, there's no discon, there's no discontinuities, that's for sure. >> Alright, now if we've got a continuous function that we're trying to model with a neural network. As long as it's connected, it has no, no discontinuous jumps to any place in the space, we can do this with just a single hidden layer. As long as we have enough hidden units, as long as there's enough units in that layer. And, essentially one way to think about that is, if we have enough hidden units, each hidden unit can worry about one little patch of the function that, that it needs to model. And they, the patches get set at the hidden. And at the output layer they get stitched together. And if you just have that one layer you can make any function as long as it's continuous. If it's Arbitrary. We can still represent that in our neural network. Any mapping from inputs to outputs we"
UQk_bq2exSM,Restriction Bias,3-4,"can represent, even if it's discontinuous, just by adding one more hidden layer, so two total hidden layers. And that gives us the ability to not just stitch these patches at their seams, but also to have big jumps between the patches. So in fact, neural networks are not very restrictive in terms of their bias as long as you have a sufficiently complex network structure, right, so maybe multiple hidden layers and multiple units. >> So that worries me a little bit Michael, because it means that we're almost certainly going to overfit, right? We're going to have arbitrarily complicated neural networks and we can represent anything we want to. Including all of the noise that's represented in our training set. So, how are we going to avoid doing that? >> Excellent question. So, it seems like there's, there is exactly that worry. But, it is the case though, that when we train neural networks, we typically give them some bounded number of hidden units and we give them some bounded number of layers. And so, it's not like any fixed network can actually capture any arbitrary function. So any fixed network can only capture whatever it can capture, which"
UQk_bq2exSM,Restriction Bias,4-5,"is a smaller set. So going to neural nets in general doesn't have much restriction. but any given network architecture actually does have a bit more restriction. So that's one thing, the other is hey, well we can do with overfitting what we've done the other times we've had to deal with overfitting. And that's to use ideas like, cross validation. And we used cross validation to decide. How many hidden layers to use. We can use it to decide how many nodes to put in each layer. And we can also use it to decide when to stop training because the weights have gotten too large. So, and this is, it's probably worth pointing this out that this is kind of a different, different property from the. Other classes of supervised learning algorithms we've looked at so far. So in a decision tree, you build up the decision tree, an you may have over fit, but it is what it is. In regression, you know, you solve the regression problem, and again that may have over fit. What's interesting about neural network training is it's this iterative process that you started out running, and"
UQk_bq2exSM,Restriction Bias,5-6,"as it's running, it's actually Errors going down and down and down. So, in this standard kind of graph, we get the error on the training set dropping as we increase iterations. It's doing a better and better job of modeling the training data. But, in classic style, if you look at the error in the, in some kind of held-out test set, or maybe in a cross validation set, you see the error starting out kind of high and maybe dropping along with this, and at some point It actually turns around and goes the other way. So here, even though we're not changing the network structure itself, we're just continuing to improve our fit, we actually get this, this pattern that we've seen before, that the cross validation error can turn around and, and at this, you know, at this low point, you might have, you might want to just stop training your network there. The more you train it, possibly the worse you'll do. And again, that, it's reflecting this idea that the complexity of the network is not just in the nodes and the layers, but also in the magnetude of the weights. Typically what happens in this turnaround point is that some weights are actually getting larger and larger"
UQk_bq2exSM,Restriction Bias,6-7,"and larger. So, just wanted to highlight that difference between neural net function approximation of what we see in some of the other algorithms"
mzkIMfatv4M,Preference Bias,0-1,"Alright, you know the issue that we want to make sure that we think about each time we introduce a new kind of supervised learning representation is to ask what its preference bias is. So Charles, can you remind us what preference bias is? >> Mike researcher bias tells you what it is you are able to represent. Preference bias tells you something about the algorithm that you are using to learn. That tells you, given two representations, why I would prefer one over the other. So, perhaps you think back what we talked about with decision trees, we preferred trees where nodes near the top had high information gain We preferred correct trees. We preferred trees that were shorter to ones that were longer unnecessarily and so on and so forth. So that actually brings up a point here which is, we haven't actually chosen an algorithm. We talked about how derivatives work, how back propagation works, but you missed telling me one very important thing, which is how do we start? You tell me how to update the weights but, how do I"
mzkIMfatv4M,Preference Bias,1-2,"start out with the weights? Do they all start at zero? Do they all start out at one? How do you usually set the weights in the beginning? >> Yes indeed. We did not talk about that, that's, it's really important. You can't run this algorithm without initializing the weights to something. Right? We did talk about how you update the weights but they don't just you know, just start undefined and you, you can't just update something that's undefined. So we have to set the initial weights to something. So pretty typical thing for people to do, is small, random, values. So why do you suppose we want random values? >> Because we have no particular reason to pick one set of values over another. So you start somewhere in the space. Probably helps us to avoid local minimum. >> Yea kind of. I mean there's also the issue of Well if we run the algorithm multiple times if we get stuck, we like it not to get stuck exactly there again, if do, if you run it again. So it gives some variability, which is a helpful thing in avoiding local minimal. And what do you suppose, it's important to start with small values."
mzkIMfatv4M,Preference Bias,2-3,">> Well you just said. In our discussion before that if the weights get really big that can sometimes lead to over fitting, because it let's you represent arbitrarily complex functions. >> Good. And so, and what is that tell us about what the preference bias is then? >> Well if we start out with small random values. That means we are starting out with low complexity. So that means we prefer Simpler explanations to more complex explanations. And of course the usual stuff like we prefer, correct answers to incorrect answers, and so on and so forth. >> > So, you'd say that neural-nets implement, or maybe we should say, that neural networks implement a kind of bias that says Prefer correct over incorrect but all things being equal, the simpler explanation, is preferred. >> Well, if you have the right algorithm. If the algorithm starts with small, random values and tries to stop, you know, when you start over-fitting Then you, cause you're going to start out with the simpler explanations first before you allow your weights to grow. so you, about that. >> So this"
mzkIMfatv4M,Preference Bias,3-4,"reminiscent of the principal that is known as Occan's razor which is often stated as entities should not be multiplied unnecessarily. And given that we're working with neural networks, there's a lot of unnecessary multiplication that happens. [LAUGH] But, in fact, this actually is referring to exactly what we've been talking about. So this unnecessarily is, one interpretation of this is that, ""Well, when is it necessary?"" It's necessary if you're getting better explanatory power, you're fitting your data better. So Unnecessarily would mean, well we're not doing any better at fitting the data. If we're not doing any better at fitting the data, then we should not multiply entities. And multiply here means make more complex. So don't make something more complex unless you're getting better error, or if two things have similar error Choose the simpler one, use the one that's less complex. That has been shown to, if you mathematize this and you use it in the context of supervised learning, that we're"
mzkIMfatv4M,Preference Bias,4-5,going to get better generalization error with simpler hypotheses.
ZTjot416e-g,Instance Based Learning Before - Georgia Tech - Machine Learning,0-1,"So that brings us to the end of the topics we are going to talk about in terms of neural nets. There's going to be some interesting stuff for you to do in terms of the homework where you'll be exposed to some other important concepts. But that's, that's all we're going to lecture about for now. So let's just remind ourselves what exactly we covered in the neural net section. So Charles what do you remember? >> I remember perceptrons. I remember. >> And perceptron was a threshold unit, a linear threshold unit, and we could put networks of them together. >> Yes. >> To produce any Boolean function. What else? Oh, we had a learning rule for perceptrons. >> Mm-hm. Which runs in finite time for linearly separable data sets. >> And we learned a general differentiable rule. Adding general we learned about propagation using a gradient set. >> And we talked a little bit about the, about the preference and restriction by c's of neural networks. Alright, til next time. >> See you Michael. Hi Michael! >> Hey Charles! How's it going? >> It's going pretty well. How's it going with you? >> It is a beautiful fall day here in Providence Rhode Island. >> Oh that's right it's fall, when you are. >> [LAUGH] Yeah, I think, that's right. >> So, what we're going to do today, Michael. If you will indulge me. Is ,we're going to talk about a different class of ,uh, learning algorithms and approaches than we've been talking about before. >> So now the other ones were low class, this is going to be high class? >> Exactly. And we call them instance based learning. Which sounds very hoity toity and high voluting. Don't you agree? >> Yeah, sure, why not? >> [LAUGH] >> It sounds like it maybe has good posture. >> It does, in fact, have good posture. >> Well let's, let's learn about it. I'm, I'm, I'm intrigued. >> Yeah, so I think that ,uh, what we're going to end up talking about to day is kind of interesting, I hope. But it's sort of different, and what I'm hoping is through this discussion Is that, we will be able to reveal some of the unspoken assumptions that we've been making so far, okay? >> Unspoken assumptions, it sounds, yeah, okay, that sounds like we should get to the bottom of that."
ZTjot416e-g,Instance Based Learning Before - Georgia Tech - Machine Learning,1-2,">> Yes, so let's do that. So, just to remind you of what we have been doing in the ,um, past, this is what was going on with all of our little supervised learning tasks, right. We were given a bunch of training data ,labeled here as you know, x, y One, xy two, xy three, dot, dot, dot, xy zen. And ,uh, we would then learn some function. So, for example, if we have a bunch of points in a plane, we might learn a line to represent them, which is what this little blue line is. And what was happening here is we take all this data. We come up with some function that represents the data. And then we would throw the data away effectively, right? >> Okay. Yeah, so like, black is the input here and then the two blue things are what get derived by the learning algorithm. >> Right. And then in the future when we get some data point, let's call it x, we would pass it through this function whatever it is. In this case, probably line. And that would, be how we would determine answers going forward. >> Yeah. That's, that's what we've been talking about. >> Right. And in particular without reference to the original data. So. I want"
ZTjot416e-g,Instance Based Learning Before - Georgia Tech - Machine Learning,2-3,"to propose an alternative and the alternative is basically going to not do this. >> [LAUGH] >> So let me give you a, let me, let me tell u exactly what I mean by that."
yZBKzXjSg1k,Instance Based Learning Now - Georgia Tech - Machine Learning,0-1,"Okay, so here what I mean concretely by not doing this thing over here any more. So here what I'm proposing we do now. We take all the data, all of the training data we had, the xy1, xy2, dot, dot, dot, xyn and we put it in a database >> Ah-ha. >> And then next time we get some new x to look at, we just look it up in the database. And we're done. >> None of this fancy shmancy learning, none of this producing an appropriate function like you know, wx+b, or what ever the equation of a line is. None of that fancy stuff anymore. We just stick in to the data base. People written data base programs before. We'll look it up when we're done. We're done.Period >> I feel like you've changed the paradigm. >> Yes, I am a paradigm changer. So what do you think? >> It's like, it's like disruptive. It's going to throw off the markets. >> Yeah. It's going to change everything. So, what do you think? >> well, I mean, so there's a bunch of really cool things about this idea. Which is why I'm excited. So one is it, you know, it"
yZBKzXjSg1k,Instance Based Learning Now - Georgia Tech - Machine Learning,1-2,"doesn't forget, right? So it actually is very reliable. It's very ,um ,dependable, right, so if you put in an x, y pair you ask for the x you're going to get that y back instead of some kind, you know, crack potty, smooth version of it. >> Right, so we don't, yeah that's a good point. So we look at this little blue line over here, you'll notice that say, for this little x over here, we're not going to get back what we put in, so, it remembers, it's like an elephant. Good. >> So that's kind of cool. Another thing is that there's none of this wasted time, you know, doing learning [LAUGH]. It just takes the data and it, and it's, very rapidly just puts it in the database. So [CROSSTALK] it's fast. >> It's fast. It's like. I like it when you say nice things about my algorithms. Okay. So it's fast. Anything else, you can think of? >> Sh, yeah I cant think of one more thing at least. >> Mm-hm. >> Which is ,that like you, it's simple. >> [LAUGH] That's true. I am simple. I am simple and straightforward. I just need a few things to make me happy. >> Bacon. >> Bacon, and >> And >> Chocolate. >> Oh nice. >> Have you ever had chocolate covered bacon?"
yZBKzXjSg1k,Instance Based Learning Now - Georgia Tech - Machine Learning,2-3,">> That seems wrong. >> You know, you would think so, but it turns out it's delicious. It's like if you take fat, and sugar, and you put it together somehow you like it [LAUGH] I'm not making this up you can buy chocolate covered bacon, you're unsurprised to here in America. Okay, so we've got three good things in remember stuff. So, you know, none of this little noisy throwing away information. It's very fast, you just stick it in a database. Using your favorite data base. And looking up is going to be equally as fast. And it's very simple. There's really no interesting learning going on here. So it's the perfect algorithm when we're done. >> Okay. I mean, I, it feels like there's more that we need to say though. >> Like what? >> In particular the way that you wrote this, F of X equals look up of X. If I give you one of the other points in between ,then it will return no such point found. Which means it's really quite conservative. It's not willing to go out on a limb and say ,well I haven't seen this before but. It ought to be around here, instead it just says, I don't know. >> Mm. So the down side of remembering is, no generalization."
yZBKzXjSg1k,Instance Based Learning Now - Georgia Tech - Machine Learning,3-4,">> [LAUGH] And I guess a similar sort of issue is that when you, when you call it memorization, it makes, it reminds me of the issues that we saw with regard to overfitting So, it bottles the noise exactly, it bottles exactly what it was given. So it's going to be very sensitive to noise. So it's kind of a yes and no. >> So that's a little scary and, and it can over fit in a couple of ways, I think it can over fit ,um, by believing the data too much that is literally believing all of it and what do you do if you have couple ,uh, speaking in noise, what if you have you know a couple of examples that are all the same. I have got an x, shows up multiple times but each with a different y. >> Oh,the same x,ah, yeah, and so the look up would return two different things and this algorithm or whatever that you have described so far, wouldn't commit to either of them and it would just say, hey, here is both. >> Yeah, that seems problematic. >> Okay, alright. But I feel like, you know, you are going to to tell me, how to fix those things. So I wasn't too worried. >> Yeah, well, there is gotta be a nice way of fixing it. I think There's sort of a basic problem"
yZBKzXjSg1k,Instance Based Learning Now - Georgia Tech - Machine Learning,4-5,"here, which is that we're taking this remembering and then looking up a little too literally, right? So I stick in the data, and I can get back exactly the data that I got, but I can't get back anything that I don't have, and that seems like something that we might be able to overcome if we're just a little bit clever. >> Mm. >> So let's see if we can be a little bit clever."
tUw9A-g3scE,Cost of the House - Georgia Tech - Machine Learning,0-1,"Okay Michael, so let's see if we can, work together to deal with this minor triffle of a problem, that ,ah, you've observed with my cooling algorithm, okay. So, here's some data, it's a graph and you see here's a y axis and here's an x axis, and each of these points, represents a house, on this map, which I'm, I'm cleverly, using in the background. [CROSSTALK] And, you'll notice, that each of the dots is colored. I'm going to say that red represents, really expensive houses, blue represents, moderately expensive houses, and green represents, really inexpensive houses. Okay? >> Okay, where is this? >> Where is this? Oh, this is Georgia Tech, as you can tell because, it says Georgia Tech. >> Oh, I see it now. >> Okay. So, here's what I want you to do. using machine learning. I want you to look at all of this data, and then I want you to tell me, for these little black dots, whether they"
tUw9A-g3scE,Cost of the House - Georgia Tech - Machine Learning,1-2,"are really expensive, moderately expensive or, or inexpensive. But ,I want you to do it, using something like the technique that we talked about before. >> Okay? >> So, let's look at this little dot, over here. Which, by the way, I want to point out. this little black dot here by the US Post Office, underneath the rightmost ,e ,over here, is not a point in our data base. But I think by staring at this, you might be able to come up with a reasonable guess, about whether it is moderately expensive, expensive, or inexpensive. >> Okay, yeah. I think, this is a helpful, example, because, now I see that it does kind of make sense, especially, in this context, to think of the geometric location, as actually being a very useful attribute for deciding how to label the new points. So, that black point that you've pointed out, is in the part of the neighborhood, that has a green dot in it. Like, the nearest dot to it, seems like a pretty good guess as to what, what the value of that house might be, so I'm going to guess green. >> Yes, and I think ,you would be right. And I like the word that you used there. You talked about, its nearest neighbor, so I like that. I'm going to write that down."
tUw9A-g3scE,Cost of the House - Georgia Tech - Machine Learning,2-3,"Neighbor, okay. So, I'm going to look at my nearest neighbor. Well let's see if this works, for another point. Let's look at another point, that's near an, e, let's see, the first e over here. This little black point, over here. What do you think? If I, if I looked at my nearest neighbor, what would I, what would I guess? >> Yeah, this one seems really clear. It's, it's surrounded by red. It's in the red part of town. >> So, you're guessing, the output is then, purple? [LAUGH] >> No, I'm going with red. >> Yes, and I think that that makes perfect sense. So, this is pretty cool. If I have a point that's not in my database ,but, I still, by looking at my nearest neighbour, can, sort of figure out ,ah, what the actual value should be. So, there we have solved, the problem. >> Yes, seems like a pretty good role. >> Yeah, just look at your nearest neighbour and you are done. There, so, boom. There is nothing else for you to do. >> Yeah, except that you didn't do all of the houses yet. >> Okay, well, what did I miss? >> The one in the middle and [CROSSTALK] I'm wondering, if maybe you did that on purpose, because, this one has some issues."
tUw9A-g3scE,Cost of the House - Georgia Tech - Machine Learning,3-4,">> What are its issues? Besides being too, near 10th Street? >> well, yeah, apart from that it doesn't really have any very close neighbors ,on the, on the map. So the closest that you get, is, I don't know, maybe that red one? >> Maybe. >> But I would be really, I'd be very wary of just using that as my guess, because, it's also pretty darn close to a bluepoint. >> Yeah. >> And also not so, far from the green point. >> That's a good point. So, this whole nearest neighbor thing doesn't quite work, in this case when you got a bunch of neighbors that are saying different things. And they are kind of close to you. So, any clever way we might around this? >> I would say, move the black dot, to, >> No, no, no, no, we are not allowed that before. >> No? Okay, right it seems, it seems, like it would be helpful. >> No, no, they are federal laws ,against interesting. >> I was going to say, yeah, so, alright So, short of that, maybe ,we just need to look at a bigger context?"
tUw9A-g3scE,Cost of the House - Georgia Tech - Machine Learning,4-5,">> Ahh, that makes sense. So, you're saying my little nearest neighbor thing, sort of worked ,but the problem was I started out with examples ,that were, you know, very clearly in a neighborhood, and now I'm in a place where I'm not so sure about the neighborhood, so I should let I should look at more of my neighbors, than just the closest one."
0WELNkvAQz0,Cost of the House Two - Georgia Tech - Machine Learning,0-1,"Okay, so, how man do you want to look at? >> Well in this case it, you know, I feel like I could draw a, a kind of extended city block zone and capture maybe, I don't know, five of the points. >> Okay, let's do it. So let's find our five, our five nearest neighbors. So let's see. This is clearly close, that's one over here. I'd say this is close. I'll say this one is close. This one's close. None of the other blue ones are actually that close. And I'd say that's the next closest one, so here are my little five points. That all seem relative near. So what does that tell you? >> Well, I mean, it's, it feels like it suggests that red is not a bad choice here. >> Mm >> It's in a reddish part of town. >> Yeah, I get that. So, so you think it's a pretty, fair thing to bet that this should be red then? >> Yeah I mean I think that if you were really asking me seriously I would wonder about that blue point to the right of the highway and whether"
0WELNkvAQz0,Cost of the House Two - Georgia Tech - Machine Learning,1-2,"that had any influence. >> That's pretty far away. >> Yeah, it's not that far away. >> Well in Atlanta, once you cross highways you might as well be an infinite distance away. >> Well so, okay, but. That's a good point then. So, I guess I was interpreting your notion of distance as being, you know, like straight line distance on the map. But maybe that doesn't make sense for this kind of neighborhood example. >> Hm, no, that's a good point. So, we've been talking about distance sort of implicitly. But this notion of distance. It's actually quite important. So maybe distance is straight-line distance, maybe it's as the crow flies. Maybe it's driving distance. Maybe it has to take into account the fact that, when you cross highways in Atlanta, you're typically moving into a completely different universe. These sorts of things matter. >> Yeah. So I could imagine I don't know, like Google Maps distance. >> Right. Or how many paths can you get there and which is the shortest one given the traffic? There's all kinds of things like that you could do. So. So that's fair, that's fair. But that just says that this, this distant, we have to be very careful what we mean by distance and that's okay. But let's just say for the sake of this discussion"
0WELNkvAQz0,Cost of the House Two - Georgia Tech - Machine Learning,2-3,"that these are the closest points by some reasonable measure of distance. So, in that world, would you be happy if you had to pick a single example? a single output, a single label of red ,uh, blue or green. Would you be happy picking red? >> Yeah, I mean you know, not ecstatic, but okay. >> That's fair. So, I like this. So, we, we went from just picking our nearest neighbor to picking our nearest neighbors. And ,what's a good value you think we should, we should stick to with neighbors? We started with one and that clearly wasn't good. You picked, at least not in all cases and you came up with five. So what do you think? What, what, if I'm going to call this algorithm something, what do you think five nearest neighbors? What do you think? What should I call it? >> Five seems good. I mean I feel like that, that's gotta be universal. >> The number five? >> Yeah. >> Well it is in Atlanta but it might not be univeral in wherever it is you are. >> We'll call it the Georgia Tech nearest neighbors. >> That doesn't seem like an algorithm that's going to to be used very much. >> Fair enough. All right. So what about,"
0WELNkvAQz0,Cost of the House Two - Georgia Tech - Machine Learning,3-4,"we could do as many nearest neighbors as is appropriate. Or maybe we should just make it a free parameter and call it K. >> Ok, I like that. K nearest neighbors, so we'll have K nearest neighbors. And we'll pick our K numbers. Oh, and you said something fancy there, by the way. You said free parameter. I like that. We should, we should come back to that again. So we have an algorithm, k nearest neighbors. Which takes K nearest neighbors as a way of deciding how you're going to label some query point here. And we've identified two parameters to the algorithm so far. K Which is the number of neighbors we're going to use. And some notion of distance. >> Oh, sure. >> Which here we were kind of using in the sort of obvious way, but there might be other ways we might want to use distance here. >> Yeah, like I could imagine if the houses, if, had additional features like how many Square footages they had. >> Right, stuff like that. That would make perfect sense. So, so really distance, we're using distance here in a kind of in an over loaded sense, because this is something on a map. But really distance is a standard for similarity. >> Similarity, good. It's kind of standard for the opposite of similarity."
0WELNkvAQz0,Cost of the House Two - Georgia Tech - Machine Learning,4-5,">> [LAUGH] Well distance is just a kind of similarity, right? But in case of, you know, points on the map. Similarity, it sort of makes sense because as you said when we were talking about real estate, location, location, location matters. So, there, similarity really is kind of the inverse of distance. But in other ways, things like the number of veterans you have, whether you're one on side of the highway or the other, the school district you're in, things like that, are other things you might add as features or dimensions when you talk about similarity or distance. Okay, so I like this. I think we have a general algorithm now and I think it does a pretty good job of addressing the points you brought up. We no longer have to worry about overfitting as much, at least it seems that way to me. And we have a way of being a little bit more robust to this, you know, not having an exact data point in the database. So ,maybe we should turn this into an algorithm. >> Yeah, let's go for it. >> Okay, let's do that."
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,0-1,"Okay, so what we have here, again, is pseudocode for our K-NN algorithm. And I'm sort of writing it as like, a function. So, you're going to be given some training data D, that's the little x, y points, x y one, x y 2, x y 3, so on and so fourth. You're given some kind of distance metric or similarity function. And this is important because this represents the domain knowledge as I think we, we've already said. You get some number of neighbors that you care about, k, hence the k and n, which also, by the way, represents domain knowledge. Tells you something about how many neighbors you think you should have. And then are given some particular new query point and I want to output some kind of answer, some label, some value. So the K nn algorithm is remarkably simple given these things you simply find a set of nearest neighbors such that they are the K closest to your query point. >> Okay. I'm sort of processing this. So the, the data"
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,1-2,"the capital D. Are those pairs and there's a set of pairs? >> Yes. >> Ok. And k smallest distances. So this NN this is a set? >> Yes. >> And it consists of all the elements in the data that are closest to the query point? >> Yep. And the so the query point is a parameter of that. Okay. Yeah. Alright. I think I. Oh. And then it's, then the so it's just return. >> Yeah, so we haven't figured out what to return. So there's two separate cases we've been talking about so far. One is where, we're doing classification, and one is where we're doing regression. So, a question for you would be, what do you think we should when we're doing classification? Sort of, what we were doing before on the map. What will be a way of returning a proper label? >> So you want to label, not a, like a weight on a label or something like that? >> No. I want a label. You have to produce an answer. You have to commit to something Michael. >> Alright. Can I commit to more than one thing? >> Nope. >> Okay. So I would say that a reasonable thing to do there would be. Did we get Ys associated with the things in NN?"
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,2-3,">> Yeap. >> So I would go with they should vote. >> I like that. I think that's a good one, so we'll simply vote and what does it mean to vote? >> It means, let's see, so feel like there would be a way to represent it in terms of NN, the set. Like do you want me to write it formally? >> No. >> Oh, then I would just say The closest point. Whichever yi is most frequent among the closest points wins. >> Yeah. Right. So you want to find a, a vote of basically a vote of the yi's, that are apart of the neighborhood set. And you take the plurality. >> Plurality I see. So it's whichever one occurs the most. >> Right. >> What if there's ties? >> It's the mode. The mode. Right. >> Right. >> Mmmm. I love mode. >> What if they're ties? That's a good point. Well, if they are ties among the output, then you're just going to have to pick one. >> OK. >> And there's lots of ways you might do that. You might say, well, I'll take the one. That is"
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,3-4,"say, most commonly represented in the data period. Or I'll just randomly pick each time, or any number of ways you might, you c an imagine doing that. >> The one that's first alphabetically. >> The one that's first lexicographically? >> Hm. >> What about in the regression case? >> Okay. So in the regression case our y-is are numbers. >> Uh-huh. And we have the closest Yi's, so we have a bunch of those numbers and it seems like [LAUGH] if you have a pile of numbers and have to return one, a standard thing to do would be to take the average, or the mean. >> Yeah. Now let's just simply take the mean of the Yi's, and at least there, you don't have to worry about a tie. That's right. Though, I guess, you know. We didn't really deal with the question of what happens if there's more than k small. It's, like, what if they're all exactly the same distance? All n of them are exactly the same distance. So which are the k closest? >> Well, there's lots of things you could do there. I guess what I would suggest doing, is, take the, If you have more than k that are close, that are closest because you have a bunch of ties, in terms of the distance. Just take"
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,4-5,"all of them. Get the smallest number greater than or equal to k. Okay. >> That seem reasonable? >> Yeah, I think that's what college rankings do. >> Actually, that is what college rankings do, and then they, yeah, that's exactly what college rankings do. So, let's do that. We know that college rankings make sense. [LAUGH]. Yeah, those are, they're scientifically proven to be, >> Youths. >> scary, scary to people in colleges. >> That's exactly right. So, here's what we've got, Michael. So, all we do is we take the training data. We have some notion of similarity or distance. We have a notion of the number of neighbors that we care about. We have a query point, we find the K closest to one, you know breaking ties accordingly. And then we basically average in some way, in a way that make sense for classification, in a way they make sense for regression and we are done. It's a very simple algorithm, but some of that's because a lot of decisions are being left up to the designer. The distance metric. The number k, how you're going to break ties. Exactly how you choose to implement voting. Exactly how you choose to implement the mean or the"
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,5-6,"average operation that shows how to do here. And you could put a bunch of different things here and you end up in, completely, you could end up with completely different answer. Mm. >> By the way, one thing that you might do, just to give you an example of just, how much range there is here. Is rather than doing a simple vote by counting, you could do a vote that is say, weighted by how far away you are. So we could have a weighted vote. >> Uh-huh. >> That might help us with ties. >> That could help with ties. Yeah. >> You could do a weighted average. Yes, right. So, you're basically saying that the y values that correspond to x values that are closer to the query point have more of an influence on the mean. >> Which makes some sense, right? >> No, I think it makes a lot of sense! >> So, how would you weight that? What would you do? >> I would weight it by the similarity. >> Right, so well in this case, the similarity is we have a distance value similarity, so You would have to, you know, weight it by something like one over the distance. >> Oh I see. Okay. That seems like a hack."
mpU84OJ5vdQ,K NN - Georgia Tech - Machine Learning,6-7,">> Sure but it's a hack that sort of makes sense. >> Okay. >> Okay. So anyway. Simple algorithim. Lots and lots of decisions to make here. All of which could in principle have a pretty big effect. And so, in order to see that, I want to do two quizzes that I hope get to heart of this and maybe give us a little bit of insight into how some of these decisions might matter on the one hand, and exactly just how simple or not simple this algorithm turns out to be. Okay? >> Awesome."
xK3icFAiEJs,Wont You Compute My Neighbors Quiz - Georgia Tech - Machine Learning,0-1,"Okay Michael, I have two quizzes for you. Okay? >> Yeah, yeah. >> Here's the first quiz, and here's the way it's set up. I want you to fill in the empty boxes of this table. Okay? >> Ooh. >> Got it. >> There's a lot of empty boxes. >> There's a lot of empty boxes. >> Okay, but Okay, let me make sure I understand what's going on here. So we're looking at three different algorithms that are learning algorithms. >> Yep. >> There's one One neural net >> No >> Okay, one nearest neighbor. >> Mm-hm >> K nearest neighbor and linear regression. >> Yep >> And for each one you want to know running time and space. >> Mm-hm. >> And this is on n points I assume, yeah, n sort, what does it mean for data points to be sorted? >> So let's assume we're living in a world where all of our data points are you know in r one. Okay. >> Oh okay that well that. That could be sorted. >> That could be. Yeah that could be sorted. And that you know we are going to be out putting some real numbers as well. So they're points on a, on a number line. So to make things simple for you. I'm going to say that the points that your given are already sorted. >> Oh ok alright. And yeah that makes sense. Its just"
xK3icFAiEJs,Wont You Compute My Neighbors Quiz - Georgia Tech - Machine Learning,1-2,"a scaler. So then a query point is going to come in. And then its going to be some value. And were going to have to find the nearest neighbor or do the linear regression or whatever. >> Right. >> Alright now that's for running time. For now space your talking about the space of what. >> How much space you are going to have to do in order to accomplish your task. How much space you going to have to use in order to accomplish your task? >> So this is kind of like the the. The space that's representing the class enviro. Or the regression. After training. >> Yes. So actually that question about after training is important. You'll notice I've divided each of these algorithms into two phases. There's the learning phase. How much time it takes to learn. How much space you need to learn. Then there's the query phase. When I give you some new value and you have to output and answer. What's the running time for that and what are the space requirements for that? Okay? You got that? >> Yeah >> I want that for each one. Of these three algorithms. >> Except for one nearest neighbor which the, it appears as though you filled in for me to get me started. >> Right so just to get you started and make it easier for you know to know what I'm talking about. I'm talking about big o times here. Right. I'm"
xK3icFAiEJs,Wont You Compute My Neighbors Quiz - Georgia Tech - Machine Learning,2-3,"not going to make you write out big o. Big o is implicit. So if we look at one nearest neighbor, and we ask well what's the running time of learning? Well, it's constant. Right? Because there's no learning. >> I see. You just take that sorted set of data points and you just pass it along through the query here. >> Right. Now, you could say that"" Well, I'm going to take the data points or I'm going to copy them into this database,"" and so it's linear. But let's assume they already come in a data base, or some data structure that you can use, okay? >> Gotcha. >> Okay, so now that actually brings us to a nice little question about how much space, learning takes here. And, well because you have to store those points, and keep them around. The space requirements are big O of N. >> Yeah, that makes sense. >> Okay, good. So given that as an example. Do you think your one example in your data base. Mm, do you think you can use that to build up labels for all the rest of the phases of the different algorithms? >> Yeah, I think so. >> Okay, cool. Go for it."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay Michael, are you ready? >> I am afraid so. >> All right, which one do you want to fill out first? >> Let's just do them in order, so ,one nearest neighbor. You, you explained, how the training works. We just take the assorted list, and leave it there. >> Mm-hm. >> And we have the classifier, or the aggressor itself ,has linear space, and now at query time, we need to find the nearest neighbor, Um-huh. >> Which we could do by taking the query point, and running through the whole list ,and seeing which one it's closest to, but, because, it's sorted I think we, we outta be able to use binary search and, and in log time, find the closest, point to the query. >> That's exactly right, you should be able to do that in log base, two time. What if it weren't sorted? >> Yeah then, like I said, I think you could just scan through the whole list and that would be linear time and that's not a big deal. >> Right, yeah, we could do linear time, but, because I gave you a sorted list, because, I'm so helpful, you can do it in [INAUDIBLE] time, okay, but."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,1-2,">> That was, that was very, very thoughtful of you. >> It was I thought, I thought of her, so what about on the, space side? >> Alright, so the amount of space that you need to process its query is linear. We don't need to take any special, set aside, space beyond, a couple simple variables. And the data that we're given, which we've already accounted for. >> Right, so then why would it be linear, if we accounted for it? >> Did I say linear? I meant constant. >> Yes, yes, that's right, constant. That's what you meant. That's what you said. That's what happened. >> [LAUGH] >> Okay. >> It's a good thing, this wasn't being recorded, so we could verify one way or the other. >> [LAUGH] It is a good thing, maybe we'll look it up on Wikipedia, and it'll say confusingly [LAUGH] >> Linear sometimes use to mean constant. >> Constant. [LAUGH]. Yeah, that is pretty confusing. >> Okay, what about k and n? >> Alright, K and n. So k and n, so the training process, the learning process, is exactly the same, as it is for one year stamper, which is to say you do nothing and you pass all the data forward, to the, The query processor. So it's going to be 1 n."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,2-3,">> That is correct, nice. >> Now querying, seems like its a little more subtle. So we can find the single nearest neighbor in log and time. >> Mm-mm. >> Where we going to get the other K minus one? So, I'm pretty sure, that ,once we find the nearest neighbor we can kind of start doing a little, Spread out search, from there, until we found the k nearest neighbors. >> Sure. So, you're saying, you know, you've got these points. They're already in a line, you find the nearest neighbor. You know ,the, the next nearest neighbors have to be within k of the points surrounding it, and so you can just move in kind of, either direction and pick them up as you go. Yeah, something like that. >> Okay. >> I mean the way that, the way that I was thinking about it is that, I, I think you can use the same algorithm that you used for merging lists, in merge sort, but here the lists actually corresponds, to being, to the left of the query point, and being to the right of the query point and they are both sorted ,in terms of their distance from the query point. Sure, yeah, I buy that."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,3-4,">> So, so that ought to give us log n, plus k. >> Okay, so, do we need to write the k? >> I'm going to say yes, because, if k is on the order of like, n over 2, then it's going to dominate. If k is on the order of log n, then it's not going to dominate. Mm, that's a good point. So, yeah, we'll do k. I will point out that if k is on the order of n over 2, you're right, it will dominate, and then really this is big o of n. >> That's right. >> But if it's on the order of log n, then it's just log n plus n, and so it's a big old long n, log n. But ,you're right, so we should probably keep the k around because, we don't know its relationship to n. Okay, fair enough. Okay, what about the space requirements? >> We know one bit of relationship, it's smaller than or equal to n. >> That's true. >> Because that would be really weird, if I gave you ten data points and asked you for the 20 nearest neighbors. >> That's the sort of thing you would do. >> It's the sort of thing you would do, but then ,it would be really confusing. >> No, no, no, it's the sort of thing YOU would do, again, let's go to Wikipedia. >> Confusingly, twenty sometimes means ten. [LAUGH] >> Okay. So what about space? >> Space, so, I don't understand why, it would ever need more than constant space."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,4-5,"So, so we're going to, zip around in that. I mean, I guess, if do it really badly ,we can use K space. To kind of copy over what those, possible nearest neighbors are. But ,we don't need to keep track of them. We can just point to them in place, so it's constant. >> Okay, yea that's true in fact, because, it's sorted all you really need to know is the beginning and the ending. So, that's two things that's constant. Okay, cool, alright, good, so what about linear regression? Your favorite little algorithm thing that you did? When we talked about this before. >> I do like, linear regression. The learning in this case, is what we are mapping, real number input to a real number output. The way we are doing that is we are taking, its probably M X plus B sort of form [CROSSTALK]. We need to find, the multiplier and the additive constant. which, It seems, like, in general doing a regression involves, inverting a matrix. But, in this case,I think the matrix that we're talking about is of constant size. So"
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,5-6,"inverting, is, constant time. I think, it's as easy ,as basically just scanning through the list ,to populate that, that ,constant size matrix. So, I'm going to say order n. >> Yep. >> To process the data. >> That is correct. >> There's probably a really nice algorithm for that. >> Yeah, probably some kind of linear regression algorithm. >> Yeah. [LAUGH] No, I mean like the general linear regression algorithm is, is involves inverting a matrix. >> Right. >> Or something like it, something equivalent to it. But here because, we're, it's all in scaler land, I think it's simpler. >> Yeah, I think that's right. Okay ,so what about space? >> All right, so space interpreted the data that you passed forward from the learning algorithm, to the regressor, is just, well MX plus B. It's just M and B, which is constant. There's the two numbers. >> Right, that's 2, 2 is like 1, [UNKNOWN] large values [LAUGH] of 1, so it's constant. >> Yeah, All right, now at query time, you give me an X. I multiply, it by M and add B, so that's constant time [CROSSTALK]. So, before the query, cost was expensive and the learning"
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,6-7,"cost was cheap. And now we've kind of swapped that around. >> Yeah, we have, so space would be. >> Space, oh, that you're asking me? >> Yeah. >> Space for the query would be constant as well. >> Right, exactly, so yeah, so you made a good point here. So earlier on, we had the situation where learning was fast, was constant, and querying was, you know, not as fast. It was, you know, probably logarithmic. But, in the regression case, learning was expensive and the querying was easy, so we swapped around, that's exactly right. So, why would you care about that, well, let's see, I'll point out something, which is though, even though we swapped out what was expensive in terms of time and what wasn't, you'll notice that. It's only logarithmic at query time for these first two but it's linear for the learning time, in, linear regression, so doesn't that mean that linear regression is always slower and worse? >> No really, because we only have to learn once, but we can query many, many times."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,7-8,">> Right, right. So I guess if we query more than, you know, n times for example ,it'll certainly be, worse overall. In terms of running time. >> That's right. >> Okay. >> Though, it's, though it's interesting, because like when I see numbers like this, my, my algorithm, hat tells me that I should try to balance them a little bit more. Like, here it's, it's you can make, learning ,essentially free and the other one you can make querying essentially free. Really you want to split those, somewhat evenly. Though it's, not obvious to me how you would do that. Like, square root of n, learning time and then square root of n query time or something like that. >> Yeah, but you did say something else that was important right? Which is that you only have to learn once. >> Yeah, It's true. >> So, the balance you know, really depends on how often you're going to do querying and exactly, what power it gives you. I mean, the trade off is really there. Don't you think? >> Yeah, I guess so. I mean so, so specifically, in the, in the version where you just query ones. >> Right. >> Then the balance thing could be more interesting. >> Sure, okay, cool. All right anything else you want to observe about this. Let's see, we got the trade off between learning versus"
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,8-9,"querying. So, either you do all your work upfront, or, you put it ,off ,and do your work only, when you're forced to at query time. >> Yeah, I guess, well one thing, is, I want to point out that there's a nice Mr. Rodgers, reference in the title. That was, that was very cool. >> Thank you very much. And the second thing, is that it does strike me, in a sense, that what's going on here for the nearest neighbor algorithms, is that you just put off ,doing any work until you absolutely have to. >> Mm-hm. >> Which strikes me as kind of a procrastinatory approach. >> So that's a good word, that you used there, procrastinate. The words that people use, in the literature, are ,uh, lazy. >> Mm. >> They say that these are lazy learners, versus something like linear regression, which is an eager learner. >> Eager. >> Yes. So, linear regression, is eager, it wants to learn right away, and it does, but nearest neighbor algorithms are lazy. They want to put off, learning until they absolutely ,have to, and so we refer to this class ,as lazy and this class as eager."
1t6Wm37e1VM,Wont You Compute My Neighbors Quiz Solution - Georgia Tech - Machine Learning,9-10,">> I See, so I guess its the case, that, if we never query it, then the lazy learner definitely comes out ahead. >> Right, that makes sense. >> Yeah. >> It's just in time learning, or JIL. [LAUGH] Or JITL, I guess, which doesn't roll off the tongue anywhere near as well. Okay, cool. So we've gotten through this quiz. Would you like to do another one? >> Yeah, I just have to get this JITL off my tongue. >> [LAUGH]"
eBt8vTvmsV4,Domain K NNowledge Quiz - Georgia Tech - Machine Learning,0-1,"Okay Michael, so here's our second ,quiz, is a row. In the last quiz, we talked about running time and space time, but now we're going to talk about ,how the k-nn algorithm, actually works. And in particular how different choices, between distance metrics, values of k, and how you're going to put them together, can give you different answers, okay? So, what I have over here on the left is training data. This is a regression problem and you're training data is made up of xy pairs. X is two dimensional. Okay? So this is a function from R squared to some value in R1. Okay? >> Mm-hm. >> So, the first dimension represents, something and the second dimension, represents something. And then there's some particular, output over here. And what I want you to do, is given a query point, 4, 2 produce what the proper y or output ought to be, given all of this training did. You're with me?"
eBt8vTvmsV4,Domain K NNowledge Quiz - Georgia Tech - Machine Learning,1-2,">> Yeah. >> Okay, so I want you to do it in four different cases, I want you to do it in the case where, your distance matrix is euclidean, Okay. >> The distance metric, in R2? >> Yes. >> Oh I see because, we're going to measure the distance between the query and the different data points. >> Right. >> Yeah. Okay. Uh-huh. >> Mm-hm. So it's euclidean, for a case of one nearest neighbor and three nearest neighbor and I want you to take, for example, in the three nearest neighbor case. I want you take their output and average them. Okay? >> Okay. >> Now, in the I also want you to do the same thing. But in the case where instead of using Euclidean distance, we use Manhattan distance. But again, for both 1 nearest neighbor and 3 nearest neighbor And in any case where we have ties, like in three nearest neighbor where we absolutely have to have at least three of these things show up, just let 'em average. Okay? >> Got you. >> Now we're doing averaging instead of straight voting, because, this is a regression problem. >> Got it. >> Okay. Any questions?"
eBt8vTvmsV4,Domain K NNowledge Quiz - Georgia Tech - Machine Learning,2-3,">> Maybe. Let's see. Three nearest neighbor. And so if there's ties, we, we use the college ranking trick of including everybody who's at least as good as the k, largest or k closest. >> Yes, exactly. >> Okay, yeah, no I think, I think I can take a stab at this. >> Okay, cool then go."
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,0-1,"Alright Michael, you ready? >> Yeah. >> Okay. What's the answer? Walk me through. >> I will walk you through. Alright. So let's, let's do this. Let's write the Euclidean distance. Well let's write the Manhattan distance, because I don't, I don't want to take square root to my head. >> Okay. >> Let's write the Manhattan distances next to the Xs. >> OKay. >> Or the Ys. >> Alright. >> Either way. >> Let's do it next to the Xs. So this is the Manhattan distance or MD as the cool kids call it. >> [LAUGH] >> Is that true? >> Yea. >> The cool kids called it L one. >> No, no, no have you ever heard a cool kid ever say something like L one? >> Well, to me the cool kids are the people at neps who know more math than I do. Yea, do you think any of them are going to watch this video? Actually I'm afraid all of them are going to watch this video. >> Now I'm really afraid. >> Mm-Hm so you better get it right, every ones watching. >> All right, well let me do, let me complete the Manhattan distances. So the first one what you do is you take the 1 minus 4. >> Mm-Hm. >> And that's three. And you take the 6 minus 2 and that's 4. And you add the two together and you get 7. Which interestingly is"
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,1-2,"the same as y, but I think that's a coincidence. >> Okay. [CROSSTALK] >> And now I'll do all the rest of them 'cause I pre-computed them of Four, six, eight, four, six. Alright, so now we've got it set up so we can do one and three nearest neighbor relatively quickly. So, the one nearest neighbor, the closest distance, is four. >> Mm--hm. >> But unfortauntely there are two points that have that two comma four in set number one. We have outputs of eight and 50 because they. Almost agree with each other. >> Uh-huh. >> Not. And if we take the average of those two things we get 29. >> Yep. That is correct Michael. >> Great now in terms of the three nearest neighbors we have the fours and the sixes. >> So the four, three nearest neighbors. >> Yep. >> Somewhat awkwardly. And the we have the average of those things which is what. Eight, fifty and sixteen and sixty eight which gets us thirty five point five."
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,2-3,">> Right. Obviously. [LAUGH] Okay. Alright, so that was pretty straightforward. And those answers aren't too far off from one another. So what about the Euclidean case? >> Alright, so one thing to point out. I, I was worried about computing square roots but it occurs to me that I actually don't have to compute square roots because that's the monotonic transformation, and we only care about the orders. >> Hm, okay. >> So for Euclidean distance, or as I like to call him casually, ED, >> Mmhm. >> We can just take the square differences summed up. >> Okay, so this would be ED squared. >> Yes, it would be ED squared. >> Okay, ED. >> Good. So the first one, it'll be the one minus four is three, squared is nine. And the 6 minus 2 is 4, squared is 16. And 9 plus 16 is 25. So the first one will be 25. >> And notice the square of 25 is pretty easy to compute. >> Yeah, but the other ones aren't going to be. It just so happens that we've got a pythagorean triple on our hands. >> Mm. I love those. >> Al right so the remaining ones, the x squared are eight, 26, 40, ten, and 20."
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,3-4,">> Hm, none of those are easily square rootable. >> Exactly, though 40 feels like it really was trying and failed. >> Yeah. An eight over shot and now it's a perfect cube. So, eight is the smallest distance. >> Yep. >> And again, seemingly, coincidentally, they Y value associated with that, is eight. >> Hm. >> So an eight, eight is our answer. >> Good and that's correct. >> And the three closest are eight, ten and 20. >> Mm-hmm. >> And if we average the Y values for those that's eight, 50 and 68, which gives us an average of 42. The meaning of life, the universe. And pretty much everything? >> Yes! And that is absolutely correct. So that's kind of That's kind of cool that you get completely different answers depending upon what you do. >> Yeah, it does seem very different, doesn't it? I mean there's like several orders of magnitude spread here. >> Well, that's. >> Maybe not orders of magnitude but orders of doubling."
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,4-5,">> Yes, there are orders of doubling spread. Well, you know what Michael, I actually had a specific function in mind when I did this. >> Okay! Let's find out which one is the right one! >> Well, the function I had was Y was equal to the first dimension squared plus the second dimension. So, let's call that X1 and X2, and this was actually the function that I had in place. So, you square the first term and you add the second. >> Okay, and so like looking at the second last one, for example, seven squared is 49 plus one is 50 Oh, [UNKNOWN]. It's very consistent. >> Thank you. So what would be the actual answer for four comma two? >> Okay so four squared is 16 plus two is 18. Which is close to none of them. >> Right. So there's a lesson here, there's several lessons here. And one lesson I don't want you to take away. So here's the lesson. So I actually had a real function here. There was no noise. It was fairly well represented. The proper answer was 18 and basically none of these are right. But the first thing I want"
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,5-6,"you to notice is you get completely different answers, depending upon exactly whether you do one versus three, whether you do Euclidean versus Manhattan. And that's because these things make assumptions about your domain that might not be particularly relevant. And this sort of suggests, that maybe this thing doesn't do very well. Uh, kNN doesn't do very well because none of these are close to 18. That seems a little sad. But I've good new for you Michael. >> Okay. >> The good news is that, actually kNN tends to work really, really well. Especially given it's simplicity, it just doesn't in this particular case. And there's really a reason for that, and it has to do with this sort of. Fundamental assumptions in bias of kNN, I happen to pick an example that sort of violates some of that bias. So I think it's worth to take a moment to think about what the preference bias is for kNN and to see if that can lead us to understanding why we didn't get anything close to 18 here. >> Okay that sounds useful."
X8tm6x2k_gQ,Domain K NNowledge Quiz Solution - Georgia Tech - Machine Learning,6-7,">> Okay, so let's do that."
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,0-1,"Ok, Michael, so I'm going to talk a little bit about bias. In particular, the preference bias for K [INAUDIBLE]. So, let me remind you what preference bias is. Preference bias is kind of our notion of why we would prefer one hypothesis over another. And they say all things, other things being equal. And what that really means is, it's the thing that encompasses our belief. About what makes a good hypothesis. So in some of the previous examples that we used it was things like shorter trees, smoother functions, simpler functions, Occam's Razor, those sorts of things were the ways that we expressed our preferences over various hypothesis. And kNN is no exception. It also has preference by its built in as does every algorithm of any note. So I just wanted to go through three that I thought of is as being indicitive of this bias. And they're, kind of all related to one another. So the first one"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,1-2,"is a notion of locality. Right? There's this idea that near points are similiar to one another. Does that make sense to you? >> Yeah. Yeah. That was really important. It came out nicely in the the real estate example. Right. So the whole idea. The whole thing we are using to generalize from one thing to another is this notion of nearness. >> Right. And exactly how this notion of nearness works out. Is embedded in whatever distance function we happen to be given. And so, there's further bias that might come out, based upon exactly the way we implement distances. So, in the example we just did, euclidian distance is making a different assumption about what nearness or similarity is, compared to Manhattan distance, for example. >> So is there like, a perfect distance function for a given problem? >> There's certainly a perfect distance function for any particular problem. >> Yeah, that's what I mean. Not one that works for the universe, but one, like, you know, if I give you a problem and you can work on it all day long. Can you find, is there a notion that there''s a distance function that would capture things perfectly? >> Well, it has to be the case for any given fixed problem. That there"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,2-3,"is some distance function that minimizes, say, sum of squared errors or something like that. First is some other distance function. Right? >> Okay. >> That has to be the case. So there, there always to be at least one best distance function given everything else is fixed. >> That makes sense. >> Right. Now, what that is, who knows. Maybe you finding it might be. Arbitrarily difficult. Because there's at least an infinite, there's at least an infinite number of distance functions. >> Well yeah, I was thinking that, that for latter to find distance functions to be anything we want. What about a distance function that said the distance between all the things that have the same answer, is zero. >> Mm-hm. >> And the distance between them and the ones that have different answers is you know, infinity or something big. >> Yeah. >> And then, then the distance function, like, somehow already has built in the solution to the problem because it's already put the things that have the same answers together. >> Right, you could do that, and of course, doing that would require again solving the original problem. But yeah, so."
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,3-4,"So, such a function has to exist, or, well, you know, there's always noise. What if there's noise in your data, you know? But some such function like that has to exist, the question is finding it. But I think the real point to take there is, there are some good distance functions for our problem and there are some bad distance functions for our problem. And how you pick those is really fundamental assumption your making about the domain. That's why it's domain knowledge. >> Yeah, that sounds right. >> Mm 'Kay. So, locality however it's expressed to the distance function, that is similarity. It's built in to kNN that we believe that near points are similar. Kind of by definition. That leads actually to the second preference bias which is this notion of smoothness. Alright. That we are by choosing to average. And by choosing to look at points that are similar to one another. We are expecting functions to behave, smoothly. Alright, so, you know, in the 2D case. It's, it's kind of easy to see, right? You, you, you, you have these, these sort of points and you're basically saying, look, these two points should somehow be"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,4-5,"related to one another more than this point and this point. And that sort of assumes kind of smoothly changing behavior as you move from one neighborhood to another. Does that make sense? >> I mean, it seems like we're defining to be pretty similar to locality. >> In this case. So I'm, I'm drawing an example, such that, you know, whatever we meant by locality has already been kind of expressed in the graph. >> Okay. >> And you know, by picking, you know, this is really for pedagogical reasons. You know can imagine, this you know, these are points that live in 77,000 dimensions, and it's impossible to actually visualize them much less draw them. And I could try. [LAUGH] But here's, here's three dimensions and here's the fourth dimension. I think I'm going to get tired before I hit seven and seven thousand but, you know, you kind of, you kind of get the idea, right? That, if. In, you know, if you can imagine in your head points that are really near one another in some space, you kind of hope that they behave similarly. Right. >> Right. Okay, so locality and smoothness. And I think these make sense. I mean, these, this is hardly the only algorithm that makes these kind of assumptions. But there is another assumption which is a bit more subtle I think. Which"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,5-6,"is worth spending a second talking about, which is, for at least the distance functions we've looked at before. The Euclidian distance and the Manhattan distance. They all kind of looked at each of the dimensions, sort of, and subtracted them, and squared them, or didn't, or took their absolute value and added them all together. What that means is, we were treating, at least in those cases, that all the features mattered. And not only did they matter, they mattered equally. Right. So think about the the last quiz I gave you. Right. It said y equals x 1 squared plus x 2. And you noticed we got answers that were wildly off from what the actual answer was. Well if I know that the first dimension. The first feature is going to be squared and the second one is not going to be squared. Do you think either one of these features is more important or more important to get right? >> Okay. Right. Trying to think about what that might mean. So, if, yea its definitely the case that when you look"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,6-7,"for similar examples in the database you want to care more about X1 because a little bit of a difference in X1 gets squared out. Right? It can lead to a very large difference in the corresponding Y value. Whereas in the x2's, it's not quite as crucial. Th, th, the, if you're off a little bit more, then you're off a little bit more, it's just a linear relationship. So yeah, it does seems like that first dimension needs to be a lot more important, I guess, when you're doing the matching. Then the second one. >> Right so, we probably would have gotten different, I'm not going to go through this but, we probably would have gotten different answers if, in the Euclidian or Manhattan case we had instead of just taking the difference between the first two The first dimensions, we had taken that difference and squared it. And then in the case, including this and squaring it again, and then some of those things that were closer in the first dimension instead of the second dimension would've looked more similar and we might've gotten better answer. That's probably a good exercise to go back and do for someone else. >> [LAUGH] Yeah, I was thinking of doing it right now, but yeah, probably should leave it for other people. >> Well you can do it if you want to. So did you do it Michael?"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,7-8,">> I did. >> And? >> So it's a kind of now a mix between the Manhattan distance and the Euclidian distance. So, I'm taking the first component, take the difference, square it. >> Mm-hm. >> Take the second component, take the difference, absolute value it. And add those two things together. >> Sure. >> All right. So if I do that, with one nearest neighbor, I still get that tie, but the output answer ends up being 12. >> Hm. Which is better than 24.7. >> And that's better than eight, which is what it was before. So the eight has gone up to 12, which is better than the other one, which I think was 35.5, comes down to 29.5 Close here again to the correct answer which is eighteen. So in both cases it kind of pushed in the right direction, it was using more, of the, the answers that were relevant and fewer of the answers that were not relevant. >> Right. There you go. So the notion of relevance by the way, turns out to be very, very important. And highlights a weakness of kNN. So this brings me to a kind of theorem or fundamental"
BXX_L4vd4Bs,K NN Bias - Georgia Tech - Machine Learning,8-9,results of a machine learning that is particularly relevant to kNN but its actually relevant everywhere. Do you think its worth while to mention it? >> Sure it sounds very relevant. >> Alright let's do it.
QZ0DtNFdDko,Curse of Dimensionality - Georgia Tech - Machine Learning,0-1,"Okay, Michael. So this notion of having different features or different dimensions throw us off has a name and it's called the Curse of Dimensionality. >> Oh, nice audio effect. >> I did like that effect in post-production. And it refers to well, a very particular thing. So let me just read out what it refers to. As the number of features or equivalently ,uh, dimensions grows that is as we add more and more features we go x of 1, x of two then we add x of three, add more and more of these features. As those features grows or as the number of dimensions grow ,the amount of data ,that we need to generalize accurately also grows exponentially. Now this is a problem of course because Exponentially means, bad in computer science land because when things are exponential they're effectively untenable. You just, you just, you sort of can't win."
QZ0DtNFdDko,Curse of Dimensionality - Georgia Tech - Machine Learning,1-2,">> I think everybody knows that in the sense that if you look, I've done this experiment actually, if you look in the popular press like, you know, Time Magazine Or New York Times, USA Today. People will use the word exponentially sometimes to mean exponentially, and sometimes to mean, a lot. >> Yeah that's actually a pet peeve of mine. The whole notion of, >> Me too. >> Oh, it's exponentially bigger. No, that's, that's not meaningful. If you're saying I have one point. And then I have another point, and I want to say this one point is exponentially bigger than this one. That's meaningless! It's also liberally bigger than that one. Exponentially refers to a trend. >> Again, their,their,their not talking about the mathematical relationship. They just mean a lot. >> Okay, so they're wrong. And it bothers me deeply but I'm willing to accept it for the purposes of this discussion. Okay. Exponentially means bad. It means that we need more, and more, and more, and more data as we add features and dimensions. Now as a machine learning person this is a real problem right, because What you want to do, or like what your instinct tells you to do is, oh ,we've got this problem, we've got a bunch of data, we're not sure what's"
QZ0DtNFdDko,Curse of Dimensionality - Georgia Tech - Machine Learning,2-3,"important. So why don't we just keep adding more and more and more features. You know, we've got all these sensors and we'll just add this little bit and this little bit, and we'll keep track of GPS location and we'll see the time of the day and we'll just keep adding stuff and then we'll figure out which ones are important. But the curse of dimensionality says that every time you add another one of these features. You add another dimension, to your input space, you're going to need exponentially more data, as you add those features, in order to be able to generalize accurately. >> Mm. >> This is a very serious problem, and it sort of captures, a little bit of what the difficulties are in k and n. If you have a di, if you have distance function or a similarity function, that assumes that everything is Relevant, or equally relevant, or important, and some of them aren't. You're going to have to see a lot of data before you can figure that out, sort of before it washes itself away. >> [CROSSTALK] >> Yeah, that makes a lot of sense. >> Yeah, it seems a little scary. So, you know, I think you can say these words, and the words sort of make sense, but I think it helps to kind of draw a picture,"
QZ0DtNFdDko,Curse of Dimensionality - Georgia Tech - Machine Learning,3-4,and so I'm going to draw a little picture. Okay? >> Yeah. >> All right.
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,0-1,"Okay, Michael, so let's, let's look at this little line segment, okay? And then say I've got ten little points that I could put down on this line segment, and I want them all to represent some part of this line, alright? That's kind of K nearest neighbor-y/-ish. So, I'm going to put a little X here, I'll put one here, I'll put one here, put one here, put one here, here, here, here, here, here. Is that ten? Three... six. Nine, ten. Ten. Okay. And let's pretend I did the right thing here and I have them kind of uniformly distributed across the line segment. So that means each one of these points is sort of owning, an equal size sub segment of this segment. Does that make sense? >> Yeah, so, so it's representing it in the sense that, that point. Uh,when you're trying to estimate values of other places on the line it's going to default as the nearest neighbor to being that point so there's a very small little"
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,1-2,"neighborhood of the red line segment that is covered by each of the green X's. >> That is exactly right and in fact each one of these green X's represents. How much of this segment? >> Each of the green X's covers one tenth? >> That's exactly right. You cover one tenth. Alright Michael, so let's say I move from a line segment now to a two dimensional space. So a little square segment. If that's the right technical term. And I've taken my little ten x's, and I put them down here before. Well, here's something you'll notice; you'll notice that each one of these x's is going to still end up representing one-tenth of all of this space, but you'll also notice that, that, that it's representing now you know. Really really really really big. >> I see. >> So one way of putting it is, you know if you think about the farthest point, as opposed to the furthest point which would be incorrect. >> [LAUGH] >> The farthest point that this particular first x"
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,2-3,"over here is representing, its got some distance here. Over here, the farthest point from this x, the distance is very, very far away. So, a question would be, how can I make it so that each of the x's I put down represents the same amount of. I don't know diameter or distance as the xs in this line segment over here. So what do you think I have to do? >> I feel like you need to fill up the square with xs. >> Yeah, that's exactly right so let's do that. So filling em up Michael as you suggested. You'll notice that at least if we pretend that I drew this right. Each of these X's is now going to end up being the nearest neighbor for a little square like this, and the diameter of these little squares are going to be the same as the diameter of these little line segments. >> Yeah, I agree for some definition of the word diameter. >> Yes, and for some definition of our demonstration. Okay, so how many of these X's are there, Michael? Can you tell? You want to count? >> [LAUGH]."
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,3-4,"I'm going to multiple [CROSSTALK] cause it looks like you did ten by ten so that'll be 100. >> That'll be 100. So each one now holds a hundredth of the space, and I went from needing ten points to, of course, 100 points in order to cover the same amount of space. >> Alright, so that definitely seems like the mild rebuke of dimensionality. >> Yes. >> But doesn't seem that bad. >> Okay well, what happens if I now move into three dimensions? So now, if I want to cover the same amount of, you know, diameter space for, you know, sufficient definition of diameter. I'm going to have to do a bunch of copying and pasting that I'm not willing to do so, you know, there would be more x's here and you know, there will be x's there and an x here and it'll just kind of go and fill up some space and you know, I'm not going to do this whatever but [SOUND] and you'll get x's everywhere. And you notice, I need a lot more X's than I had before. And by the way, I'm just showing you the outside of this little cube, there are actually X's on the inside as well, that you can't see. How many X's do you think I have?"
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,4-5,">> I don't think you drew any X's. You're just like scribbling on the side of the cube. >> These are X's. >> You, you were doing so well for awhile, and then just lost it entirely. >> Well, wouldn't you lose it if you had to write 1000 x's. >> Hm. No because I would use computers to help me but yes, yes it is very frustrating to have to have that many x's. And so but in particular in this case we're talking about data points in a nearest neighbor method and that, boy that does seem like a big growth from ten to a 100 to 1000. >> In fact the growth is, exponential. >> Exponential >> >Right. So if we went into four dimensions, which I'm not going to draw, then we would need not 1,000, but 10,000 points. And if five dimensions we would need 100,000 points. And in six dimensions, we would need 1,000,000 points. And so on and so forth. So something like. Ten to the D, where D is the number of dimensions. >> Wow. >> Right. So this is really problematic right."
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,5-6,"In my little nearest neighbor method, wanted to be able to say, well, I want to make sure the neighborhood remains small, as I add dimensions, I'm going to need to grow the number of points that I have in my training set exponentially. And that's really bad. And by the way, this isn't just an issue of kNN. This is true in general, don't think about this now as nearest neighbors in the sense of kNN, but think of it as points that are representing or covering the space. And if you want to represent the same sort of hyper-volume of space as you add dimensions, you're going to have to get exponentially more points in order to do that. And coverage is necessary to do learning. So the curse of dimensionality does not just to kNN. It is a curse of dimensionality for ML period [SOUND]. >> You mean for me? >> Yes. Because of [INAUDIBLE] >> [LAUGH] Okay. And that seems really problematic because it's very natural to just keep throwing dimensions into a machine learning problem. Like it's, it's having trouble learning. Let me"
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,6-7,"give it a few more dimensions so, to give it hints. But really what you're doing is just giving it a larger and larger volume to fill. >> Yeah. And it can't fill it unless you give it more and more data. So you're better off giving more data than you are giving more dimensions. >> Zoinks. >> Mm-hm. There's an entire series of lessons that we will get eventually that, that deals with this issue. >> The issue of? >> Dimensionality. >> Finding the right dimensionality? >> Yeah. >> That would be a useful thing. >> It would. But it's far off in the future. It's like infinitely far in the future. So we'll worry about that in a few weeks. >> Okay. >> Okay. All right. So there you go, Michael. Curse of Dimensionality is real and it's a real problem. >> Where did that term come from, it's a cool term. I think it came from, oh what's his name. Bellman. >> Oh, Bellman, like the dynamic programming guy. >> Yeah, the dynamic programming guy, uh,the Bellman of Bellman equation guy. >> Which we haven't gotten to yet in the course. >> Which we haven't gotten to in the course but we will get to in the course. Because it's central. So it looks like actually, the element's central to a lot of things."
OyPcbeiwps8,Curse of Dimensionality Two - Georgia Tech - Machine Learning,7-8,>> Wow. >> Sometimes it gives us equations that helps us but sometimes it gives us curses. >> [LAUGH] Curses Betterman. Foiled again. >> [LAUGH]
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,0-1,"Okay, Michael so we talked a little bit about the curse of dimensionality, but I think it's worthwhile to talk about some other stuff that comes up. We've been sort of skirting around this and you know bring it up in various ways throughout our discussion so far. But I think it's worthwhile kind of writing them all down on a slide and trying to think through them for a little bit. So ,uh, the other stuff that comes up in [UNKNOWN] mainly comes up in these sort of assumptions we make about parameters to the algorithm. So the one we talked about ,uh, probably the most is our distance measure, you know our distance between some X and some query point Q and we've explored a couple. We looked at Eucudean and we looked at Manhattan. And we even looked at weighted versions of those. And this really matters, I've said this before but I really think it bears repeating that your choice of distance function Really matters. If you pick the wrong kind of distance function, you're just going to get very poor behavior. >> So I, so I have a question about these these distance functions. So you mentioned Euclidean and Manhattan,"
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,1-2,"are there other distance functions that the students should know? Like, things that they, that might come up, or things that they should think of first if they have a particular kind of data? >> yeah, there's a, there's a ton of them. I think Well, first off, it, it's probably worth pointing out that this, this notion of weighted distance is one way to deal with the curse of dimensionality. You can weight different dimensions differently. And that would be one, and you might come up with sort of automatic ways of doing that. That, that's sort of worth mentioning. But you will notice that both Euclidean and Manhattan distance at least as we have talked about them, are really useful for things like regression. Their kind of assuming that you have numbers in that subtraction kind of makes sense. But there are other functions, distance functions that you might do if you are dealing with cases like, I don't know Discrete data, right? Where instead of it all being numbers, it's colors, or something like that. Alright so, your distance might be mismatches. For example, or it might be a mixture of those. In fact, one of the nice things about KNN, is that"
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,2-3,"we've been talking about it with points, because it's sort of easy to think about it that way. But this distance function is just a black box. You can take Arbitrary things and try to decide how similar they are based on whatever you know about the domain and that could be very useful. So ,you could talk about images right, where you take pictures of people and you know rather than doing something like a pixel by pixel comparison, you try to line up their eyes. And look at their mouths, and try to see if they're the same shape you know things like that, that might be more complicated and and perhaps even arbitrarily computational to determine notions of similarity so really this idea of distance in similarity tells you a lot about your domain and what you believe about it. ,another thing that's worth what what's pushing on a little bit is how you pick k. Well there's no good was to pick k you just You just have to know something about it, but I want to think about a particular case. Well, what if we end up in a world where K=N. >> Well, that would be silly. >> Why would it be silly? >> Well, so if K=N, then what you're doing is you're taking, so in the case of regression for example, you're taking all"
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,3-4,"of the data points and averaging the. Y values together. Basically ignoring the query. So, you end up with a constant function. >> But that's only if you do a simple average. What if you do a weighted average? >> A weighted average. So the near, the points that are the query are going to get more weight in the average, so that acually will be diffrent. Even though k equals n, it will be different depending on where you actually put your query down. >> Exactly. That's exactly right so, for example, if I have a little bunch of points like this say. Where you notice it kind of looks like I have two different lines here and I can pick a query point way over here, all of these points are going to influence me as oppose to these points and so I'm going to end up. Estimating with something that looks more like this because these points over here won't have much to say. But if I have a query point that's way over here somewhere these points are going to matter and I'm going to end up looking something looks a little bit more like this than like"
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,4-5,"that. Now I'm drawing these as lines. They won't exactly look like lines because these points will have some influence. They'll be more curvy than that. But the point is that near, near the place we want to do the query it will look To be more strongly influenced by these points over here or these points over here depending on where you are. >> Well that gives me an idea. >> Oh, what kind of idea does it give you? >> Well, what about instead of just taking a weighted average, what about using the distance matrix to pick up some of the points? And then do a different regression on that substantive point. >> Right, I like that. So we can replace this whole notion of average with a more kind of, regression-y thing. >> So it actually, instead of using the same value for the whole patch. Actually, it still continues to use the input values. >> Yeah. So, in fact, average is just a special case of a kind of regression, right? >> Mm hm, mm hm. >> Right? So this actually has a name, believe it or not. It's actually called locally weighted regression. Yeah, so this actually works pretty well and in place of sort of averaging function, you can do just about anything you want to."
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,5-6,"You could throw in a decision tree, you could throw in a neural network, you could throw in lines do linear regression. You can do, almost anything that you can imagine doing. >> Neat, >> Yeah. Add that works out very well. And again, it gives you a little bit of power. So here's something I don't think is very obvious until it's pointed out to you. Which is this notion of replacing the average with a more general regression or even classification function. It actually allows you to do something more powerful than it seems. So let's imagine that we were going to do locally weighted regression and we were going to do, in fact, linear regression. So, what would locally- weighted linear regression look like? Well, if we go back to this example over here on the left basically, you take all the points that are nearby and you try to fit a line to it. And, so you would end up with stuff that looked, pretty much, like this. While you're over here, you would get the line like this, but while you were over here you'd get a line like this. Then, somewhere in the middle you would get lines that started to look like this and And you would end up with something that kind of ended up looking"
_GYhs4re3JA,Some Other Stuff - Georgia Tech - Machine Learning,6-7,"a lot like a curve. So that's kind of cool because you notice that we start with a hypothesis state of lines and this locally weighted linear regression. But then we end up actually being able to represent a hypothesis space that is strictly bigger. than the set of lines. Hm. So we can use a very simple kind of hypothesis space but by using this locally weighted regression we end up with a more complicated space that is complicated, that's made more complicated depending upon the complications that are represented by your data points. So this results, this sort of reveals another bit of power with kNN. Which is, it allows you to take local information and build functions or build concepts around the local things that are similar to you. And that allows you to make arbitrarily complicated functions. >> Neat. >> At least in principle. Okay, cool. Alright so you got all that? >> I, think so yeah. >> Okay, cool. So then, I think we should wrap up. >> Nice. >> Nice."
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,0-1,"Okay Michael so I think with that little bit of discussion, I feel like we're done. >> Cool! Alright. Well it's been nice talking to you. I hope the course went well and, oh you mean just for this lesson? >> Yeah just for this lesson. >> Alright. >> So let's. >> Well let's wrap up this lesson then. >> Yeah let's see what have we learned? So remind me Michael what have we learned? >> Well we were talking about instance based learning. >> That's true. That's the first thing we learned. You will notice by the way, I never actually told you why it was called instance based learning. >> Charles, why is it called instance based learning? >> I don't know but I am willing to guess that it has to do with a fact that we look at the exact instances that we have and we base our learning on that. >> Alright and we brought it up in by starting off thinking about eager and lazy learning. >> Right. What is the difference, Michael? >> I will tell you when I need to tell you. >> [Laugh] That's exactly right. >> So lazy learning is about putting off the work until it's actually needed. Eager is about, as soon as"
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,1-2,"the problem is posed, solve it. And then, you know, if you're lucky, the answer will eventually come in handy. >> Exactly right. Okay what else? >> So as a concrete example of a lazy learner we talked about k-nearest neighbor or k-NN. >> kNN. And this whole notion of nearest neighbor. Is in fact one way of talking about similarity functions. >> Right and the similarity functions play a really central role in all this. >> Right. Similarity. We talk about it as if they were distance functions. But distance is just another way of talking about, a similarity. So, this is actually keeping. K-nn was a specific, algorithm we used, and we talked about various versions of it, and, the nearest neighbor part really got us to think a little bit about similarity and distance and, and what all that means. A really important thing here is, I think, that similarity is"
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,2-3,"just another way of capturing domain knowledge. And K in k-NN is another way of capturing domain knowledge. And that if we saw through the quizes and some of our discussions, that this is actually very, very important. That domain knowledge matters. Now, we also talked about KNN in the context of both regression and classification. I see what you did there, 'Knnowledge', it's got KNN in it. >> >Okay, so yeah, classification and regression are different things. But, KNN can handle both of them. And, at the end of the day, that's all stuck in our notion of similarity, and our notion of averaging. Which we kind of took as an overall term, for a bunch of different things you might do, which some people find confusing. >> [LAUGH]. >> But I think that other people would really kind of understand what we mean. >> I'm very tempted to take that out of Wikipedia, but that would, that would just be rude. >> It would be rude. Anything else? We learned one big thing. >> We looked at how to compose different learning algorithms together. For example in the context of locally weighted linear regression. >> Mm hm."
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,3-4,">> We used this instance based idea along with linear regression to get something that was both locally smooth but globally bumpy. >> Right. So, I'm going to just say locally weighted regression. Where we can do any kind of regression we might want to. I was going to call that $X. So, stick in your favorite value. >> Let's see, what else? Oh, oh, a really big thing was Bellman's curse of dimensionality. >> Yes. >> And the idea there was that the more features that you include The more data you need to fill up that space. >> Yep, It's exponential. >> And in fact I even just I decided to go and play with this a little bit so that example that you were doing before where the y equals x1 squared plus x2 >> Mm-hm. >> When I gave it well as we saw in the example we gave it like ten or 12 examples and it did really badly. So it continued to do somewhat badly until I got to about 100,000 and then it was actually doing [LAUGH] really well."
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,4-5,">> Hmm. >> But that seems like an awful lot of examples for what is otherwise a very simple problem. >> Right. Well if you think about it, the amount of data you have to see to determine the relative. Relevance of the two different dimensions is quite a bit in that particular kind of function. >> Hm. >> Yeah. That's a lot of space to cover. All possible real values [LAUGH] across a potentially infinite space. >> Yeah, I guess that's true. >> Yeah, so the cursor dimensionality is real and we just sort of can't get around it. Although As I mentioned earlier we will see in the second part of the course ways that people try to get around the curse of dimensionality. >> Ahah! >> Mm-hm. Okay. >> Or at least blunt it. Right? >> Yeah or at least blunt it because you can't actually get around the curse of dimensionality, you can only deal with it. >> There is no free lunch. >> There is no free lunch. In fact, that's a theorem. >> [LAUGH] >> Isn't that a theorem? >> Yeah, I think so. >> What's the theorem?"
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,5-6,">> No free lunch. That any learning algorithm that you create is going to have the property; that if you average over all possible instances, it's not doing any different than random. >> Right. And, and another way of thinking about that, a practical way of thinking about that is; if I don't know anything about the data that I'm going to have to learn over. Then, it doesn't really matter what I do because there's all possible kind of data sets. However, if I have domain knowledge, I can use that to choose the best learning algorithm for the problems that I'm going to encounter. >> So does that mean that, that all of machine learning really comes down to, you have to already know what you need to solve the problem to apply these. Techniques to solve the problem? >> No, but you have to know a little bit about your problem in order to decide what to do. And in fact, you could make the argument that this entire class is about exposing the students to a wide range of techniques and giving them enough practice so that they can do a pretty good job of telling, given a problem. Would it be better to use this kind of technique or this kind of technique? Is K-nn a sort of"
sCB2j73jzbo,What Have We Learned - Georgia Tech - Machine Learning,6-7,"better way of approaching it? Decision tree a better way of approaching it? Um,It's a lot of what this class is about. Is helping them to get enough domain knowledge or enough knowledge anyways so that they can apply it to particular domains. >> Cool, so alright, that seems like a plenty useful lesson. >> Yes, it's a very hopeful note to end on, so let's end on that. >> Alright, see you next time. >> Alright, bye Michael."
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,0-1,"Hey Charles, how's it goin'? >> It's going pretty well Michael. How's it going with you? >> Good, thank you. >> Good, good, good. Guess what we're going to talk about today? >> Well, reading off this screen, it looks like maybe ensemble learning, and boosting, whatever that is. >> Yes, that's exactly what we're going to talk about. We're going to talk about a class of algorithms called ensemble learners. And I think you will See that they're related to some of the stuff that we've been doing already, and in particular we're going to spend most of our time focusing on, boosting. because boosting is my favorite of the ensemble learning algorithms. So you ready for that? >> Yeah! Let's do it. >> Okay. So, I want to start this out by, going through a little exercise with you. I want you to think about a problem. Okay. And the particular problem I want you to think about is, spam email. >> Mm, I think about that a lot. >> So, normally if we were thinking of this a classification task, right, where we're going to take some email and we're going to decide if it's spam or not. Given what we've talked about so far we would be thinking about using a decision tree or"
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,1-2,"you know neural networks or kNN whatever that means with email. We would be coming up with all of these sort of complicated things. I want to propose an alternative which is going to get us to ensemble learn. OK and here's the alternative. I don't want you to try to think of some complicated Rule that you might come up with that would capture spam email. Instead, I want you to come up with some simple rules that are indicative of spam email. Okay, so let me be specific, Michael. We have this problem with spam email. That is, you you're going to get some email message and you want some computer program To figure out automatically for you if something is a piece of spam or it isn't. And I want you to help write a set of rules that'll help me to figure that out. And I want you to think about simple rules, so can you think of any simple rules that might indicate that something is spam? >> Alright I can, yeah I can think of some simple rules. I don't think they would be very good, but they might better than nothing. Like If for example it mentions how manly I am, I, I would be, be willing to believe that"
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,2-3,"was a spam message. So like if the body of the message contains the word manly. >> Okay, I like that. like that when body contains manly. I like that rule, because I often get non-spam messages talking about manly. So I guess one man's spam is another man's normal email. >> [LAUGH] I guess that's true. >> Probably. Any other rules? >> Sure if it, you know if it comes from my spouse it's probably not spam. >> OK, so let's see, from spouse. >> Her name's Lisa. Now we're going to call our spouse. So let's say minus, I'm going to go to plus here, so we know some rules are indicitive of being spam, and some rules are indicitive of not being spam. Okay, anything else? >> Possibly the length of the message. I guess. Like what? >> I don't know. I don't know that this would be very accurate, but I think some of this, some of the spam I get sometimes is very, very short just like the, it's like the URL. Like hey, check out this site, and then there's a URL."
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,3-4,">> Hm, I like that. So, we'll just say short. Just contains URLs. Hm, I like those rules. Let's see if we can think of anything else. Oh, how about this one. It's just an image. >> Hm. >> I get a lot of those where it's just an image. >> I see, like in it's it's and if you look at the picture it's all various pharmaceuticals from Canada. >> Exactly. Here's one I get a lot. >> Hm, >> Lots of misspelled words that you end up reading as being a real word. >> Hm. But I don't know how I'd write that as a rule. Or you could just list the words. >> Like rules that, words that have already been modified in that way. I guess so. >> Yeah, kind of a, kind of a black list, a black list of words. >> Okay so, words like, I would say manly, but you were saying prawn. >> Or whatever that says. yeah, so they're and they're tons of these. Right? I mean, another one that's, that's very popular if you're old enough anyway is this one, remember this one?"
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,4-5,">> Oh, sure that was sometimes a virus, right? >> Yes. Our young, our younger viewers will not know this but this was one of the first big spam messages that would get out there. Make money fast. And there's tons and tons of these. We could come up with a bunch of them. Now, here's something they all kind of have in common, Michael, and you've touched on this all ready. All of them are sort of right. They're useful but no one of them is going to be very good at telling us whether a message has spam on its own. Right. So the word manly is evidence but it's not enough to decide whether something is spam or not. It's from your spouse, it's evidence it's not spam, but sometimes you get messages from your spouse that are in fact spam, because in fact, she didn't actually send them. You know, and so on and so forth. And sometimes she did email from Princes in Nigeria. I didn't. And they're not always spam. I, I actually do, but any case, sometimes people are asking you for money, and maybe that's message you want to ignore, but it isn't"
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,5-6,"necessarily spam. And some people are very interested in getting like this and don't consider it spam, right? >> So, so, okay, so I can see that these would all maybe provide some evidence, but it seems really hard tp figure out the right way of combining them all together to I don't know, make a decision. >> Right, this is exactly right. And by the way, if you think about something like decision tree, you could. There's really a sort of similar problem going on there. We can think of each of the nodes in a decision tree as being a very simple rule and the decision tree tells us how to combine them. Right? So, we need to figure out how to do that here and that is the fundamental notion of ensemble learning. >> But wait, isn't, couldn't you also do something similar with something like neural net. Right? Where each of these now becomes a feature and we're just trying to learn weights for combining them all together. So That would kind of satisfy what you were talking about. >> True, I mean I think the the difference here in this case and and I think you're absolutely right but one difference here is that typically with the new network we've already built the network itself and the nodes and we're trying to learn the weights whereas in something like a decision tree you're building up rules"
w75WyRjRpAg,Ensemble Learning Boosting - Georgia Tech - Machine Learning,6-7,"as you go along. And typically with ensemble learning you're building up a bunch of rules and combining them together until you got something that's good enough. But you're absolutely right. You could think of neural networks as being an ensemble of little parts. Sometimes hard to understand, but an ensemble nonetheless."
ZIf4I297fH8,Ensemble Learning Simple Rules - Georgia Tech - Machine Learning,0-1,"So, the characteristic of ensemble learning is first this, that you take a bunch of simple rules, all of which kind of make sense and you can see as sort of helping. But on their own, individually, do not give you a good answer. And then you magically combine them in some way to create a more complex rule, that in fact, works really well. And ensemble learning algorithms have a sort of basic form to them, that can be described in just one or two lines. So let me do that and then we can start wondering a little bit how we're going to make that real. So here's the basic form of an ensemble learning algorithm. Basically you learn over a subset of the data, and that generates some kind of a rule. And then you learn over another subset of the data and that generates a different rule. And then you learn over another subset of the data and that generates yet a third rule, and yet a fourth rule, and yet a fifth rule, and so on and so forth. And then eventually you take all of those rules and you combine them into one of these complex rules. So, we might imagine in the email case that I might look at a small subset of email that I know is already"
ZIf4I297fH8,Ensemble Learning Simple Rules - Georgia Tech - Machine Learning,1-2,"spam and discover that the word manly shows up in all of them and therefore pick that up as a rule. That's going to be good at that subset of mail, but not necessarily be good at the other subset of mail. And do the same thing and discover that a lot of the spam mails are in fact short or a lot of them are just images or just urls and so on and so forth. And that's how I learn these rules by looking at different subsets. Which is why you end up with rules that are very good at a small set of the data, but aren't necessarily good at a large set of the data. And then after you've collected these rules, you combine them in some way, and there you go. And that's really the beginning and the end of ensemble learning. >> So wait. So, when you say manly was in a lot of the positive examples. Do you mean like it distinguishes the positive and the negative example? So it should also not be in the negative examples. >> That's right. That's exactly right. So think of this as any other classification learning problem that you would have where you're trying to come up with some way to distinguish between the positives and the negatives. >> And, and now why does it, why are we are looking at subsets of the data? I don't understand why we can't just look at all, the whole data. >> Well, if we look at all of the data, then it's going to be hard to come up with these, these"
ZIf4I297fH8,Ensemble Learning Simple Rules - Georgia Tech - Machine Learning,2-3,"simple rules. That's the basic answer. Actually, ask me that question a little bit later, when we talk about overfitting, and I think I'll have a good answer for you. Okay, so here we go Michael. This is Ensemble Learning. You learn over a subset of the data over and over again picking up new rules and then you combine them and you're done."
ETleovojGA4,Ensemble Learning Algorithm - Georgia Tech - Machine Learning,0-1,"Here's the Ensemble Learning algorithm. We're done, Michael, we're done with the entire lesson. We don't have to do anything else anymore. We know that we're supposed to look over subset of data, pick up rules, and then combine them. So, what else do you need to know in order to write your first Ensemble Learning algorithm? >> So, I'm already kind of uncomfortable with this notion of"" combine,"" right? So, like, I can think of lots of really dumb ways to combine things. Like, choose one at random or, you know, I don't know, add em all up and divide by pi I mean so, so presumably there's gotta be some intelligence in how this combination is taking place >> Yes, you would think so, but your not at all bothered about how you pick a subset? >> Oh ,I was imaging you meant random subsets. >> Oh ,so you'd automated assumption about how we were going to pick a subset. You just [CROSSTALK] weren't sure how to combine them. Well actually let's explore that for a minute. Here's kind of the dumbest thing you can imagine doing. That turns out to work out pretty well. We're going to pick subsets, by, I'm going to say uniformly. Just to be specific about it. So ,we're going to do the dumbest thing"
ETleovojGA4,Ensemble Learning Algorithm - Georgia Tech - Machine Learning,1-2,"that we can think of, or one one of the dumbest things you could think of. Or maybe ,we should say simplest and not dumbest so as not to, to, to make a value judgment. That you can think of doing which would be to just uniformly randomly Choose among some of the data, and say that's the data I'm going to look at, and then I'm going to apply some learning algorithm to it. Is that what you were thinking of Micheal? >> Yeah. >> Okay, so just pick a subset of the data, apply a learner to it. I'll get some hypothesis out, I'll get some rule out. And now I'm going to combine them, so since were being simple. Why don't we try doing something simple for combining. Let's imagine, Michael, that we're doing a regression. What's kind of the simplest thing you could do if you have ten different rules which tell you, how you should be predicting some new data point? What's the simplest thing you could imagine doing with it? >> So, okay, so each of them spits out a number. I guess if we kind of equally believe in each of them, a reasonable thing to do would be to average. >> Great. So, a very simple way of combining, in the case of regression, would be to average them. We'll simply take the mean. And by"
ETleovojGA4,Ensemble Learning Algorithm - Georgia Tech - Machine Learning,2-3,"the way, why wouldn't we equally believe in each of them. Each one of them learned over a random subset of the data. You have no reason. >> Well.
>> To believe one's better than the other. >> There's a couple of reasons. One ,it could be a bad random subset. I don't know how I would measure that. >> I could be a good random subset. >> Yeah. Then we'd want, we'd want that to count more in the mean. But, but I guess what I was thinking more in terms of maybe for some of the subsets you know, it gets more error than others or it uses more complex rule than others or something. >> I could imagine that. Actually maybe we can explore how this sort of idea might go wrong. Let's, let's do that. Maybe we can do that with the quiz. You like quizzes, right? >> They're important."
NtPcPf4nmys,Ensemble Learning Outputs Quiz - Georgia Tech - Machine Learning,0-1,"Okay, so here's a quiz for you Micheal, here's the setup, you ready? You've got N data points. The learner that you're going to use over your subsets is a zeroth order polynomial. The way you're going to combine the output of the learners is by averaging them. So, it's just what we've been talking about so far, and your subsets are going to be constructed in the following way. You uniformly randomly picked them and you ended up with N different subsets or disjoint, and each one has a single point in it, that happens to be one of the data points. >> Okay i think i get that >> Right, so if you look over here on your left you got a graph of some data points and this is one subset This is another subset, that's another subset, that's another subset, that's another subset, that's another subset, that's another subset, got it. >> Yeah, now what do you want to know about it. >> Now what I want to know is when you do your ensemble learning you learn all these different, you learn all these different rules and then"
NtPcPf4nmys,Ensemble Learning Outputs Quiz - Georgia Tech - Machine Learning,1-2,"you combine them ,what is the output going to be? What does the ensemble output? >> And you want a number? >> I want a description and if the answers a number that's a perfectly fine description. But I'll give you a hint, it's a short description. >> A short description of the answer. Okay, I'll think about it. >> Alright."
Lc5QcpEdySE,Ensemble Learning Outputs Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay Michael have you thought about it? Do you know what the answer is? >> Yeah. I think, you know, you asked it in a funny way, but I think, what you're asking maybe was pretty simple. So let, let me, let me see if I can talk it through. So ,we've got n data points, each learner is a zeroth order polynomial. So you, you said the ensemble rule is that you learn over a subset, a zeroth order polynomial is just (no period) Well, we said that the thing that minimizes the average. Sorry, that minimizes the expected error, or the squared error [INAUDIBLE] it's just the average. So, if the sets are indistinct sets, with one data point each, then each, of the individual learners, is just going to learn the average. Then they get, not the average sorry. The actual output value of each individual point is the average, and then the combining algorithm, to combine all the pieces of the ensemble into one answer, combines with the mean. So ,it's going to combine the mean of those each of which is the data point, so it's the mean of the data points. So, the ensemble"
Lc5QcpEdySE,Ensemble Learning Outputs Quiz Solution - Georgia Tech - Machine Learning,1-2,"outputs, I don't know, I'd say average or mean? >> Yes. >> Or zeroth order polynomial of the data set, or, you know, one node decision tree, or ,uh. >> A constant? Which happens to be the mean of the data. Haven't we seen this before? >> It seems to come up a lot, when we are outputting very simple hypotheses. >> Right. And the last time we did this, if I recall correctly, this is what happens ,if you do an unweighted average with kNN where k is equal to n. >> Oh, right. Like, like, right. An N-NN. >> N-NN. >> Mm. >> Mm, so we should probably do something a little smarter than this then. And, I thought that we might look at some of the housing data, because, no one's started looking at the housing data yet. [LAUGH] Okay, so let's look at that right quick and see if we can figure out how this works. And then see if we can do something a little bit better, even better than that. Okay?"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,0-1,"Alright, Michael, so, here's what you have before you. You have the same housing data that we've looked at a couple of times before. I've, for the sake of readability, I've drawn over, some of the data points so that they're easier to see. This is exactly the data, that we've always had. Okay? >> Okay. >> Now, you'll notice that I marked one of them as green, because here's what we're going to do. I'm going to take the housing data you've got, I'm going to do some ensemble learning on it. And I'm going to hold out the green data point. Okay? So of the nine data points, you're only going to learn on 8 of them. And I'm going to add that green data point as my test example and see how it does. Okay? >> Okay. So that sounds like, cross validation. >> It does. This is a cross validation. Or you could just say, I just put my training set and my test set on the same slide. >> Okay. >> Okay, Michael, so the first thing I'm going to do is I'm going to pick a random subset of these points. And just for the sake of the example, I'm going to pick five points"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,1-2,"randomly. And I'm going to do that five times. So I'm going to have five subsets of five examples. And by the way, I'm going to choose those randomly, and I'm going to choose them with replacement. So we're not going to end up in the situation we ended up just a couple of minutes ago where we never go to see the same data point twice. Okay? >> Yeah. >> Alright. So 5 subsets of 5 examples, and then I'm going to learn a third order polynomial. And I'm going to take those 3rd order polynomials. I'm just going to learn on that subset, and then I'm going to combine them by averaging. Want to see what we get? >> Oh, yeah, sure. >> So here's what you get, Michael. Here I'm showing you a plot over those same points, with the five different 3rd order polynomials. Can you see them? >> Yeah. They're, right. There's like a bunch of wispy hairs. >> Just like most third order polynomials. And as you can see they're, they're kind of you stare at them and you see their kind of similar. But some of them they veer off a little bit because they're looking at different data points. One of them actually very hard to see because it's only one like"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,2-3,"this. Actually veers off like this because just, purely randomly, it never got to see the two final points. >> I see. But they all, but they all seem to be pretty much in agreement, like between points three and four. There's a lot of consistency there. >> Right. Because just picking five of the subsets you seem to be able to either get things on the end, or you get things in the middle. And maybe one or two things on the end it sort of works out. Even the one that doesn't see the, the last two points still got to see a bunch of first ones and get this part of this space fairly right. >> Cool. >> Okay. So the question now becomes how good is the average of these compared to something we might have learned over the entire data set? And here's what we get when do that. So what you're looking at now Michael, is the red line, is the average of all of those five third order polynomials. And the blue line, is the fourth order polynomial that we learned when we did this"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,3-4,"with simple regression, a couple of lessons back. >> Okay. >> And you actually see them pretty close. >> Why is one of them a fourth order, and one a third order? >> Well what I wanted to do is try a simpler set of hypothesis, than we were doing, than when we were doing full blown regression. So third order simpler than fourth order. So, I thought we'd combine a bunch of simpler rules. Then the one we had used before and see how well it does. >> You want to know how well it does? >> I would! >> Well it turns out that on this data set and I did this many, many, many times just to see what would happen with many different random subsets. It typically is the case that the blue line always does better on the training set, the red points, than the red line does. But the red line almost always does better on the green point on the test set or the validation set. >> Interesting. >> That is kind of interesting. So wait, so let me get this straight. It seems sort of magical. So, so it learns an average of third degree polynomials, third order polynomials, which is itself a third order polynomial. But you're saying it does better by doing"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,4-5,"this kind of trick than just learning a third order polynomial directly. >> Yeah, why might you think that might be? I have a guess, you tell me what you think. >> Wow, so well, I mean, you know, the danger is often over fitting, over fitting is like the scary possibility. And so maybe by, by kind of mixing the data up in this way and focusing on different subsets of it. I don't know. Somehow manages to find the important structure as opposed to getting misled by any of the individual datapoints. >> Yeah. That's the basic idea. It's kind of the same thing, at least that's what I, I think that's a good answer. It's basically the same kind of argument you make for cross validation. Alright. You take a random bunch of subsets. You don't get trapped by one or two points that happen to be wrong because they happen to be wrong because of noise or whatever. And you sort of average out all of the variances and the differences. Hm. And often times it works. And in practice this particular technique of ensemble learning does quite well in getting rid of overfitting. >> And what is this called?"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,5-6,">> So, this particular version, where you take a random subset and you combine by the mean, it's called bagging. >> And I guess the bags are the random subsets? >> Sure. >> [LAUGH] That's how I'm going to think of it. >> That's how I'm going to think of it. It also has another name which is called bootstrap aggregation. So I guess the different subsets are the boots. >> [LAUGH] No,no, no, no bootstrap usually refers to pulling yourself up by your bootstraps. >> Yeah, I like my, I like my answer better. So, each of the subsets are the boots and the averaging is the strap. And there you go. So, regardless of whether you call it bootstrap aggregation or you call it bagging, you'll notice it's not what I said we were going to talk about during today's discussion. I said we were going to talk about boosting. So we're talking about bagging but we're going to talk about boosting. The reason I wanted to talk about bagging is because it's really the simplest thing you can think of and it actually works remarkably well. But there are a couple of things that are wrong with it, or a couple of things you might imagine you might do better. That"
Cn7StaXU_8o,Ensemble Learning An Example - Georgia Tech - Machine Learning,6-7,might address some of the issues and we're going to see all of those when we talk about boosting right now.
_Z8uJgg92ew,Ensemble Boosting - Georgia Tech - Machine Learning,0-1,"Okay so, let's go back and look at our two questions we were trying to answer. And so far we've answer the first one, learn over a subset of data, defined a rule by choosing that subset uniformally randomly and applying some learning algorithm. And we answered the second question, which is how do you combine all of those rules of thumbs by saying, you simply average them. And that gave us, bagging. So Michael, I'm going to suggest an alternative to at least the first one. And leave open the second one for a moment. That's going to get us to what we're supposed to be talking about today, which is boosting. So let me throw and idea at you and you tell me if you think it's a good one. So rather than choosing uniformly randomly. Over the data, we should try to take advantage of what we are learning as we go along, and instead of focusing just kind of randomly, we should pick the examples that we are not good at. So what do i mean by that? What i mean by that"
_Z8uJgg92ew,Ensemble Boosting - Georgia Tech - Machine Learning,1-2,"is. We should pick a subset based upon whether the examples in that subset are hard. So what do you think of that? >> Well, I guess it depends on how we think about hard, right so it could be that it's hard because some, in some absolute sense right, or could be that it is hard relative to you know, if we were to stop now how well we do Yeah, and I mean the latter. >> Oh. Okay. Alright. Well that I feel like that makes a lot of sense. I mean, certainly when I'm you know, trying to learn a new skill, I'll spend most of my energy on the stuff that I kind, that I'm kind of on the edge of being able to do, not the stuff that I've already mastered. It can be a little dispiriting. But it, but it I think it, I make faster progress that way. >> Right and if you, if you go back to the example that we, we started with, with spam right? If you come up with a and you see it does a very good on some of the data, some of the mail examples, but doesn't do a good job on the other. Why would you spend your time trying to come up with more rules that do well on the email messages you already know how to classify? You should"
_Z8uJgg92ew,Ensemble Boosting - Georgia Tech - Machine Learning,2-3,"be focusing on the ones you don't know how to classify. And that's the basic idea here between, the basic idea here behind boosting and finding the hardest examples. >> Cool. >> Okay. So that answers the first one. We're going to look at the hardest examples, and I'm going to define for you exactly what that means. I'm going to have to introduce at least one technical definition. But ,uh, I want to make certain you got that. And the second one, the combining, well that's a difficult and sort of complicated thing, but at a high level, I can explain it pretty easily by saying we are going to still stick with the mean. >> Okay. >> We're voting except this time,this time we are going to do weighted mean. Now why do we want to do weighted mean? Well I have to tell you exactly how we are going to weight it but the basic idea is to avoid the certain situations That we came across when we looked at the data before, when taking an average over a bunch of points that are spread out, this gives you an average or a constant that doesn't give you a lot of information about the space. So we're going to weight it by something, and it's going to turn out the way we choose to weight it will be very important. But just keep in your head for now that we're going to try to"
_Z8uJgg92ew,Ensemble Boosting - Georgia Tech - Machine Learning,3-4,"do some sort of weighted average. Some kind of weighted voting. Okay? >> Sure. One of the things that's scaring me at the moment though is this, like I have this fear that by focusing on the hardest questions, and then, and then sort of mastering those, what's to keep the learner from starting to kind of lose track of the ones it has already mastered? Like how, why does it not thrash back and forth? >> So that's going to be the trick. Behind the, the particular way that we do weighting. >> Okay >> So I will show you that in a moment, and it's going to require two slightly technical definitions, that we have been kind of skirting around, this entire conversation. Okay? >> Sure."
zC2rgxxf4dQ,Ensemble Boosting Quiz - Georgia Tech - Machine Learning,0-1,"Alright so, the, the whole goal of what we're going to add for boosting here is we're going to, we're going to expand on this notion of hardest examples and weighted mean. But before I can do that, I'm going to have to define a couple of terms. Okay. And you let me know Michael if, if these terms make sense. So, here's the first one. The first one is error. So how have we been defining error so far? >> Usually we take the square difference between the correct labels and the, what's produced by our classifier or regression algorithm. >> That's true. That is how we've been using error when we're thinking about regression error. How about, a notion of accuracy. About how good we are at, say, classifying examples. So let's, let's stick with classification formulas. >> Well, that would be the same as squared areas, except that it's not really meeting the whole powers [INAUDIBLE] area. That is to say, if the outputs are zeroes and ones, the squared area is just whether or not there's a mismatch. So it could just be the total number of wrong answers. >> Right. So, what we've been doing so"
zC2rgxxf4dQ,Ensemble Boosting Quiz - Georgia Tech - Machine Learning,1-2,"far is counting mismatches. I like that word, mismatches. And we might call an error raid or an error percentage as the total number of mismatches over the total number of examples. And that tells us whether we're at 85% or 92%, or, or whatever, right? So that's what we've been doing so far. But implicit in that, Michael, is the idea that every single example is equally as important. So, that's not always the case. Now you might remember from the first talk that we had. We talked about distributions over examples. We said that, you know, learning only happens if you're training set has the same distribution as your future testing set. And if it doesn't, then all bets are off. And it's very difficult to talk about induction or learning. That notion of distribution is implicit in everything that we've been doing so far, and we haven't really been taking into account when we've been talking about error. So here's another definition of error and you tell me if you think it makes sense, given what we just said. So, this is my definition of error. So the subscript"
zC2rgxxf4dQ,Ensemble Boosting Quiz - Georgia Tech - Machine Learning,2-3,"D, stands for distribution. So we don't know how new examples are being drawn, but however they're being drawn they're being drawn from some distribution, and I'm just going to call that distribution"" D"", okay? >> mhm Right. So H is our old friend the hypothesis. That's the specific hypothesis that our learner has output. That's what we think is the true concept, and C is whatever the true underlying concept is. So I'm going to define error as the probability, given the underlined distribution that I will disagree with the true concept on some particular instance X. Does that make sense for you? >> Yeah but I'm not seeing why that's different from number of mismatches in the sense that if we count mismatches on a sample drawn from D, which is how we would get our testing set anyway. Then I would think that would be you know if it's large enough a pretty good approximation of this value. >> So here Michael, let me give you a specific example. I'm going to draw four, four possible values of X. And when I say I'm going to draw four possible values of X, I mean I'm just going to put four dots on the the screen. >> Hm. >> Okay? And"
zC2rgxxf4dQ,Ensemble Boosting Quiz - Georgia Tech - Machine Learning,3-4,"then I'm going to tell you this particular learner output a hypothesis. Output you know, a, a potential function that ends up getting the first one and the third one right, but gets the second and the fourth one wrong. So what's the error here? >> Mm. >> So let's just make sure that, that everybody's with us. Let's do this as a quiz. >> Okay, so let's ask the students what they think. So here's the question again. You've output some hypothesis over the four possible values of x, and it turns out that you get the first and the third one right, and you get the second and the fourth one wrong. If I look at it like this, what's the error rate?"
6lhp_YSGhEA,Ensemble Boosting Quiz Two Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay, Michael what's your answer? >> It looks like, half of them are right and half of them are wrong. So, the number of mismatches, is, two out of four or a half. >> Right, that is exactly the right answer ,because ,you got half of them right and half of them wrong. But ,it assumes ,that your likely to see all four of the examples, equally often. So, what if I told you, that, that's not in fact the case. So ,here's another example of error for you. What if I told you that each of the points, is, likely to be seen ,uh, in different proportions and in fact in these particular proportions. So you're going to see the first one ,half the time. You're going to see the second one ,one 20th at a time. You're also going to see the fourth one, one 20th at a time and you'll see the third one ,four tenths of the time. Alright, so you got it Michael? One half, one 20th, four tenths and one twentieth. >> Got it. Okay. So, now I have a different question for you. Actually, I have the same question for you, which is, what is the error rate now. Go. Okay, Michael what's the answer? >> Well, it's still a half. But I guess we, we really should take into consideration those probability. So the number of mismatches they have, but the actual number of errors, the expected number of errors is like well, a 20th plus 20th, so like a 10th. So it's 90% correct, 10% error. >> Right. That's exactly right, so, what's important to see here is that even though you may get many examples wrong, in some sense some examples are more important than others. Because some are very rare. And if you think of error, or the sort of mistakes that you're making, not as the number of distinct mistakes you can make, but rather the amount of time you will be wrong, or the amount of time you'll make a mistake, then you can begin to see that it's important to think about the underlying distribution of examples that. You see. You buy that? >> Yeah. >> Okay, so, that notion of error turns out to be very important for boositng because in the end, boosting is going to use this trick of distributions in order"
6lhp_YSGhEA,Ensemble Boosting Quiz Two Quiz Solution - Georgia Tech - Machine Learning,1-2,"to define what hardest is. Since we are going to have learning algorithms that do a pretty god job of learning on a bunch of examples. We're going to pass along to them a distribution over the examples, which is another way of saying, which examples are important to learn, versus which examples are not as important to learn. And that's where the hardest notion is going to come in. So, every time we see a bunch of examples, we're going to try to make the harder ones more important to get right. Than the ones that we already know how to solve. And I'll, I'll describe in a minute exactly how that's done. >> But isn't it the case that this distribution doesn't really matter? You should just get them all right. >> Sure. But now it's a question of how you're going to get them all right. Which brings me to my second definition I want to make. And that second definition is a weak learner. So there's this idea of a learning algorithm, which is what we mean by a learner here. As being weak. And that definition's actually fairly straightforward so straightforward in fact that you can sort of forget that it's really important. And all a weak learners is, is a learner that no matter what"
6lhp_YSGhEA,Ensemble Boosting Quiz Two Quiz Solution - Georgia Tech - Machine Learning,2-3,"the distribution is over your data, will do better than chance when it tries to learn labels on that data. So what does does better than chance actually mean? Well what it means is, that no matter what the distribution over the data is, you're always going to have an error rate that's less than a half. So that means sort of as a formalism, is written down here below. That for all D, that is to say no matter what the distribution is, your learning algorithm We'll have an expected error. That is the probability that it will disagree with it through actual concept if you draw a single sample that is less than or equal to one half minus Epsilon. Now epsilon is a term that you end up seeing a lot in mathematical proofs and particularly ones involving machine learning. And epsilon just means a really, really small number somewhere between a little bigger than 0 and certainly much smaller than 1. So, here what this means technically is that you're bounded away from 1 1/2. Which another way of thinking about that is you always get some information from the learner. The"
6lhp_YSGhEA,Ensemble Boosting Quiz Two Quiz Solution - Georgia Tech - Machine Learning,3-4,"learner's always able to learn something. Chance would be the case where your probability is 1/2 and you actually learn nothing at all which kind of ties us back into the notion of information gained way back when with decision trees. So does that all make sense Michael? >> I'm not sure that I get this right. Let's, maybe we can do a quiz and just kind of nail down some of the questions that I've got. >> Okay, sure. You got an idea for a quiz? >> Sure."
zUXJb1hdU0k,Weak Learning Quiz - Georgia Tech - Machine Learning,0-1,"Okay Michael so you, let's make certain that you really grasp this concept of weak learning okay? >> Mm-hm. >> So, here's a little quiz that I put together to test your knowledge. So, here's the, here's the deal. I've got a little matrix here, it's a little table, and across the top. Are three different hypotheses. So, hypothesis one, hypothesis two, and hypothesis three. So your entire hypothesis base consists only of these three hypothesis, hypotheses. Got it? >> Got it. >> Okay, your entire instance space consists entirely of only four examples; X1, X2, X3, and X4. Got it? >> Got it. >> I have an X in a square, if that particular hypothesis does not get the correct label for that particular instance, and I have a green check mark if that particular hypothesis does in fact get the right label for that example. So, in this case hypothesis one gets examples 2, 3,"
zUXJb1hdU0k,Weak Learning Quiz - Georgia Tech - Machine Learning,1-2,"and 4 correct. But gets example one wrong, while hypothesis three gets one in four correct, but two and three incorrect. >> I see. So, there's no hypothesis that gets everything right. >> Right. >> So does that mean that we don't have a weak learner, because then there's some distributions for which any given hypothesis is going to get things wrong. >> Maybe. Maybe not. Let's see. Here's what I want you to do. I want you to come up with the distribution over the 4 different examples, such that a learning algorithm that has to choose between one of those 3 hypotheses will in fact be able to find that does better than chance. That is, has an expected error greater than half. >> Okay. Then if you can do that, I want you to see if you can find a distribution which might not exist, such that if you have that distribution over the four examples, a learning algorithm that only looked at h1, h2 and h3 would not be able to return one of them that has an expected error greater than half."
zUXJb1hdU0k,Weak Learning Quiz - Georgia Tech - Machine Learning,2-3,">> So greater than half in this case would mean three out of four, correct? Oh no, no. Oh, you're using, you want to use that definition that you, that actually took into consideration the distribution. >> Exactly. That's the whole point. If you, if you always need to have some distribution over your examples to really know what your expected error is. >> Alright. And if there is no such evil distribution, should I just fill in zeroes in all those boxes? Yes, all zeros means no such distribution. You can do it in either case. So if you put in all zeros you're saying no such distribution exists. But otherwise it should add up to one down each of the columns. >> It had better add up to one. >> Alright, I think I can give that a shot. Okay, go."
lj-IO4uuVR8,Weak Learning Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay Michael, you got answers for me? >> Yeah, I think so. The first thing I notice is that if I put equal weights on all four examples, like I, I decided that instead of solving this problem by thinking, I would just try a couple examples, and see if I found things in both boxes. So, if I put equal weight on X1, X2, X3, X4. >> Mm-hm. >> Then hypothesis one, H1 gets three out of four correct, that's three quarters. That's better than a half. So. >> Well done. >> Then I fill that in, in the good boxes, quarters all the way down. >> That's a turtle, 'because it's turtles all the way down [LAUGH]. >> No, no, it's not though, it should be quarters all the way down. I thought you'd may be draw a quarter. >> I, I can't draw a quarter, also I can't draw a turtle obviously but still. >> [LAUGH] Agreed. Alright, good. >> You'd think, anyone, do you think anyone listening to this is old enough to get turtles all the way down. >> Yeah, that's a great joke. Everybody knows that joke. >> And if people don't know the joke, then we should pause this thing right now, and you should go look up turtles all the way down. And then come back. Okay. >> It's a, it's a really great joke if you're computer scientist."
lj-IO4uuVR8,Weak Learning Quiz Solution - Georgia Tech - Machine Learning,1-2,">> Yes, and if you don't think it's a good joke then you should probably be in a different field. Okay. >> [LAUGH] >> What about the evil distribution? >> So then I started to generate. Okay, well what if, the, the, the issue here is that, because we spread all the, the, the, the probability out in the first hypothesis really good. So I said okay, well let me put all the weight on the first example. The x1. >> Okay. So what did that look like. >> Now h1 did very badly. It gets, it's 100 percent error. And h2 is 100 percent error. But h3 is 0 percent errors. So so. >> yes. >> So, so putting it all putting all the weight on x1 is no good. And if you look x2, x3, x4, they all have the property that there's always a hypothesis that gets them right. So I started to think, well maybe there isn't an evil distribution. And I kind of lucked into putting a half on both the first and the second one. because i figured that, that ought to work, but then i realized, oh wait a second that's an evil distribution, because if you choose h1, h2, or h3, they all have exactly 50% error on the half a half distribution."
lj-IO4uuVR8,Weak Learning Quiz Solution - Georgia Tech - Machine Learning,2-3,">> Very good. So 1/2, 1/2, zero, zero, is a correct answer. >> Now I don't know if there's others. You know, certainly X, putting all the weight on X2 and X3 is no good, because H2 and H1 both get those. Putting all the weight on X3 and X4 are no good, because H1 gets all of those correct. In fact we have to have some weight on X1, right. Otherwise H1 is the way to go. >> Right. So, yeah. No, that's interesting. So what does that mean in this case? >> What do you mean, what does that mean? >> So what does this tell us about, how do we build a weak learner for this example? >> So what it tells us is that since there is a distribution for which none of these hypotheses will be better than chance, there is no weak learner for this hypothesis space, on this instant set. >> Interesting. Now is there a way that we can, like, okay, so this example has no weak learner. Is there a way to change this example so it would have a weak learner? >> Um...I'm sure there is. >> Like if we change that x2, x, h3, if that was a check instead of an X. >> Which one? X2 H3."
lj-IO4uuVR8,Weak Learning Quiz Solution - Georgia Tech - Machine Learning,3-4,">> So if we made that a green one, here I'll, I'll make it a green one. By using the power of computers. >> Woah, special effect. >> Yes. >> So now there's no way to put weight on any two things and have it fail. I don't know, my intuition now is that this, this should have a weak learner. Okay, well, how would we prove that? >> I don't know, but may be we should end this quiz. >> Yeah, I think, we should end this quiz. And leave it as an exercise to the listener. I'm pretty sure I can figure this out. By the way, we should point a couple of things here though, Michael. That one is that, the if it weren't the case, if we had more hypotheses and more examples. Perhaps an odd number of them and we have the x's and the y's in the right places then there'd be lots of ways to get weak learners for all the distributions just because you'd have more choices to choose from. What made this one particularly hard is that you only had three hypotheses and none of them was, not all of them were particularly good. >> Sure, yeah. I mean if you have a bun-, you can have many, many hypotheses and they're all pretty bad then you're not going to do very well."
lj-IO4uuVR8,Weak Learning Quiz Solution - Georgia Tech - Machine Learning,4-5,">> Well, it would depend upon if they're bad on very different things. But you're right, if you have a whole lot of hypotheses that are bad at everything, you're going to have a very hard time with a weak learner. And if you have a whole bunch of hypotheses that are good at almost everything, then it's pretty easy to have a weak learner. >> Interesting. Okay, this is more subtle than I thought. So that's, that's interesting. >> Right. So what the lesson you should take away from this is. If you were just, to think about it for 2 seconds you might think okay weak learner. That seems easy. And often it is, but if you think about for 4 seconds you realize that's actually a pretty strong condition. You're going to have to have a lot of hypotheses that are, many of which are going to have to do good on lots of different examples, or otherwise, you're not always going to be able to find one that does well no matter what the distribution is. So it's actually a fairly strong, and important condition."
ooxQS5-Grgc,Boosting In Code - Georgia Tech - Machine Learning,0-1,"All right Michael, so here's boosting in pseudo code. Okay, let me read it out to you then you can tell me if it makes sense. So we're given a training set. It's made up of a bunch of xi, yr pairs. You know, x is your input and y is your output. And for reasons that'll be clear in a moment All of your labels are either minus one or plus one. Where minus one means not in class or plus one means you're in a class. So this is a binary classification task. That make sense? >> So far. >> Okay. And then what you're going to do is, you're going to loop at every time step, let's call it lower-case t. From the first time step one, to some big time in the future. We'll just call it capital T and not worry about where it comes from right now. The first thing you're going to do is you're going to construct a distribution. And I'll tell you how in a minute, Michael. Okay, so, so, don't worry about it. And we'll just call that D sub T. So, this is your distribution over your examples at some particular time T. Given that distribution, I want you to find a weak classifier. I want your"
ooxQS5-Grgc,Boosting In Code - Georgia Tech - Machine Learning,1-2,"weak learner to output some hypothesis. Let's call that epsilon sub T. The hypothesis that gets produced to that time step. And that hypothesis should have some small error. Let's call that error Epsilon sub T, because it's a small number. Such that it does well on the training set, given the particular distribution. So, I'm just rewriting my notion of error from, the other side of the screen. So there are times we want you to find a weak classifier. That is, we want you to call some weak learner that returns some hypothesis. let's call it h sub t that has a small error. let's call that epsilons of t. Which is to say that the probability of it being wrong that is disagreeing with the training label is small, with respect to the underlying distribution. >> So just to be clear there, the epsilon could be as big as slightly less than a half. Right? It doesn't have to be teeny, tiny. It could actually be, almost a half. But it can't be bigger than a half. >> That's right. And, and no matter what happens."
ooxQS5-Grgc,Boosting In Code - Georgia Tech - Machine Learning,2-3,"Or even equal to a half. but, you know, we can assume, although it doesn't matter for the algorithm that the learner is going to return the best one that it can. With some error. But regardless, it's going to have, it's going to satisfy the requirements of a weak learner, and all I've done is copy this notion of error over to here. Ok? >> Awesome! >> Ok. So, you're going to do that and you'll do that a whole bunch of times steps, constantly finding hypothesis at each time step h sub t with small error epsilon sub t constantly making new distributions, and then eventually, you're going to output some final hypothesis. Which, I haven't told you yet how you're going to to get the final hypothesis. But that's the high level bit. Look at your training data, construct distributions, find a week classifier with low error. Keep doing that you have a bunch of them and then combine them somehow into some final hypothesis. And that's high level of algorithm for boosting, okay? >> Okay, but you've left out the two, two really important things, even the part from how you find we, weak classifier, which is where do we get this"
ooxQS5-Grgc,Boosting In Code - Georgia Tech - Machine Learning,3-4,"distribution and where do we get this, this final hypothesis? >> Right, so let me do that for you right now."
iWfmROeYu24,The Most Important Parts - Georgia Tech - Machine Learning,0-1,"Okay Michael, you've called my bluff. You, you said I've left out the most important parts, and you are right. So, I'm going to tell you ,how to construct the most important parts. Let's start, with the distribution. So, let's start with the base case, and that is the distribution, at the beginning of time, D sub one. So, this distribution, is going to be over each of the examples and those examples, are ,indexed, so, over i. And I'm simply going to set that distribution, to be uniform. So, how many examples do we have, Michael? Let's pick, let's pick a letter. Let's call it n. >> Okay. >> Why not, cause we do that for everything else and I'm going to say that for every single one of the examples they happen one over int times, that is uniform distribution. Now, why do I do that, because, I have no reason to believe, for the purposes of this algorithm, that any given example, is better ,than any other example, more important than any other example, harder than other example"
iWfmROeYu24,The Most Important Parts - Georgia Tech - Machine Learning,1-2,"or anything else. I know nothing. So, see if you can learn over all of the examples. You with me? >> Yeah, cause I feel like if it actually solves that problem, we're just done. So [CROSSTALK] >> [CROSSTALK] Yes and, and that's what you always want. But that's the easy case. So I start out with uniform distribution, that's what you usually do ,when you don't know anything. But, what are you going to do ,while your in the middle? So, here's what I am going to do Michael. At every time step T, I'm going to construct, a new distribution, Dis of T plus 1. Okay so, here's how we're going to construct the distribution at every time step. Okay? I'm going to create the new distribution, T plus 1 to be E for each example, I. - to be the old distribution, and times T, times E to the minus alpha T, times Y sub i, times H of sub T, of X of I, all divided by Z sub T. [LAUGH] So that's pretty obvious right? [LAUGH] So what do each of those terms mean? I mean ,I know it's intuitively obvious ,even to the most casual observer, but ,let me just try to explain what each of the parts mean."
iWfmROeYu24,The Most Important Parts - Georgia Tech - Machine Learning,2-3,"So, we know that the D is our distribution and it's some number, where, over all the examples, it adds up to one. And it's a stand-in, we know, because I said this at the beginning, for how important a particular ,example is, how often we expect to see it. And that's the trick that we're using with distributions. So, I'm going to take the old distribution for an example, of, for a particular example. And I'm going to either make it bigger or smaller, based upon, how well, the current hypothesis, does, on that particular example. So, there's a cute little trick here, we know that h of t always returns, a value ,of either minus one or plus one, because ,that's how we define our training set, you always have a label of minus one or plus one. So, ht is going to return minus one or plus one for a particular x sub i. Y of i which is the label with respect to that example, is also always going to be plus one or minus one. And alpha t is a constant, which I will get into a little bit later just right now think of it as a number. And so what"
iWfmROeYu24,The Most Important Parts - Georgia Tech - Machine Learning,3-4,"happens, Michael, if the hypothesis, at time t for a particular example x of i agrees, with the label, that is associated with that x of i? >> Well, hang on, you say the alpha's a number. Is it a positive number? A between 0 and 1 number? A negative number? What kind of number? Does, does it not matter. I think it matters. >> That's a good question. It, it matters eventually. But right now, that number is always, positive. >> Positive, alright. So, like, a [UNKNOWN]. Almost like a learning rate-y kind of thing, maybe. >> It's a learning rate-y kind of thing, sort of. >> Alright, so, good. So the y, okay, I see, I see. So, the y times the h is going to be. 1 if they agree, and minus 1 if they disagree. >> Exactly, so if they both say positive 1, positive 1 times positive 1 is 1. If they both say negative 1, negative 1 times negative 1 is 1. So, it's exactly what you say when they agree, that number is 1. And when they disagree, that number is minus 1. Alpha Sub T, which i define below, is always a positive number. You can"
iWfmROeYu24,The Most Important Parts - Georgia Tech - Machine Learning,4-5,"trust me on this. The error is always between 0 and 1. And it just turns out that the natural log of 1 minus a number between 0 and 1 over that number, always gives you a positive number. And if you don't believe me, you should play around with the numbers till you convince yourself. So, that's going to be some positive number. So, that means when they agree, that whole product will be positive. Which means, you'll be raising e to minus some number when they disagree that product will be negative which means you'll be raising e to some positive number. So, let's imagine they agree. So you're going to be re raising, e, to minus some number, what's going to happen to the relative weight of d sub t of i?"
MpFjG3bAGwk,When D agrees Quiz - Georgia Tech - Machine Learning,0-1,"So, Michael wants us to do a quiz. Because Michael likes quizzes cause he thinks you like quizzes. And so, I want you to answer this question before Michael gets a chance to. So just to be clear here's the question again. What happens to the distribution over a particular example i when the hypothesis ht that was output by the example. Agrees with the particular label, Y-sub-i. Okay, so we have four possibilities when they agree. One is the probability of you seeing that particular example increases. That is, you increase the value of D-sub-t on i. Or the probability of you seeing that example decreases. That is, the number d of t of i goes down, or it stays the same when they agree or well it depends on exactly what's going on with the old value of d and alpha and all these other things. So ,you can't really give just one of those other three answers. So those are your possibilites. The other radio buttons"
MpFjG3bAGwk,When D agrees Quiz - Georgia Tech - Machine Learning,1-2,[LAUGH] only one of them is right. And go.
nle0iezRpoo,When D agrees Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay Michael what's the answer. >> Alright, so you kind of were walking us through it, but basically if Yi and Ht agree, that means they're both negative or they're both positive. They're equal to each other. So when we multiply them together we get one. One times whatever our alpha thing is, some positive number is going to be positive. We're negating that, so it's negative E to the negative something is something between zero and one. Less than, less than one. So, that's going to scale it down. So, it looks like. And you know assuming that everything else goes ok with, with the way that ,uh, the normalization happens right? It seems like it could be depends on the normalization. >> So by the way. That's a good point. The the x sub t. Is in fact, what ever normalization constant you need at time T, in order to make it all work out to be a distribution. >> Correct. Then not going to, not going to change. >> True. >> But is some of them are correct and some of them incorrect, the ones that are correct are going to decrease. And the ones that are incorrect are going to increase."
nle0iezRpoo,When D agrees Quiz Solution - Georgia Tech - Machine Learning,1-2,">> That's right, so what's the answer to the quiz. >> Depends. >> That's true, it does. That's exactly the right answer. It depends ,on what else is going on, you're correct. Now. >> But I feel like it should be decreases, like that's really, mainly what happens. >> That's also fair. The answer is, if this one is correct, that is they agree, and you disagree on at least some of them, at least one, one other example, it will in fact decrease. So I could ask a similar question, which is, well what happens when they disagree? And at least one other example agrees. Then what happens? >> Yeah, then they, then that should increase. Oh. >> Right. >> Oh. It's going to put more weight on the ones that it's getting wrong. >> Exactly. And the ones that it's getting wrong must be the ones that are harder. Or at least that's the underlying idea. All right, Michael, so you got it? So you understand what the equation's for? >> Yeah, it look. It seemed really scary at first but it seems you know marginally less scary now because all that it's doing, it's doing it in a particular way."
nle0iezRpoo,When D agrees Quiz Solution - Georgia Tech - Machine Learning,2-3,"I don't know why it's doing it in this particular way. But all it seems to be doing is. The answers that it, it had, it was getting wrong... It puts more weight on those and the ones that its getting right, it puts less weight on those and then you know, the loop goes around again and it tries to make a new classifier. >> Right, and since the ones that its getting wrong are getting more and more weight but we are guaranteed or atleast we've assumed that we have a weak learner that will always do better than chance. On ,ah, any distribution, it means that you'll always be able to output some learner that can get some of the ones that you were getting wrong, right."
xzqnQQSTEAk,Final Hypothesis - Georgia Tech - Machine Learning,0-1,"So that ties together this, what constructed E does for you, and connecting it to the hardest examples. So now, that gets us to a nice little trick where we can talk about how we actually output our final example. So, the way you construct your final example, they way you do that combination in the step is basically by doing a weighted average. And the weight Is going to be based upon this alpha sub T. So the final hypothesis is just the s g n function of the weighted sum of all of the rules of thumb, all of the weak classifiers that you've been picking up over all of these time steps Where they're weighted by the alpha sub T's. And remember, the alpha sub T is one half of the natural log of one minus epsilon T over epsilon T. That is to say, it's a measure of how well you're doing with respect to underlining error. So, you get more"
xzqnQQSTEAk,Final Hypothesis - Georgia Tech - Machine Learning,1-2,"weight if you do well Then if you do less well or you get less weight. So what does this look like to you? Well its a weighted average based on how well you're doing or how well each of the individual hypotheses are doing and then you pass it through a thresh holding function where if its below zero you say you know what? Negative and if its above zero you say you know what? Positive and if its zero you just throw up your hands and And return zero. In other words, you return literally the sign of the number. So you are throwing away information there, and I'm not going to tell you what it is now, but when we go to the next lesson it;s going to turn out that that little bit of information you throw away is actually pretty important. But that's just a little bit of a teaser. We'll get back to that there. Okay so, this is boosting, Michael. There's really nothing else to it. You have a very simple algorithm, which can be written down in a couple of lines. The hardest parts are constructing the distribution, which I show you how to do over here, and then simply bringing everything together, which I show you how to do over here. >> Alright yeah, I think it doesn't seem so bad and I feel like I could code this up, but I would be a little happier if I had a handle"
xzqnQQSTEAk,Final Hypothesis - Georgia Tech - Machine Learning,2-3,"on what the, why alpha is the way that it is. >> Well there's two answers. The first answer is. You use natural logs because you're using exponentials and that's always a cute thing to do. And of course, you're using the error term as a way of measuring how good the hypothesis is. And the second answer is, it's in the reading you were supposed to have done. [LAUGH] So, go back and read the paper now that you've listened to this and you will have a much better understanding of what it's trying to tell you. >> Thanks >> You're welcome. I'm about helping others Michael you know that."
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,0-1,"So, Michael, I want to try to convince you other than the fact that it's an algorithm with symbols that, it sort of works, at, at least informally. And then, I'm going to do what I always do and refer you to actually read the, the, the text to get the, the details. But before I do that, I wanted to go through an example if you think that would help. >> I would like an example. >> Okay. So, let's go through an example. So, here's a very simple example. So, I got three little boxes on the screen. Can you see them? >> Yeah. >> Now, they're the same boxes. I've drawn them up here beforehand because I'm going to solve this problem in only three steps. >> Hey those boxes are really nice, did you get help from our trusty course developer? >> I did in fact did get help from our trusty course developer. And when I say help, I mean he did this. >> Oh thanks Push Car. >> Yes Push Car is wonderful. Now what's really cool about this is that Push Car is already let you know that we're going to be able to do this in 3 simple steps. And I'm going to be able to animate it. Or at least hopefully it'll look animated by the time, [LAUGH] we're done with all the editing. So just pay attention to the first box for"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,1-2,"now, you have a bunch of data points; red pluses and green minuses, which is the opposite of what we usually do Push Car. But either way it's red pluses and green minuses. [LAUGH] With the appropriate labels and they all live in this, this part of the plane. By the way, what do you call a part of the plane? I know you have line segments, what's like, a sub part of a plane? >> Looks like a square to me. >> Yes it is, but I mean, what do you call them? You, you don't call it a plane segment, do you? What do you call it? >> A region. >> A square region, fine. So it's a square region on a plane. And we want to figure out how to be able to correctly classify these examples. Okay, so that is nothing new there. We just want to be able to come up with something. So now we have to do what we did like in the quiz is that we have to specify what our hypothesis space is. So here's our hypothesis space. So the hypothesis space is the set Of axis aligned semi-planes. You know what that means? >> Mm, no. >> Well for the purpose of this example it means,"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,2-3,"I'm going to draw a line, either horizontal or vertical and say that everything on one side of that line is positive and everything on the other side of that line is negative. >> I see. Okay, good. >> Right. And their axes align because it's only horizontal and vertical, and they're semi-planes because the positive part of it is only in part of the plane. Okay, so I'm going to just walk through what boosting would end up doing with this particular example or what a boosting might do with this particular example given that you have a learner. That always chooses between axis aligned semi planes. Okay? >> Yeah. >> So let's imagine we ran our boosting algorithm now in the beginning it's step 1 all of the examples look the same because we have no particular reason to say any are more important than the other, any are easier or harder than the other. And that's just the algorithm we had before We run through and we ask our learner to return some hypotheses that does well in"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,3-4,"classifying the examples. It turns out that though there are many, and in fact there are an infinite number of possible hypotheses you could return. One that works really well is one that looks like a vertical line that separates the first two data points from the rest. >> That is what I was guessing. >> Of course it was. And what I'm saying here is that everythign to the left of this line is going to be positive and everything to the right is going to be negative. So if you look at this what does this hypothesis do? So it gets correct, correctly labeled positive. The two pluses to the left. Right? >> Correct. >> And it gets correct all of the minuses as well. >> Correct. >> Right? But it gets wrong the three pluses on the right side. So it gets, this wrong, this wrong, and this wrong. >> Right, the Three Plusketeers. >> Exactly. [LAUGH] The Three Plusketeers. That's actually pretty good. So I'm just you know I'm just going to ask you to trust me here but it turns out that the specific"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,4-5,"error here is 0.3 and if you stick that into our little alpha you end up, our little, our little formula for alpha, you end up with alpha equal to 4.2. >> That's not obvious to me but. >> Is is See, see, see it's not always obvious. >> [LAUGH] >> Okay. Good. So there you go and that's just what happens when you stick this particular set in there. So now we're going to construct the next distribution. Right? And what's going to happen in the next distribution? >> So the one's that it got right should get less weight and the one's that it got wrong should get more weight so those three plusketeers should become more prominent somehow. >> That's exactly what happens. They become, I'm just going to draw them as much thicker and bigger to kind of emphasise that they're getting bigger, and it's going to turn out that everything else is going to get smaller which is a lot harder to draw here. So i'm just going to kind of leave them their size, so they sort of get normalized away. Okay? >> I would guess as to what the next plane should be. I think that we should"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,5-6,"cut it. Underneath those pluses but above the green minuses. And that should get us three errors. The two pluses on the left and the minus on the top will be wrong. But they have less weight than the three pluses we got right, so this going to be better than the previous one. >> So, that's possibly true. But it's not what the learner output. >> Oh! >> Let me tell you what the learner did output though. This learner output by putting a line to the right of the three pluses, because he's gotta get those right in saying that everything to the left is in fact, positive. So, does that seem like a reasonable one to you? >> Well, it does better than half. I guess that's really all what we're trying to do, but it does seem to do worse than what I suggested. >> Well, let's see, it gets the three that mattered that you were really, really doing poorly right but then so did yours. And it only, and it picks up still the other two which it was getting right. And it gets wrong these"
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,6-7,"three minus' which aren't worth so much. So is that worse than what you suggested? No, it gets wrong, oh, the three minuses. Oh, it gets correct those two red pluses on the left. So it gets three things wrong. So that's just as good as what I suggested. Okay, I agree. >> Okay good. So the error of this step by the way, turns out to be 0.21 and the alpha at this time step turns out to be 0.65. So that's pretty interesting, so we got a bunch of these right and a bunch of these wrong. So what's going to happen to the distribution over these examples. >> Alright, the ones that it, again, the ones that it got wrong should get pushed up in weight and which ones are those, those are the, the three green minuses in the middle patch >> Right. >> They should become more prominent. The pluses, the three, the three plusketeers should become less prominent than they were but it still might be more prominent than they were in the beginning. And maybe because in fact the alpha, let's see the alpha is bigger so, it will have actually a bigger effect on bringing it down."
u1MXf5N3wYU,Three Little Boxes - Georgia Tech - Machine Learning,7-8,">> Yeah I guess so, but it, there'll still be more prominent than the other ones that haven't been bumped. >> Yeah the ones that you, the, the two, the two red pluses on the left have, you've never gotten them wrong. >> Hm. >> So they're really going to disappear. So, if we do, If I do my best to, If I do my best to kind of draw that you're still, you're going to have. These pluses are going to be a little bit bigger than the other pluses, but they're going to be smaller than they were before. The two, the three greens in the middle are going to be bigger than they were before. But those two pluses are going to be even smaller, and these two minuses are going to be smaller. So, what do you think the third hypothesis should be. >> Quiz. >> Oh, I like that."
zodDmURwMHY,Which Hypothesis Quiz Solution - Georgia Tech - Machine Learning,0-1,"Okay, so Michael wanted to have a quiz here, 'because Michael again, likes those sort of things and, and I like to please Michael. So, we came up with three possibilities, one of which we hope is right. >> [LAUGH] >> And I've labeled them here in orange, A, B, and C and put little radio boxes next to 'em, so you could select 'em. So which of those three hypotheses are, is a good one to pick next? So, A is a horizontal line that says everything above it should be a plus. B is a, another horizontal line that says everything above it should be a plus. And C is a vertical line, like the last two hypotheses that we found, that says everything to the left should be a plus. So, which do you think is the right one? Go. >> Alright Michael, what's the answer? >> Alright so of those others, well C is pretty good, because it does separate the pluses from the minuses. We, we even liked it so much we used it in round two. >> Mh-hm. >> But it doesn't as good to me as A, because A actually does a good job of separating the very, the more heavily weighted points. So I would, I would say A. >> So in fact that is what our little learning system shows. It shows A. Now, through the trick of animation, I leave you with A. And that is exactly the right answer. By the way, Michael, if you look at these three hypothesis and their weights, you end up with something kind of interesting. So if you look at this third hypothesis that's chosen here, turns out they have a very low error, you'll notice that the errors are going down over time, by the way, of 0.14. And it has a much higher alpha of 0.92. Now if you look at these weights and you add them up, you end up with a cute little combination. So,"
zodDmURwMHY,Which Hypothesis Quiz Solution - Georgia Tech - Machine Learning,1-2,"let me draw that for you. Okay Michael, so I cleaned up a little bit so that you could see it. If you take each of the three hypothesis that we produced, and you weight them accordingly, you end up with the bottom figure. >> No way. >> Absolutely. >> That's. Kind of awesome. So what you're saying is that, even though we were only using half planes, or, or axis-aligned semi planes, for all the weak learners, that at the end of the day it actually kind of bent the line around and captured the positive and negative examples perfectly. >> Right. Does that remind you of anything else we've talked about in the past? >> Sh. Everything. Nothing. No, I dunno, I mean so with, with decision trees you can make the shapes like that, and >> That's true. >> And the fact that we're doing a weighted combination of things reminds me of the neural net. >> Yeah. And it should remind you of one other thing. >> I'm imagining that you want me to say nearest neighbors, but I can't quite make the connection. >> Well, you recall in our discussion with nearest neighbors, when we did weighted nearest neighbor. In particular we did weighted"
zodDmURwMHY,Which Hypothesis Quiz Solution - Georgia Tech - Machine Learning,2-3,"linear regression, we were able to take a simple hypothesis, add it together in order to get a more complicated hypothesis. >> That's true, because it's local. >> Right, exactly because it's local, and this is a general feature of Ensemble methods that if you try to look at just some particular hypothesis class. Let's just call it H, because you're doing weighted averages over hypotheses drawn from that hypothesis class. This hypothesis class is almost all low, is at least as complicated as this hypothesis class and often is more complicated. So you're able to be more expressive, even though you're using simple hypotheses, because you're combining them in some way. >> I'm not surprised that you can combine simple things to get complicated things. But I am surprised that you can combine them just with sums. And get complicated things because sums often act very, you know, sort of, friendly. Right it's a linear combination not a nonlinear combination. >> Actually, Michael part of the reason you get something nonlinear here is because you're passing it through a non-linearity at the end. >> The sine."
zodDmURwMHY,Which Hypothesis Quiz Solution - Georgia Tech - Machine Learning,3-4,">> Yea, that's a good thing, we should, we should ponder that."
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,0-1,">> Okay Michael, so we've done our little example. I want to ask you a quick question and try to talk something through with you and then we can start to wrap up. Okay. >> Awesome. >> Alright, so, here is my quick question. Now, in the reading, which I know you've read, there's a proof. That shows that boosting not only, you know, does pretty things with axis of line semi-planes, but also that it will converge to good answers and that it will find good combined hypotheses. You know, we could go look at the reading and write down a proof that shows that boosting does well. Umm. And there's one in the reading. Or we could talk about an intuition. So if someone were to come up to you. If a student were to find you somewhere and said, I read the proof, I'm kind of getting it, but do you have a good sort of intuition about why boosting tends will do well? What do you think you would tell them? Could you think of something simple? I've been struggling with this for a while. >> No. [LAUGH]."
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,1-2,">> Okay, well, then let me try something on you and you can tell me if it sort of makes sense. So this is just an intuition for why, for why boosting pins will do well. Okay, so what does boosting do? Okay. Boosting basically says, if I have some examples that I haven't been able to classify well, I'm going to re-rate all my examples. So that the ones I don't do well become increasingly important. Right, that's what boosting does. Yes? >> Yes. >> Right, that's what this whole, whole bit of D is all about. It's all about re-weighting based on difficulty and hardest. And we know that we have the notion of a weak learner. That no matter what happens for whatever distribution, we're always going to be able to find some hypothesis that does well. So, if I'm trying to understand why boosting in the end, why the final hypothesis that I get at the end, is going to do well. I can try to get a feeling for that by"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,2-3,"asking, well. Under what circumstances would it not do well? So, if it doesn't do well, then that means there has to be a bunch of examples that it's getting wrong, right? >> Mm hm. >> That's what it would mean not to do well, agreed? >> Yeah. >> Okay. So how many things could it not get right? How many things could it misclassify? How many things could it get incorrect? Well, I'm going to argue Michael, that, that number has to be small. There cannot be a lot of examples that it gets wrong. So do you want to know why? Do you want to know my reasoning for why? >> Yeah. >> So, here's my reasoning, let's imagine I had a number of examples at the end of this whole process. I've done it T times. I've gone through this many times and I have some number of examples that I'm getting wrong. If I were getting those examples wrong, then I was getting them wrong in the last time step, right? And, since I have a distribution and I re-normalize, and it has to be the case that at least half of the time, more than half of the time I am correct, that number"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,3-4,"of things I'm getting wrong has to be getting smaller over time. Because let's imagine that was at a stage where I had a whole bunch of them wrong. Well, then I would naturally renormalize them with a distribution so that all of those things are important. But if they were all important, the ones that I was getting wrong, the next time I run a learner, I am going to have to get at least half of them right, more than half of them are right. Is that make sense? >> It does, but it, but what scares me is, okay, why can't it just be the case that the previous ones which were getting right start to get more wrong as we shift our energy towards the errors. >> Yeah, why is that? >> I don't know. But did you wanna, are we, we working up to some kind of you know, log n kind of thing where each time you are knocking off half of them and therefore. >> I don't know. Do you remember the proof. >> The proof. >> I mean what goes on is that you get, sort of, this exponentially aggressive weighting over examples, right? >> Yeah. >> And you're driving down the number of things you get wrong. Sort of exponentially quickly, over time. That's why boosting works so well and works so fast."
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,4-5,">> I get that we're, the we're quickly ramping up the weights on the hard ones. I don't get why that's causing us to get fewer things wrong over time. So like, when you should, in your, in your example that you worked through, that had the error in the alphas and the errors kept going down and the alphas kept going up. >> Right. >> Like, is that necessarily the case? >> Well, what would be the circumstances under which it isn't the case? How would you ever go back and forth between examples? Well, certainly it's the case that if you keep getting something, right, you will, get them. Well, so here's what happens over time, right. Is that over time, every new hypothesis, it gets to get a vote, based upon how well it does on the last, difficult let's say, distribution. So the ones that are even if the ones that you were getting right you start to get wrong, they are going to, if you get them increasingly wrong, that error's going to go down and you're going to get less of a vote, right."
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,5-6,"Because e sub T is over the current distribution. And it's not over the sum of the voted, over all the examples you've ever seen. >> Understand. >> So does that make sense? Is that right? >> I don't know. I don't have the intuition, it seems like it could be, you know, could we keep shifting the distribution. It could be that the error is going up. Like if the error could be low, why can't we just make it low from the beginning. >> Right. >> Like, I feel like the error should be going up, because we're, we're asking it harder and harder questions as we go. >> No, no, no, because we're asking it harder and harder questions, but even though we're asking it harder and harder questions, it's forced to be able to do well on those hard questions. It's forced to, because it's a weak learner. I mean that's why having, being able to always, that's why having a weak learner is such a powerful thing. >> But why couldn't we like on, on iteration 17, have something where the weak learner works right at the edge of it's abilities, and it just comes back with something that's a half minus epsilon. >> That's fine. But it has to always be able to do that. If it's a half minus epsilon, the things it's getting"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,6-7,"wrong will have to go back down again. >> No, no I understand that. What I'm saying is that, why would the error go down each iteration. >> Well, it doesn't have to, but it shouldn't be getting bigger. >> Why shouldn't it be getting bigger? >> So, imagine, imagine, imagine the case that you're getting, right. You, you are working at the edge of your abilities. You get half of them right. Roughly and half of them wrong, the ones you got wrong would become more important, so the next time round you're going to get those right, versus the other ones. So you could cycle back and forth I suppose, in the worst case, but then you're just going to be sitting around, always having a little bit more information. So your error will not get worse, you'll just have different ones that are able to vote on that do well on different parts of the space. Right? Because you're always forced to do better than chance. So. >> Yeah but that, that's not the same as saying that we're forced to get better and better each iteration. >> That's right, it's not. >> So it's, yeah again, I don't see that, that property just falling out. >> Well, I don't see it falling out either, but then I haven't read the proof in like seven, eight, nine years. >> Well, I feel like it should be, it should be something like, look we"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,7-8,"had, look at what the, so okay, so we generate a new distribution, what is the previous, what's the previous classified error on this distribution, it better be the case. I mean if it were the case that we always return the best classifier that I could imagine trying to use that but. >> Well we, well we don't, we don't require that. >> Yeah, I mean, it's just finding one that's epsilon minus, or a half minus epsilon. >> Right, so let's, let's see if we can take the simple case, we got three examples, right, and you're bouncing back and forth and you want to construct something so that you always do well on two of them. And then poorly on one, kind of a thing, and that you keep bouncing back and forth. So let's imagine that you have one-third, one-third, one-third, and your first thing gets the first two right and the last one wrong. So you have an error of a third. And you make that last one more likely and the other two less likely. Suitably normalized, right? >> Yep. >> So now, your next one, you want to somehow bounce back and have it decide that it can miss, so let's say you missed the third one. So you, you get the third one right. You get the second"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,8-9,"one right but you get the first one wrong. What's going to happen? Well, three is going to go down. You're still going to, well you won't have a third error actually. You'll have less than a third error because you had to get one of the ones you were getting right wrong, you had to get the one you were getting wrong right. So your error is going to be at least an example I just gave. Less than a third. So, if your error is less and a third, then the weighting goes up more. And so, the one that you just got wrong goes up, doesn't go back to where it was before. It becomes even more important than it was when you had a uniform distribution. So the next time around, you have to get that one right, but it's not enough to break a half. So you're going to have to get something else right as well, and the one in the middle that you were getting right isn't enough. So you'll have to get number three right as well. >> Interesting. >> Right? And so, it's really hard to cycle back and forth between different examples, because you're exponentially"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,9-10,"weighting how important they are. Which means, you're always going to have to pick up something along the way. Because the ones that you, coicidentally, got right two times in a row. Become so unimportant. It doesn't help you to get those right. Whereas, the ones that you've gotten wrong, in the past. You've got to, on these cycles. Pick up some of them in order to get you over a half. >> Mmm >> And so, it is very difficult for you to cycle back and forth. >> Interesting. >> And that kind of makes sense, right? If you think about it in kind of an information gain sense, because what's going on there is you're, you're basically saying you must pick up information all the time. >> Hm. And then your non uni. Well uniform is the wrong word but you are kind of. You know, non-linearly using that information in some way. So that kind of works. It makes some sense to me, but I think that in the end what has to happen is you. You, there must be just a few examples in a kind of weighted sense that you're getting wrong. And so if I'm right, that as"
OWjjAP4noUE,Good Answers - Georgia Tech - Machine Learning,10-11,"you, as you move through each of these cycles, you're weighting in such a way that you have to be picking up things you've gotten wrong in the past. So in other words, it's not enough to say, only the things that are hard in the last set, are the ones that I have to do better. You must also be picking up some of the things that you've gotten wrong earlier more than you were getting right. Because there's just not enough information in the one's that you're getting right all the time, because by the time you get that far along, the weight on them is near zero and they don't matter. >> Interesting. >> And then if you say, well, Charles, I could cycle back by always getting those wrong, yes, but then if you're getting those wrong, they're going to pull up and you're going to have to start getting those right too. And so, over time, you've gotta not just pick out things that do better than a half. But things that do well on a lot of the data. Because there's no way for all of the possible distributions for you to do better than chance otherwise. >> Cool."
1AIZsPOhgmE,Summary - Georgia Tech - Machine Learning,0-1,"Okay, Michael, so that was a great conversation, what have we learned? >> Alright, well we talked about ensemble learning which was the idea of instead of just learning one thing, if it's good to learn once, it's even better to learn multiple times, >> In multiple ways. >> The simple version that we concentrated on first was this notion of bagging. Where what we did is instead of just learning on the whole data set, we would sub-sample bunch of examples from the training set, different ways, and train up different classifiers or different learners on each of those and then merge them together with the average. >> Okay, so if I can summarize that, we learned that ensembles are good. [LAUGH] >> We learned that even simple ensembles like bagging are good. >> We talked about the fact that by using this kind of ensemble approach, you can take simple learners or simple classifiers and merge them together and get more complicated classifiers. >> Mm, yeah, so we can take. We can. Combining simple gives you complex. Anything else?"
1AIZsPOhgmE,Summary - Georgia Tech - Machine Learning,1-2,">> And we talked about the idea of boosting where you can Oh, maybe this is why it's called boosting. You can take something that has possibly very high error but always less than a half, and turn it into something that has very low error. >> So we learned that boosting is really good. And, we talked a little bit about why, that's good. By the way, there's a whole bunch of other details here too, right? Boosting also has the advan, as does bagging Not only has these little properties you've talked about before, but it tends to be very fast. It's agnostic to the learner. As you noticed, that in no time, did we say, try to take advantage of what the actual learner was doing. Just that it was, in fact, a weak learner. >> Hm. >> So I think that's important. It's agnostic. >> Meaning you can plug in any learner you want? >> Yeah. So long as it's a weak learner. So there's something we learned about. We learned about weak learners that we defined with that meant. And, we also talked about ,um, what error really, really means. With respect to some kind of underlying distribution. What do you think Michael? >> That seems like useful stuff."
1AIZsPOhgmE,Summary - Georgia Tech - Machine Learning,2-3,">> These are useful stuff to me. I'm going to throw one more thing at you, Michael, before I let you go. Okay, you ready? >> Yep. >> Here's a simple fact. About boosting that turns out in practice. You know our favorite little over-fitting example. Do you know how over-fitting works? You have a training line that tends to get better, and better, and better. Maybe even going down to zero error. But then you have test error Which gets better and better and at some point it starts to get worse. >> Mm. >> And at that point you have over fitting and I think, Michael, you asserted it at some point or maybe I asserted that ,you always have to worry about over fitting. Over fitting is just the kind of fact of life. You got to come up with ways to deal with it or sort of over believing your data. Well, what if I told you that in practice When you run boosting, even as you run it over time so that your training error keeps getting better and better and better and better, it also turns out that your testing error keeps getting better and better and better and better and better and better and better."
1AIZsPOhgmE,Summary - Georgia Tech - Machine Learning,3-4,">> That seems too good to be true. >> It does seem too good to be true. It turns out it's not too good to be true. And I have an explanation for it. >> Tell me. >> Not until next time. >> alright, see you then. >> See you then. Bye."
